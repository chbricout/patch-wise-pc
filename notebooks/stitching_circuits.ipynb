{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1270fb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"pconv\")\n",
    "import cirkit\n",
    "from cirkit.templates import data_modalities\n",
    "from cirkit.templates import utils\n",
    "from cirkit.pipeline import compile, PipelineContext\n",
    "from cirkit.symbolic.io import plot_circuit\n",
    "import torch\n",
    "from src.utils import patchify, unpatchify\n",
    "from src.benchmark_logic import BenchPCImage\n",
    "ctx = PipelineContext(fold=False, optimize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f4e8e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 71, 209,  19,  ..., 200,  18, 244],\n",
       "           [223,  49,  97,  ...,  20, 106,  36],\n",
       "           [119,  71, 128,  ..., 199, 227, 218],\n",
       "           ...,\n",
       "           [ 44,  16, 150,  ..., 100, 106, 156],\n",
       "           [ 98,   9, 167,  ...,  40, 107, 253],\n",
       "           [ 11, 238,  88,  ...,  33,  53, 245]],\n",
       " \n",
       "          [[211,  27, 153,  ..., 163,  86,  25],\n",
       "           [173, 150,  61,  ...,  14, 236, 230],\n",
       "           [ 77, 158, 244,  ..., 236, 153, 219],\n",
       "           ...,\n",
       "           [175, 230,  37,  ..., 181,  85,  77],\n",
       "           [ 53, 235, 195,  ..., 203,  64, 150],\n",
       "           [188,  31,  48,  ..., 116, 171,  28]],\n",
       " \n",
       "          [[ 46,  30,  41,  ..., 214,  48,  53],\n",
       "           [103,  48, 164,  ..., 138, 115,  16],\n",
       "           [ 25,  51,  88,  ..., 225, 146,  22],\n",
       "           ...,\n",
       "           [ 68,  12, 227,  ..., 130,   0, 128],\n",
       "           [ 65, 223,   8,  ..., 250, 151,   7],\n",
       "           [214,   4, 187,  ..., 155, 162,  84]]]]),\n",
       " tensor([[[[ 71, 209,  19, 110],\n",
       "           [223,  49,  97, 180],\n",
       "           [119,  71, 128, 191],\n",
       "           [250, 215, 103,  31]],\n",
       " \n",
       "          [[211,  27, 153, 227],\n",
       "           [173, 150,  61, 127],\n",
       "           [ 77, 158, 244,  25],\n",
       "           [  3, 152, 137, 105]],\n",
       " \n",
       "          [[ 46,  30,  41, 129],\n",
       "           [103,  48, 164, 190],\n",
       "           [ 25,  51,  88, 193],\n",
       "           [ 13, 118, 196, 100]]],\n",
       " \n",
       " \n",
       "         [[[240, 229,  42, 199],\n",
       "           [183, 225,  88, 145],\n",
       "           [ 47,  79, 114,  76],\n",
       "           [198, 169, 209, 162]],\n",
       " \n",
       "          [[ 60, 113, 251, 229],\n",
       "           [ 48,  19, 149, 216],\n",
       "           [234, 219, 210,  83],\n",
       "           [ 74, 125, 155, 141]],\n",
       " \n",
       "          [[ 22,  30,   2,   2],\n",
       "           [101, 150, 241,  12],\n",
       "           [237,  85, 113, 142],\n",
       "           [152,  98,  25, 207]]],\n",
       " \n",
       " \n",
       "         [[[243, 230, 153, 178],\n",
       "           [161, 154, 138,  76],\n",
       "           [254, 247,  20,  34],\n",
       "           [220, 131, 168, 177]],\n",
       " \n",
       "          [[ 62, 204,   7, 163],\n",
       "           [129, 117, 230,  50],\n",
       "           [187, 168, 213,   5],\n",
       "           [208,  54,  64, 220]],\n",
       " \n",
       "          [[ 66,  98,  29, 247],\n",
       "           [207,  77,  27, 235],\n",
       "           [168, 184, 223, 247],\n",
       "           [209,  23, 205, 254]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[211,  87,   6, 178],\n",
       "           [ 91,  82,  36,  27],\n",
       "           [223, 139, 209, 111],\n",
       "           [ 23, 232,  37, 117]],\n",
       " \n",
       "          [[159,   4, 227, 254],\n",
       "           [ 10, 157, 159, 143],\n",
       "           [ 51, 116, 216,  58],\n",
       "           [ 65, 133, 136, 239]],\n",
       " \n",
       "          [[149,  68,  32, 155],\n",
       "           [164, 178, 101, 249],\n",
       "           [ 73,  12,  95, 226],\n",
       "           [100, 223,   9, 226]]],\n",
       " \n",
       " \n",
       "         [[[ 56, 219, 186,  16],\n",
       "           [223,  10, 213,  47],\n",
       "           [122, 175, 191, 124],\n",
       "           [218,  91,  40, 176]],\n",
       " \n",
       "          [[150,  28, 241,  36],\n",
       "           [120,  71, 136, 117],\n",
       "           [ 52,  88, 241, 244],\n",
       "           [128, 230, 101, 212]],\n",
       " \n",
       "          [[102, 162, 134, 243],\n",
       "           [ 74, 148, 217, 186],\n",
       "           [233,  14, 126,  37],\n",
       "           [ 99,  24, 104, 122]]],\n",
       " \n",
       " \n",
       "         [[[  6,  26,  81,  56],\n",
       "           [190, 100, 106, 156],\n",
       "           [  2,  40, 107, 253],\n",
       "           [ 61,  33,  53, 245]],\n",
       " \n",
       "          [[182,  88,  79,  10],\n",
       "           [164, 181,  85,  77],\n",
       "           [180, 203,  64, 150],\n",
       "           [109, 116, 171,  28]],\n",
       " \n",
       "          [[238, 227,  72,   5],\n",
       "           [105, 130,   0, 128],\n",
       "           [105, 250, 151,   7],\n",
       "           [241, 155, 162,  84]]]]),\n",
       " tensor([[[[ 71, 209,  19,  ..., 200,  18, 244],\n",
       "           [223,  49,  97,  ...,  20, 106,  36],\n",
       "           [119,  71, 128,  ..., 199, 227, 218],\n",
       "           ...,\n",
       "           [ 44,  16, 150,  ..., 100, 106, 156],\n",
       "           [ 98,   9, 167,  ...,  40, 107, 253],\n",
       "           [ 11, 238,  88,  ...,  33,  53, 245]],\n",
       " \n",
       "          [[211,  27, 153,  ..., 163,  86,  25],\n",
       "           [173, 150,  61,  ...,  14, 236, 230],\n",
       "           [ 77, 158, 244,  ..., 236, 153, 219],\n",
       "           ...,\n",
       "           [175, 230,  37,  ..., 181,  85,  77],\n",
       "           [ 53, 235, 195,  ..., 203,  64, 150],\n",
       "           [188,  31,  48,  ..., 116, 171,  28]],\n",
       " \n",
       "          [[ 46,  30,  41,  ..., 214,  48,  53],\n",
       "           [103,  48, 164,  ..., 138, 115,  16],\n",
       "           [ 25,  51,  88,  ..., 225, 146,  22],\n",
       "           ...,\n",
       "           [ 68,  12, 227,  ..., 130,   0, 128],\n",
       "           [ 65, 223,   8,  ..., 250, 151,   7],\n",
       "           [214,   4, 187,  ..., 155, 162,  84]]]]),\n",
       " tensor([[ 71, 209,  19,  ..., 118, 196, 100],\n",
       "         [240, 229,  42,  ...,  98,  25, 207],\n",
       "         [243, 230, 153,  ...,  23, 205, 254],\n",
       "         ...,\n",
       "         [211,  87,   6,  ..., 223,   9, 226],\n",
       "         [ 56, 219, 186,  ...,  24, 104, 122],\n",
       "         [  6,  26,  81,  ..., 155, 162,  84]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size=32\n",
    "kernel_size=4\n",
    "example_data = torch.randint(256,(1,3,image_size,image_size))\n",
    "patch_fn = patchify((kernel_size,kernel_size), (kernel_size,kernel_size))\n",
    "unpatch_fn = unpatchify((image_size,image_size),(kernel_size,kernel_size), (kernel_size,kernel_size), 3)\n",
    "patched=patch_fn(example_data)\n",
    "example_data, patched, unpatch_fn(patched), patched.reshape(-1, 3*kernel_size*kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a2d75b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 2, 2])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patched.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062a561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,  ...,  8385,  8386,  8387],\n",
      "        [    4,     5,     6,  ...,  8389,  8390,  8391],\n",
      "        [    8,     9,    10,  ...,  8393,  8394,  8395],\n",
      "        ...,\n",
      "        [ 3892,  3893,  3894,  ..., 12277, 12278, 12279],\n",
      "        [ 3896,  3897,  3898,  ..., 12281, 12282, 12283],\n",
      "        [ 3900,  3901,  3902,  ..., 12285, 12286, 12287]])\n"
     ]
    }
   ],
   "source": [
    "from copy import copy\n",
    "from cirkit.symbolic.circuit import Scope\n",
    "from cirkit.symbolic.circuit import Circuit\n",
    "\n",
    "\n",
    "from cirkit.symbolic.layers import InputLayer, SumLayer\n",
    "from cirkit.symbolic.parameters import (\n",
    "    Parameter,\n",
    "    ReferenceParameter,\n",
    "    TensorParameter,\n",
    ")\n",
    "\n",
    "def copy_circuit(graph: Circuit,root_node_outputs=None):\n",
    "    new_circ_layers = []\n",
    "    copy_map = {}\n",
    "    in_nodes = {}\n",
    "    outputs = []\n",
    "    for layer in graph.topological_ordering():\n",
    "        new_layer = layer.copyref()\n",
    "        new_circ_layers.append(new_layer)\n",
    "        copy_map[layer] = new_layer\n",
    "        inputs = [copy_map[in_node] for in_node in graph.node_inputs(layer)]\n",
    "        if len(inputs) > 0:\n",
    "            in_nodes[new_layer] = inputs\n",
    "    outputs = [copy_map[out_node] for out_node in graph.outputs]\n",
    "    if root_node_outputs is not None:\n",
    "        for n in outputs:\n",
    "            n.num_output_units = root_node_outputs\n",
    "    return new_circ_layers, in_nodes, outputs\n",
    "\n",
    "\n",
    "def patch_circuits(top_circuit_param, patch_circuit_param):\n",
    "    im_shape = [i*k for i,k in zip(top_circuit_param[\"image_shape\"],patch_circuit_param[\"image_shape\"])]\n",
    "    kernel_shape = patch_circuit_param[\"image_shape\"]\n",
    "\n",
    "    example_data = torch.arange(im_shape[0]*im_shape[1]*im_shape[2]).reshape(1, *im_shape)\n",
    "    patch_fn = patchify(kernel_shape[1:], kernel_shape[1:])\n",
    "    scope_order=patch_fn(example_data).reshape(-1, kernel_shape[0]*kernel_shape[1]*kernel_shape[2])\n",
    "    print(scope_order)\n",
    "    top = data_modalities.image_data(**top_circuit_param)\n",
    "    new_layers = top._nodes.copy()\n",
    "    new_inputs = top._in_nodes.copy()\n",
    "    for new_scope,input_node in zip(scope_order, list(top.layerwise_topological_ordering())[0]):\n",
    "        # Remove input node\n",
    "        new_layers.remove(input_node)\n",
    "        # add output of patch (create patch)\n",
    "        patch = data_modalities.image_data(**patch_circuit_param)\n",
    "        patch_input = list(patch.layerwise_topological_ordering())[0]\n",
    "        for idx,inp in enumerate(patch_input):\n",
    "            inp.scope= Scope([new_scope[list(inp.scope)[0]].item()])\n",
    "        new_layers.extend(patch._nodes)\n",
    "\n",
    "        # verify connections\n",
    "        for node, inputs in top._in_nodes.items():\n",
    "            if input_node in inputs:\n",
    "                new_inputs[node].remove(input_node)\n",
    "                new_inputs[node].extend(patch.outputs)\n",
    "        new_inputs.update(patch._in_nodes)\n",
    "        \n",
    "\n",
    "        \n",
    "    return Circuit(new_layers, new_inputs, top.outputs)\n",
    "    # Update scope\n",
    "\n",
    "units=512\n",
    "new_circ=patch_circuits(\n",
    "    {\n",
    "        \"image_shape\": (1,16,16),\n",
    "        \"region_graph\": \"quad-graph\",\n",
    "        \"input_layer\": \"categorical\",\n",
    "        \"num_input_units\":units,\n",
    "        \"sum_product_layer\": \"cp\",\n",
    "        \"num_sum_units\": units,\n",
    "        \"sum_weight_param\": utils.Parameterization(\n",
    "            activation=\"softmax\", initialization=\"normal\"\n",
    "        ),\n",
    "    },\n",
    "     {\n",
    "        \"image_shape\": (3, kernel_size, kernel_size),\n",
    "        \"region_graph\": \"quad-graph\",\n",
    "        \"input_layer\": \"categorical\",\n",
    "        \"num_input_units\": units,\n",
    "        \"sum_product_layer\": \"cp\",\n",
    "        \"num_sum_units\": units,\n",
    "        \"num_classes\":units,\n",
    "        \"sum_weight_param\": utils.Parameterization(\n",
    "            activation=\"softmax\", initialization=\"normal\"\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "cnew=compile(new_circ)\n",
    "\n",
    "# plot_circuit(new_circ)\n",
    "# new_circ.layers[-1].params['weight'].nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3008c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_circ=data_modalities.image_data(\n",
    "        (3,64,64),\n",
    "        region_graph=\"quad-graph\",\n",
    "        input_layer=\"categorical\",\n",
    "        num_input_units=128,\n",
    "        sum_product_layer=\"cp\",\n",
    "        num_sum_units=128,\n",
    "        num_classes=1,\n",
    "        sum_weight_param=utils.Parameterization(\n",
    "            activation=\"softmax\", initialization=\"normal\"\n",
    "        ),\n",
    ")\n",
    "scopes=list(map(lambda x:list(x.scope)[0], next(test_circ.layerwise_topological_ordering())))\n",
    "nodes=list(test_circ.layerwise_topological_ordering())[6]\n",
    "sub_circ=test_circ.subgraph(nodes[0])\n",
    "sub_circ.scope\n",
    "ctest=compile(test_circ)\n",
    "\n",
    "# ctest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee42da5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchSumLayer(\n",
       "  folds: 32  arity: 1  input-units: 128  output-units: 128\n",
       "  input-shape: (32, 1, -1, 128)\n",
       "  output-shape: (32, -1, 128)\n",
       "  (weight): TorchParameter(\n",
       "    shape: (32, 128, 128)\n",
       "    (0): TorchTensorParameter(output-shape: (32, 128, 128))\n",
       "    (1): TorchSoftmaxParameter(\n",
       "      input-shapes: [(32, 128, 128)]\n",
       "      output-shape: (32, 128, 128)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctest.layers[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db490854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchSumLayer(\n",
       "  folds: 32  arity: 1  input-units: 512  output-units: 512\n",
       "  input-shape: (32, 1, -1, 512)\n",
       "  output-shape: (32, -1, 512)\n",
       "  (weight): TorchParameter(\n",
       "    shape: (32, 512, 512)\n",
       "    (0): TorchTensorParameter(output-shape: (32, 512, 512))\n",
       "    (1): TorchSoftmaxParameter(\n",
       "      input-shapes: [(32, 512, 512)]\n",
       "      output-shape: (32, 512, 512)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cnew.layers[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e973910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt=torch.load(\"pconv/shared.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0c3e429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'circuit_type': 'shared',\n",
       " 'layer_type': 'cp-t',\n",
       " 'region_graph': 'quad-graph',\n",
       " 'num_units': 128,\n",
       " 'lr': 0.05,\n",
       " 'dataset': 'celeba',\n",
       " 'kernel_size': [2, 2],\n",
       " 'colour_transform': 'ycc_lossless',\n",
       " 'batch_size': 32,\n",
       " 'early_stopping_delta': 10,\n",
       " 'experiment_path': 'experiments/bench-shared-64/',\n",
       " 'image_size': (64, 64),\n",
       " 'channel': 3,\n",
       " 'num_classes': 128}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt['hyper_parameters']['config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4009b929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing benchmark PC\n",
      "benchmark PC initialized\n"
     ]
    }
   ],
   "source": [
    "module = BenchPCImage(ckpt['hyper_parameters']['config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27092dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchCircuit(\n",
       "  (0): TorchCategoricalLayer(\n",
       "    folds: 12288  variables: 1  output-units: 128\n",
       "    input-shape: (12288, 1, -1, 1)\n",
       "    output-shape: (12288, -1, 128)\n",
       "    (probs): TorchParameter(\n",
       "      shape: (12288, 128, 256)\n",
       "      (0): TorchTensorParameter(output-shape: (12288, 128, 256))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(12288, 128, 256)]\n",
       "        output-shape: (12288, 128, 256)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): TorchHadamardLayer(\n",
       "    folds: 4096  arity: 3  input-units: 128  output-units: 128\n",
       "    input-shape: (4096, 3, -1, 128)\n",
       "    output-shape: (4096, -1, 128)\n",
       "  )\n",
       "  (2): TorchCPTLayer(\n",
       "    folds: 4096  arity: 2  input-units: 128  output-units: 128\n",
       "    input-shape: (4096, 2, -1, 128)\n",
       "    output-shape: (4096, -1, 128)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (4096, 128, 128)\n",
       "      (0): TorchTensorParameter(output-shape: (4096, 128, 128))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(4096, 128, 128)]\n",
       "        output-shape: (4096, 128, 128)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): TorchCPTLayer(\n",
       "    folds: 2048  arity: 2  input-units: 128  output-units: 128\n",
       "    input-shape: (2048, 2, -1, 128)\n",
       "    output-shape: (2048, -1, 128)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (2048, 128, 128)\n",
       "      (0): TorchTensorParameter(output-shape: (2048, 128, 128))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(2048, 128, 128)]\n",
       "        output-shape: (2048, 128, 128)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): TorchSumLayer(\n",
       "    folds: 1024  arity: 2  input-units: 128  output-units: 128\n",
       "    input-shape: (1024, 2, -1, 128)\n",
       "    output-shape: (1024, -1, 128)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (1024, 128, 256)\n",
       "      (0): TorchTensorParameter(output-shape: (1024, 128, 2))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(1024, 128, 2)]\n",
       "        output-shape: (1024, 128, 2)\n",
       "      )\n",
       "      (2): TorchMixingWeightParameter(\n",
       "        input-shapes: [(1024, 128, 2)]\n",
       "        output-shape: (1024, 128, 256)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): TorchCPTLayer(\n",
       "    folds: 1024  arity: 2  input-units: 128  output-units: 128\n",
       "    input-shape: (1024, 2, -1, 128)\n",
       "    output-shape: (1024, -1, 128)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (1024, 128, 128)\n",
       "      (0): TorchTensorParameter(output-shape: (1024, 128, 128))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(1024, 128, 128)]\n",
       "        output-shape: (1024, 128, 128)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (6): TorchCPTLayer(\n",
       "    folds: 512  arity: 2  input-units: 128  output-units: 128\n",
       "    input-shape: (512, 2, -1, 128)\n",
       "    output-shape: (512, -1, 128)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (512, 128, 128)\n",
       "      (0): TorchTensorParameter(output-shape: (512, 128, 128))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(512, 128, 128)]\n",
       "        output-shape: (512, 128, 128)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (7): TorchSumLayer(\n",
       "    folds: 256  arity: 2  input-units: 128  output-units: 128\n",
       "    input-shape: (256, 2, -1, 128)\n",
       "    output-shape: (256, -1, 128)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (256, 128, 256)\n",
       "      (0): TorchTensorParameter(output-shape: (256, 128, 2))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(256, 128, 2)]\n",
       "        output-shape: (256, 128, 2)\n",
       "      )\n",
       "      (2): TorchMixingWeightParameter(\n",
       "        input-shapes: [(256, 128, 2)]\n",
       "        output-shape: (256, 128, 256)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (8): TorchCPTLayer(\n",
       "    folds: 256  arity: 2  input-units: 128  output-units: 128\n",
       "    input-shape: (256, 2, -1, 128)\n",
       "    output-shape: (256, -1, 128)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (256, 128, 128)\n",
       "      (0): TorchTensorParameter(output-shape: (256, 128, 128))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(256, 128, 128)]\n",
       "        output-shape: (256, 128, 128)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (9): TorchCPTLayer(\n",
       "    folds: 128  arity: 2  input-units: 128  output-units: 128\n",
       "    input-shape: (128, 2, -1, 128)\n",
       "    output-shape: (128, -1, 128)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (128, 128, 128)\n",
       "      (0): TorchTensorParameter(output-shape: (128, 128, 128))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(128, 128, 128)]\n",
       "        output-shape: (128, 128, 128)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (10): TorchSumLayer(\n",
       "    folds: 64  arity: 2  input-units: 128  output-units: 128\n",
       "    input-shape: (64, 2, -1, 128)\n",
       "    output-shape: (64, -1, 128)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (64, 128, 256)\n",
       "      (0): TorchTensorParameter(output-shape: (64, 128, 2))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(64, 128, 2)]\n",
       "        output-shape: (64, 128, 2)\n",
       "      )\n",
       "      (2): TorchMixingWeightParameter(\n",
       "        input-shapes: [(64, 128, 2)]\n",
       "        output-shape: (64, 128, 256)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (11): TorchCPTLayer(\n",
       "    folds: 64  arity: 2  input-units: 128  output-units: 128\n",
       "    input-shape: (64, 2, -1, 128)\n",
       "    output-shape: (64, -1, 128)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (64, 128, 128)\n",
       "      (0): TorchTensorParameter(output-shape: (64, 128, 128))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(64, 128, 128)]\n",
       "        output-shape: (64, 128, 128)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (12): TorchCPTLayer(\n",
       "    folds: 32  arity: 2  input-units: 128  output-units: 128\n",
       "    input-shape: (32, 2, -1, 128)\n",
       "    output-shape: (32, -1, 128)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (32, 128, 128)\n",
       "      (0): TorchTensorParameter(output-shape: (32, 128, 128))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(32, 128, 128)]\n",
       "        output-shape: (32, 128, 128)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (13): TorchSumLayer(\n",
       "    folds: 16  arity: 2  input-units: 128  output-units: 128\n",
       "    input-shape: (16, 2, -1, 128)\n",
       "    output-shape: (16, -1, 128)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (16, 128, 256)\n",
       "      (0): TorchTensorParameter(output-shape: (16, 128, 2))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(16, 128, 2)]\n",
       "        output-shape: (16, 128, 2)\n",
       "      )\n",
       "      (2): TorchMixingWeightParameter(\n",
       "        input-shapes: [(16, 128, 2)]\n",
       "        output-shape: (16, 128, 256)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (14): TorchCPTLayer(\n",
       "    folds: 16  arity: 2  input-units: 128  output-units: 128\n",
       "    input-shape: (16, 2, -1, 128)\n",
       "    output-shape: (16, -1, 128)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (16, 128, 128)\n",
       "      (0): TorchTensorParameter(output-shape: (16, 128, 128))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(16, 128, 128)]\n",
       "        output-shape: (16, 128, 128)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (15): TorchCPTLayer(\n",
       "    folds: 8  arity: 2  input-units: 128  output-units: 128\n",
       "    input-shape: (8, 2, -1, 128)\n",
       "    output-shape: (8, -1, 128)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (8, 128, 128)\n",
       "      (0): TorchTensorParameter(output-shape: (8, 128, 128))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(8, 128, 128)]\n",
       "        output-shape: (8, 128, 128)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (16): TorchSumLayer(\n",
       "    folds: 4  arity: 2  input-units: 128  output-units: 128\n",
       "    input-shape: (4, 2, -1, 128)\n",
       "    output-shape: (4, -1, 128)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (4, 128, 256)\n",
       "      (0): TorchTensorParameter(output-shape: (4, 128, 2))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(4, 128, 2)]\n",
       "        output-shape: (4, 128, 2)\n",
       "      )\n",
       "      (2): TorchMixingWeightParameter(\n",
       "        input-shapes: [(4, 128, 2)]\n",
       "        output-shape: (4, 128, 256)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (17): TorchCPTLayer(\n",
       "    folds: 4  arity: 2  input-units: 128  output-units: 128\n",
       "    input-shape: (4, 2, -1, 128)\n",
       "    output-shape: (4, -1, 128)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (4, 128, 128)\n",
       "      (0): TorchTensorParameter(output-shape: (4, 128, 128))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(4, 128, 128)]\n",
       "        output-shape: (4, 128, 128)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (18): TorchCPTLayer(\n",
       "    folds: 2  arity: 2  input-units: 128  output-units: 128\n",
       "    input-shape: (2, 2, -1, 128)\n",
       "    output-shape: (2, -1, 128)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (2, 128, 128)\n",
       "      (0): TorchTensorParameter(output-shape: (2, 128, 128))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(2, 128, 128)]\n",
       "        output-shape: (2, 128, 128)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (19): TorchSumLayer(\n",
       "    folds: 1  arity: 2  input-units: 128  output-units: 128\n",
       "    input-shape: (1, 2, -1, 128)\n",
       "    output-shape: (1, -1, 128)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (1, 128, 256)\n",
       "      (0): TorchTensorParameter(output-shape: (1, 128, 2))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(1, 128, 2)]\n",
       "        output-shape: (1, 128, 2)\n",
       "      )\n",
       "      (2): TorchMixingWeightParameter(\n",
       "        input-shapes: [(1, 128, 2)]\n",
       "        output-shape: (1, 128, 256)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ed3aa70",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BenchPCImage:\n\tMissing key(s) in state_dict: \"circuit._nodes.0.probs._nodes.0._ptensor\", \"circuit._nodes.0.probs._address_book._in_fold_idx_2_0\", \"circuit._nodes.2.weight._nodes.0._ptensor\", \"circuit._nodes.2.weight._address_book._in_fold_idx_2_0\", \"circuit._nodes.3.weight._nodes.0._ptensor\", \"circuit._nodes.3.weight._address_book._in_fold_idx_2_0\", \"circuit._nodes.4.weight._nodes.0._ptensor\", \"circuit._nodes.4.weight._address_book._in_fold_idx_3_0\". \n\tUnexpected key(s) in state_dict: \"circuit._nodes.0.probs.internal_param.0._ptensor\", \"circuit._nodes.2.weight.internal_param.0._ptensor\", \"circuit._nodes.3.weight.internal_param.0._ptensor\", \"circuit._nodes.4.weight.internal_param.0._ptensor\". \n\tsize mismatch for circuit._nodes.18.weight._nodes.0._ptensor: copying a param with shape torch.Size([2, 1, 128]) from checkpoint, the shape in current model is torch.Size([2, 128, 128]).\n\tsize mismatch for circuit._nodes.19.weight._nodes.0._ptensor: copying a param with shape torch.Size([1, 1, 2]) from checkpoint, the shape in current model is torch.Size([1, 128, 2]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstate_dict\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk/scratch_fast1/s2893001/pconv/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:2629\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2621\u001b[39m         error_msgs.insert(\n\u001b[32m   2622\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2623\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2624\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2625\u001b[39m             ),\n\u001b[32m   2626\u001b[39m         )\n\u001b[32m   2628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2629\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2630\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2631\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2632\u001b[39m         )\n\u001b[32m   2633\u001b[39m     )\n\u001b[32m   2634\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for BenchPCImage:\n\tMissing key(s) in state_dict: \"circuit._nodes.0.probs._nodes.0._ptensor\", \"circuit._nodes.0.probs._address_book._in_fold_idx_2_0\", \"circuit._nodes.2.weight._nodes.0._ptensor\", \"circuit._nodes.2.weight._address_book._in_fold_idx_2_0\", \"circuit._nodes.3.weight._nodes.0._ptensor\", \"circuit._nodes.3.weight._address_book._in_fold_idx_2_0\", \"circuit._nodes.4.weight._nodes.0._ptensor\", \"circuit._nodes.4.weight._address_book._in_fold_idx_3_0\". \n\tUnexpected key(s) in state_dict: \"circuit._nodes.0.probs.internal_param.0._ptensor\", \"circuit._nodes.2.weight.internal_param.0._ptensor\", \"circuit._nodes.3.weight.internal_param.0._ptensor\", \"circuit._nodes.4.weight.internal_param.0._ptensor\". \n\tsize mismatch for circuit._nodes.18.weight._nodes.0._ptensor: copying a param with shape torch.Size([2, 1, 128]) from checkpoint, the shape in current model is torch.Size([2, 128, 128]).\n\tsize mismatch for circuit._nodes.19.weight._nodes.0._ptensor: copying a param with shape torch.Size([1, 1, 2]) from checkpoint, the shape in current model is torch.Size([1, 128, 2])."
     ]
    }
   ],
   "source": [
    "module.load_state_dict(ckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100f774c",
   "metadata": {},
   "source": [
    "## Test Connection Base Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c7b6a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchCategoricalLayer(\n",
      "  folds: 48  variables: 1  output-units: 512\n",
      "  input-shape: (48, 1, -1, 1)\n",
      "  output-shape: (48, -1, 512)\n",
      "  (probs): TorchParameter(\n",
      "    shape: (48, 512, 256)\n",
      "    (0): TorchTensorParameter(output-shape: (48, 512, 256))\n",
      "    (1): TorchSoftmaxParameter(\n",
      "      input-shapes: [(48, 512, 256)]\n",
      "      output-shape: (48, 512, 256)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "TorchHadamardLayer(\n",
      "  folds: 16  arity: 3  input-units: 512  output-units: 512\n",
      "  input-shape: (16, 3, -1, 512)\n",
      "  output-shape: (16, -1, 512)\n",
      ")\n",
      "TorchSumLayer(\n",
      "  folds: 32  arity: 1  input-units: 512  output-units: 512\n",
      "  input-shape: (32, 1, -1, 512)\n",
      "  output-shape: (32, -1, 512)\n",
      "  (weight): TorchParameter(\n",
      "    shape: (32, 512, 512)\n",
      "    (0): TorchTensorParameter(output-shape: (32, 512, 512))\n",
      "    (1): TorchSoftmaxParameter(\n",
      "      input-shapes: [(32, 512, 512)]\n",
      "      output-shape: (32, 512, 512)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "TorchCPTLayer(\n",
      "  folds: 16  arity: 2  input-units: 512  output-units: 512\n",
      "  input-shape: (16, 2, -1, 512)\n",
      "  output-shape: (16, -1, 512)\n",
      "  (weight): TorchParameter(\n",
      "    shape: (16, 512, 512)\n",
      "    (0): TorchTensorParameter(output-shape: (16, 512, 512))\n",
      "    (1): TorchSoftmaxParameter(\n",
      "      input-shapes: [(16, 512, 512)]\n",
      "      output-shape: (16, 512, 512)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "TorchHadamardLayer(\n",
      "  folds: 8  arity: 2  input-units: 512  output-units: 512\n",
      "  input-shape: (8, 2, -1, 512)\n",
      "  output-shape: (8, -1, 512)\n",
      ")\n",
      "TorchSumLayer(\n",
      "  folds: 4  arity: 2  input-units: 512  output-units: 512\n",
      "  input-shape: (4, 2, -1, 512)\n",
      "  output-shape: (4, -1, 512)\n",
      "  (weight): TorchParameter(\n",
      "    shape: (4, 512, 1024)\n",
      "    (0): TorchTensorParameter(output-shape: (4, 512, 2))\n",
      "    (1): TorchSoftmaxParameter(\n",
      "      input-shapes: [(4, 512, 2)]\n",
      "      output-shape: (4, 512, 2)\n",
      "    )\n",
      "    (2): TorchMixingWeightParameter(\n",
      "      input-shapes: [(4, 512, 2)]\n",
      "      output-shape: (4, 512, 1024)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "TorchSumLayer(\n",
      "  folds: 8  arity: 1  input-units: 512  output-units: 512\n",
      "  input-shape: (8, 1, -1, 512)\n",
      "  output-shape: (8, -1, 512)\n",
      "  (weight): TorchParameter(\n",
      "    shape: (8, 512, 512)\n",
      "    (0): TorchTensorParameter(output-shape: (8, 512, 512))\n",
      "    (1): TorchSoftmaxParameter(\n",
      "      input-shapes: [(8, 512, 512)]\n",
      "      output-shape: (8, 512, 512)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "TorchCPTLayer(\n",
      "  folds: 4  arity: 2  input-units: 512  output-units: 512\n",
      "  input-shape: (4, 2, -1, 512)\n",
      "  output-shape: (4, -1, 512)\n",
      "  (weight): TorchParameter(\n",
      "    shape: (4, 512, 512)\n",
      "    (0): TorchTensorParameter(output-shape: (4, 512, 512))\n",
      "    (1): TorchSoftmaxParameter(\n",
      "      input-shapes: [(4, 512, 512)]\n",
      "      output-shape: (4, 512, 512)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "TorchCPTLayer(\n",
      "  folds: 2  arity: 2  input-units: 512  output-units: 1\n",
      "  input-shape: (2, 2, -1, 512)\n",
      "  output-shape: (2, -1, 1)\n",
      "  (weight): TorchParameter(\n",
      "    shape: (2, 1, 512)\n",
      "    (0): TorchTensorParameter(output-shape: (2, 1, 512))\n",
      "    (1): TorchSoftmaxParameter(\n",
      "      input-shapes: [(2, 1, 512)]\n",
      "      output-shape: (2, 1, 512)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "torch.Size([2, 1, 512])\n",
      "torch.Size([1, 512, 512])\n",
      "torch.Size([2, 512, 512])\n",
      "TorchSumLayer(\n",
      "  folds: 1  arity: 2  input-units: 1  output-units: 1\n",
      "  input-shape: (1, 2, -1, 1)\n",
      "  output-shape: (1, -1, 1)\n",
      "  (weight): TorchParameter(\n",
      "    shape: (1, 1, 2)\n",
      "    (0): TorchTensorParameter(output-shape: (1, 1, 2))\n",
      "    (1): TorchSoftmaxParameter(\n",
      "      input-shapes: [(1, 1, 2)]\n",
      "      output-shape: (1, 1, 2)\n",
      "    )\n",
      "    (2): TorchMixingWeightParameter(\n",
      "      input-shapes: [(1, 1, 2)]\n",
      "      output-shape: (1, 1, 2)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 1, 2])\n",
      "torch.Size([1, 512, 2])\n",
      "torch.Size([1, 512, 2])\n"
     ]
    }
   ],
   "source": [
    "from cirkit.backend.torch.layers.inner import TorchSumLayer\n",
    "from cirkit.backend.torch.layers.optimized import TorchCPTLayer\n",
    "from cirkit.backend.torch.layers.input import TorchInputLayer\n",
    "from cirkit.backend.torch.circuits import TorchCircuit\n",
    "from cirkit.backend.torch.parameters.nodes import TorchParameterInput, TorchMixingWeightParameter, TorchTensorParameter, TorchUnaryParameterOp\n",
    "from cirkit.backend.torch.parameters.parameter import TorchParameter\n",
    "\n",
    "\n",
    "\n",
    "def copy_parameter(graph: TorchParameter, new_shape):\n",
    "    new_param_nodes = []\n",
    "    copy_map = {}\n",
    "    in_nodes = {}\n",
    "    outputs = []\n",
    "    for n in graph.topological_ordering():\n",
    "        instance = type(n)\n",
    "        config = n.config\n",
    "        if isinstance(n, TorchTensorParameter):\n",
    "            del config[\"shape\"]\n",
    "            new_param = instance(*new_shape,**config)\n",
    "            new_param._ptensor = torch.nn.Parameter(torch.zeros((graph.shape[0],*new_shape)))\n",
    "\n",
    "        elif isinstance(n, TorchUnaryParameterOp):\n",
    "            config[\"in_shape\"]=new_shape\n",
    "\n",
    "            new_param = instance(**config)\n",
    "        new_param_nodes.append(new_param)\n",
    "        copy_map[n] = new_param\n",
    "        inputs = [copy_map[in_node] for in_node in graph.node_inputs(n)]\n",
    "        if len(inputs) > 0:\n",
    "            in_nodes[new_param] = inputs\n",
    "    outputs = [copy_map[out_node] for out_node in graph.outputs]\n",
    "    parameter= TorchParameter(modules=new_param_nodes, in_modules=in_nodes, outputs=outputs)\n",
    "    return parameter\n",
    "\n",
    "class TorchSharedParameter(TorchParameterInput):\n",
    "    def __init__(self,\n",
    "        in_shape:tuple[int,...],\n",
    "        parameter:list[torch.nn.Module],\n",
    "        num_folds:int\n",
    "):\n",
    "        super().__init__()\n",
    "        self._num_folds=num_folds\n",
    "        self.in_shape=in_shape\n",
    "        self.internal_param = parameter\n",
    "    \n",
    "    def forward(self):\n",
    "        current_input=None\n",
    "        for param in self.internal_param:\n",
    "            if current_input is None:\n",
    "                current_input=param()\n",
    "            else:\n",
    "                current_input=param(current_input)\n",
    "        share_fold, *inner_units = current_input.shape\n",
    "        expanded = current_input.expand(self.num_folds//share_fold,share_fold, *inner_units).reshape(self.num_folds,*inner_units)\n",
    "\n",
    "        return expanded\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.in_shape\n",
    "\n",
    "def share_param_like(base_circ:TorchCircuit, share_struct:TorchCircuit, should_init_mean=False):\n",
    "    for idx, layer in enumerate(share_struct.layers):\n",
    "        print(layer)\n",
    "        if isinstance(layer, TorchInputLayer):\n",
    "            \n",
    "            folds = base_circ.layers[idx].probs.num_folds\n",
    "            shared_param = TorchSharedParameter(base_circ.layers[idx].probs.shape, parameter=layer.probs.nodes, num_folds=folds)\n",
    "            base_circ.layers[idx].probs = shared_param\n",
    "        elif isinstance(layer, TorchCPTLayer) or isinstance(layer, TorchSumLayer):\n",
    "            internal_param=layer.weight.nodes\n",
    "            if layer.num_output_units != base_circ.layers[idx].num_output_units:\n",
    "                new_parameter = copy_parameter(layer.weight, base_circ.layers[idx].weight.nodes[0].shape)\n",
    "                print(internal_param[0]._ptensor.data.shape)\n",
    "\n",
    "                print(new_parameter.nodes[0]._ptensor.data.shape)\n",
    "                _,o,i = internal_param[0]._ptensor.data.shape\n",
    "                _, goal_o, goal_i = new_parameter.nodes[0]._ptensor.data.shape\n",
    "                num_input = goal_i//i\n",
    "                num_output = goal_o//o\n",
    "                new_parameter.nodes[0]._ptensor.data=internal_param[0]._ptensor.data.clone().repeat((1, num_output, num_input))\n",
    "                print(new_parameter.nodes[0]._ptensor.data.shape)\n",
    "\n",
    "                internal_param=new_parameter.nodes\n",
    "            folds = base_circ.layers[idx].weight.num_folds\n",
    "            shared_param = TorchSharedParameter(base_circ.layers[idx].weight.shape, parameter=internal_param, num_folds=folds)\n",
    "            base_circ.layers[idx].weight = shared_param\n",
    "    if should_init_mean:\n",
    "        init_mean(base_circ, len(share_struct.layers))\n",
    "\n",
    "\n",
    "def init_mean(circ, start_idx):\n",
    "    for layer in circ.layers[start_idx:]:\n",
    "        print(layer)\n",
    "        if isinstance(layer, TorchCPTLayer) or isinstance(layer, TorchSumLayer):\n",
    "            param = layer.weight\n",
    "            tensor = param.nodes[0]._ptensor\n",
    "            inputs =tensor.shape[-1]\n",
    "\n",
    "            param.nodes[0]._ptensor.data = torch.full(tensor.shape, torch.exp(torch.tensor(1/inputs)))\n",
    "\n",
    "patch_circ=data_modalities.image_data(\n",
    "        (3,kernel_size,kernel_size),\n",
    "        region_graph=\"quad-graph\",\n",
    "        input_layer=\"categorical\",\n",
    "        num_input_units=units,\n",
    "        sum_product_layer=\"cp\",\n",
    "        num_sum_units=units,\n",
    "        num_classes=1,\n",
    "        sum_weight_param=utils.Parameterization(\n",
    "            activation=\"softmax\", initialization=\"normal\"\n",
    "        ),\n",
    ")\n",
    "# top_circ=data_modalities.image_data(\n",
    "#         (1,2,2),\n",
    "#         region_graph=\"quad-graph\",\n",
    "#         input_layer=\"categorical\",\n",
    "#         num_input_units=2,\n",
    "#         sum_product_layer=\"cp-t\",\n",
    "#         num_sum_units=2,\n",
    "#         sum_weight_param=utils.Parameterization(\n",
    "#             activation=\"softmax\", initialization=\"normal\"\n",
    "#         ),\n",
    "# )\n",
    "cpatch = compile(patch_circ)\n",
    "cbase = compile(new_circ)\n",
    "# ctop=compile(top_circ)\n",
    "\n",
    "share_param_like(cbase, cpatch, should_init_mean=False)\n",
    "# cbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ddba7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchParameter(\n",
       "  shape: (1, 2, 4)\n",
       "  (0): TorchTensorParameter(output-shape: (1, 2, 2))\n",
       "  (1): TorchSoftmaxParameter(\n",
       "    input-shapes: [(1, 2, 2)]\n",
       "    output-shape: (1, 2, 2)\n",
       "  )\n",
       "  (2): TorchMixingWeightParameter(\n",
       "    input-shapes: [(1, 2, 2)]\n",
       "    output-shape: (1, 2, 4)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_parameter(cpatch.layers[-1].weight,(2,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04249a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,   3,   8,   9,  10,  11,  16,  17,  18,  19,  24,  25,\n",
       "          26,  27,  64,  65,  66,  67,  72,  73,  74,  75,  80,  81,  82,  83,\n",
       "          88,  89,  90,  91, 128, 129, 130, 131, 136, 137, 138, 139, 144, 145,\n",
       "         146, 147, 152, 153, 154, 155],\n",
       "        [  4,   5,   6,   7,  12,  13,  14,  15,  20,  21,  22,  23,  28,  29,\n",
       "          30,  31,  68,  69,  70,  71,  76,  77,  78,  79,  84,  85,  86,  87,\n",
       "          92,  93,  94,  95, 132, 133, 134, 135, 140, 141, 142, 143, 148, 149,\n",
       "         150, 151, 156, 157, 158, 159],\n",
       "        [ 32,  33,  34,  35,  40,  41,  42,  43,  48,  49,  50,  51,  56,  57,\n",
       "          58,  59,  96,  97,  98,  99, 104, 105, 106, 107, 112, 113, 114, 115,\n",
       "         120, 121, 122, 123, 160, 161, 162, 163, 168, 169, 170, 171, 176, 177,\n",
       "         178, 179, 184, 185, 186, 187],\n",
       "        [ 36,  37,  38,  39,  44,  45,  46,  47,  52,  53,  54,  55,  60,  61,\n",
       "          62,  63, 100, 101, 102, 103, 108, 109, 110, 111, 116, 117, 118, 119,\n",
       "         124, 125, 126, 127, 164, 165, 166, 167, 172, 173, 174, 175, 180, 181,\n",
       "         182, 183, 188, 189, 190, 191]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patched.reshape(-1, 3*4*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5cc7a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchCategoricalLayer:\n",
      "                       Input shape: torch.Size([48, 64, 1])\n",
      "                       Input: tensor([[[235],\n",
      "         [ 26],\n",
      "         [ 72],\n",
      "         ...,\n",
      "         [202],\n",
      "         [183],\n",
      "         [ 23]],\n",
      "\n",
      "        [[ 16],\n",
      "         [234],\n",
      "         [201],\n",
      "         ...,\n",
      "         [ 73],\n",
      "         [135],\n",
      "         [217]],\n",
      "\n",
      "        [[101],\n",
      "         [211],\n",
      "         [218],\n",
      "         ...,\n",
      "         [204],\n",
      "         [117],\n",
      "         [239]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[172],\n",
      "         [173],\n",
      "         [ 98],\n",
      "         ...,\n",
      "         [184],\n",
      "         [227],\n",
      "         [250]],\n",
      "\n",
      "        [[ 61],\n",
      "         [156],\n",
      "         [141],\n",
      "         ...,\n",
      "         [ 37],\n",
      "         [134],\n",
      "         [141]],\n",
      "\n",
      "        [[ 98],\n",
      "         [  1],\n",
      "         [155],\n",
      "         ...,\n",
      "         [ 14],\n",
      "         [182],\n",
      "         [110]]])\n",
      "Output (torch.Size([48, 64, 512])):  tensor([[[-5.9017, -5.2065, -4.6380,  ..., -7.0506, -6.0913, -5.5275],\n",
      "         [-6.8701, -6.3171, -7.0039,  ..., -5.7161, -6.9219, -6.8037],\n",
      "         [-6.8242, -4.7912, -5.7677,  ..., -6.3480, -5.2794, -4.0975],\n",
      "         ...,\n",
      "         [-5.8936, -6.3410, -6.5509,  ..., -6.5629, -4.5744, -5.6617],\n",
      "         [-5.7428, -4.1974, -6.4798,  ..., -5.2544, -5.7431, -4.5708],\n",
      "         [-3.2877, -6.3601, -6.0474,  ..., -6.9313, -6.2544, -7.8228]],\n",
      "\n",
      "        [[-5.3310, -6.3777, -3.8229,  ..., -6.1503, -6.5037, -6.8531],\n",
      "         [-4.6770, -5.2171, -4.9431,  ..., -7.0823, -6.8492, -5.5471],\n",
      "         [-3.8173, -4.8745, -6.5079,  ..., -7.6761, -6.5601, -6.2989],\n",
      "         ...,\n",
      "         [-5.1823, -7.4910, -6.2259,  ..., -6.8416, -7.1221, -7.4658],\n",
      "         [-6.7832, -5.3603, -5.4941,  ..., -6.7006, -5.1978, -6.1330],\n",
      "         [-6.2999, -6.1967, -5.3373,  ..., -7.0418, -6.4071, -5.8303]],\n",
      "\n",
      "        [[-7.7115, -4.8916, -5.9795,  ..., -5.3686, -5.3837, -7.6764],\n",
      "         [-6.0099, -4.4193, -4.5733,  ..., -4.1990, -5.2371, -6.7313],\n",
      "         [-6.0890, -4.2791, -7.0557,  ..., -4.5571, -7.3198, -5.6892],\n",
      "         ...,\n",
      "         [-5.2272, -4.6106, -6.3024,  ..., -5.8278, -5.6010, -5.7988],\n",
      "         [-5.9940, -6.2321, -6.1558,  ..., -5.6320, -5.9330, -4.6163],\n",
      "         [-5.4839, -5.4872, -6.0736,  ..., -4.4011, -6.5252, -6.7646]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.6439, -5.8212, -6.9475,  ..., -6.6724, -6.3573, -4.4898],\n",
      "         [-6.7110, -7.3528, -7.3888,  ..., -5.6539, -7.3134, -5.9065],\n",
      "         [-6.9174, -6.8539, -4.6598,  ..., -6.0009, -6.1528, -7.0883],\n",
      "         ...,\n",
      "         [-5.8529, -6.1203, -4.9225,  ..., -5.6432, -6.7531, -7.4350],\n",
      "         [-4.6000, -5.0014, -6.7323,  ..., -4.8712, -7.0332, -6.0740],\n",
      "         [-4.3712, -5.9586, -4.8683,  ..., -5.4677, -5.5597, -6.6288]],\n",
      "\n",
      "        [[-6.5043, -4.6042, -4.8428,  ..., -5.2032, -8.0269, -5.3088],\n",
      "         [-6.2792, -6.7355, -7.8235,  ..., -6.5619, -7.1024, -6.6907],\n",
      "         [-4.2110, -5.9805, -4.9656,  ..., -7.2668, -5.6935, -5.9949],\n",
      "         ...,\n",
      "         [-7.6174, -6.8069, -6.1409,  ..., -6.4094, -4.9036, -4.9168],\n",
      "         [-5.3212, -5.5474, -6.6192,  ..., -4.4937, -7.4542, -4.3076],\n",
      "         [-4.2110, -5.9805, -4.9656,  ..., -7.2668, -5.6935, -5.9949]],\n",
      "\n",
      "        [[-7.3500, -5.2194, -6.6400,  ..., -4.0562, -7.2604, -4.6096],\n",
      "         [-6.3125, -5.3409, -5.7216,  ..., -5.1406, -5.0766, -6.1419],\n",
      "         [-6.6557, -5.8892, -5.7765,  ..., -7.7807, -6.0334, -6.2484],\n",
      "         ...,\n",
      "         [-6.0386, -6.2901, -7.3359,  ..., -6.7075, -6.6042, -6.7669],\n",
      "         [-6.5835, -6.8242, -6.3935,  ..., -4.9297, -6.1167, -6.7769],\n",
      "         [-7.6926, -5.0970, -7.2634,  ..., -6.9023, -7.5560, -6.1037]]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "TorchHadamardLayer:\n",
      "                       Input shape: torch.Size([16, 3, 64, 512])\n",
      "                       Input: tensor([[[[-5.9017, -5.2065, -4.6380,  ..., -7.0506, -6.0913, -5.5275],\n",
      "          [-6.8701, -6.3171, -7.0039,  ..., -5.7161, -6.9219, -6.8037],\n",
      "          [-6.8242, -4.7912, -5.7677,  ..., -6.3480, -5.2794, -4.0975],\n",
      "          ...,\n",
      "          [-5.8936, -6.3410, -6.5509,  ..., -6.5629, -4.5744, -5.6617],\n",
      "          [-5.7428, -4.1974, -6.4798,  ..., -5.2544, -5.7431, -4.5708],\n",
      "          [-3.2877, -6.3601, -6.0474,  ..., -6.9313, -6.2544, -7.8228]],\n",
      "\n",
      "         [[-5.3310, -6.3777, -3.8229,  ..., -6.1503, -6.5037, -6.8531],\n",
      "          [-4.6770, -5.2171, -4.9431,  ..., -7.0823, -6.8492, -5.5471],\n",
      "          [-3.8173, -4.8745, -6.5079,  ..., -7.6761, -6.5601, -6.2989],\n",
      "          ...,\n",
      "          [-5.1823, -7.4910, -6.2259,  ..., -6.8416, -7.1221, -7.4658],\n",
      "          [-6.7832, -5.3603, -5.4941,  ..., -6.7006, -5.1978, -6.1330],\n",
      "          [-6.2999, -6.1967, -5.3373,  ..., -7.0418, -6.4071, -5.8303]],\n",
      "\n",
      "         [[-7.7115, -4.8916, -5.9795,  ..., -5.3686, -5.3837, -7.6764],\n",
      "          [-6.0099, -4.4193, -4.5733,  ..., -4.1990, -5.2371, -6.7313],\n",
      "          [-6.0890, -4.2791, -7.0557,  ..., -4.5571, -7.3198, -5.6892],\n",
      "          ...,\n",
      "          [-5.2272, -4.6106, -6.3024,  ..., -5.8278, -5.6010, -5.7988],\n",
      "          [-5.9940, -6.2321, -6.1558,  ..., -5.6320, -5.9330, -4.6163],\n",
      "          [-5.4839, -5.4872, -6.0736,  ..., -4.4011, -6.5252, -6.7646]]],\n",
      "\n",
      "\n",
      "        [[[-5.4697, -5.9085, -6.1005,  ..., -5.0270, -5.3412, -6.8285],\n",
      "          [-4.0309, -6.9032, -4.5625,  ..., -5.6612, -5.9622, -5.8907],\n",
      "          [-5.4821, -5.5736, -3.4703,  ..., -6.1240, -5.3406, -5.1298],\n",
      "          ...,\n",
      "          [-6.1889, -7.2259, -5.5089,  ..., -5.1595, -7.2270, -4.2322],\n",
      "          [-4.5221, -4.9183, -3.8048,  ..., -5.2156, -6.4031, -6.8007],\n",
      "          [-7.8260, -6.6731, -5.2565,  ..., -6.3417, -7.3676, -7.2371]],\n",
      "\n",
      "         [[-5.4169, -6.1519, -6.3200,  ..., -5.1877, -6.0122, -6.5483],\n",
      "          [-6.3890, -6.3823, -6.0620,  ..., -7.3648, -5.7816, -6.8146],\n",
      "          [-4.9788, -5.2498, -6.5017,  ..., -5.9823, -6.1022, -7.5482],\n",
      "          ...,\n",
      "          [-5.7949, -5.3197, -5.3877,  ..., -5.5721, -6.0447, -5.5152],\n",
      "          [-6.4191, -7.4373, -6.0616,  ..., -6.4697, -5.6332, -5.1474],\n",
      "          [-8.7101, -5.0629, -7.4506,  ..., -7.7536, -6.0921, -6.9574]],\n",
      "\n",
      "         [[-5.1725, -5.1651, -4.5379,  ..., -6.4341, -7.3056, -5.0234],\n",
      "          [-7.1870, -6.0252, -7.8139,  ..., -6.1258, -4.0859, -7.0647],\n",
      "          [-5.2509, -3.1203, -5.2462,  ..., -5.9502, -4.9624, -7.5104],\n",
      "          ...,\n",
      "          [-5.7343, -6.6155, -5.3261,  ..., -6.2897, -6.4399, -4.7013],\n",
      "          [-7.1384, -5.5327, -4.0924,  ..., -5.7944, -5.3939, -6.9608],\n",
      "          [-4.1010, -6.7315, -6.1016,  ..., -6.4632, -6.8525, -5.9202]]],\n",
      "\n",
      "\n",
      "        [[[-5.5657, -6.6976, -6.4540,  ..., -6.1760, -7.2122, -7.3014],\n",
      "          [-6.2094, -5.2660, -6.1419,  ..., -6.1707, -7.2960, -7.1308],\n",
      "          [-5.3447, -5.4744, -2.9641,  ..., -4.2687, -6.8842, -7.6065],\n",
      "          ...,\n",
      "          [-4.5713, -5.7892, -4.8149,  ..., -6.0732, -6.1385, -6.3307],\n",
      "          [-5.2817, -5.5118, -6.4818,  ..., -5.5101, -6.5192, -6.1041],\n",
      "          [-6.6216, -5.1870, -6.3445,  ..., -5.9797, -5.4583, -6.2494]],\n",
      "\n",
      "         [[-4.9120, -6.7523, -6.2174,  ..., -6.1434, -6.4120, -5.4745],\n",
      "          [-5.7264, -7.6637, -5.9088,  ..., -6.2721, -5.5881, -6.3049],\n",
      "          [-5.3810, -6.5463, -6.1684,  ..., -4.7002, -8.9518, -5.4462],\n",
      "          ...,\n",
      "          [-7.3739, -5.8927, -4.2844,  ..., -5.6518, -3.9687, -6.6553],\n",
      "          [-5.6954, -4.7007, -5.7817,  ..., -7.4135, -6.3789, -6.2275],\n",
      "          [-7.0734, -6.8717, -8.7742,  ..., -4.3884, -5.1226, -5.9743]],\n",
      "\n",
      "         [[-8.0860, -9.0437, -5.5886,  ..., -6.5381, -6.7009, -6.1975],\n",
      "          [-5.5388, -6.2797, -6.2644,  ..., -7.4260, -6.8501, -7.0279],\n",
      "          [-5.8044, -7.7919, -4.7366,  ..., -5.8710, -4.7436, -6.9328],\n",
      "          ...,\n",
      "          [-5.8753, -5.8845, -6.7933,  ..., -5.7454, -6.1096, -5.7007],\n",
      "          [-6.7330, -5.2573, -7.2250,  ..., -4.6489, -6.0914, -4.9492],\n",
      "          [-6.2619, -5.4632, -5.2141,  ..., -6.4283, -8.4555, -5.0709]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-7.4955, -6.3942, -4.8859,  ..., -4.8276, -7.2962, -6.1133],\n",
      "          [-4.7753, -5.4250, -6.4991,  ..., -7.5170, -6.7392, -6.4055],\n",
      "          [-7.5566, -6.3035, -6.3992,  ..., -6.5021, -5.5752, -5.5497],\n",
      "          ...,\n",
      "          [-5.0570, -6.5045, -7.1240,  ..., -5.7808, -5.5835, -7.7009],\n",
      "          [-5.4323, -7.0487, -6.2549,  ..., -7.7313, -6.2906, -7.3532],\n",
      "          [-6.9563, -5.2952, -5.2949,  ..., -5.7753, -6.0459, -5.7736]],\n",
      "\n",
      "         [[-6.8828, -4.2094, -5.8456,  ..., -6.0874, -6.5777, -6.0805],\n",
      "          [-4.5755, -5.7843, -5.7636,  ..., -4.8238, -6.6022, -5.3587],\n",
      "          [-8.9299, -6.1750, -6.8666,  ..., -6.0463, -6.2897, -5.0591],\n",
      "          ...,\n",
      "          [-7.5453, -4.6605, -7.1881,  ..., -3.9023, -6.1453, -5.9902],\n",
      "          [-6.8332, -5.4369, -4.7022,  ..., -4.4923, -3.1339, -5.6798],\n",
      "          [-6.0497, -5.2870, -7.4849,  ..., -4.7482, -4.3045, -6.3160]],\n",
      "\n",
      "         [[-6.9700, -3.6716, -6.4442,  ..., -5.4783, -7.3922, -6.3840],\n",
      "          [-4.8603, -5.3162, -5.3455,  ..., -6.4627, -6.1065, -6.5302],\n",
      "          [-5.4315, -6.4513, -6.3443,  ..., -7.0558, -5.9529, -6.4522],\n",
      "          ...,\n",
      "          [-7.2815, -6.2767, -6.3878,  ..., -6.8022, -6.9218, -7.4406],\n",
      "          [-6.3592, -5.3912, -6.2252,  ..., -5.3801, -7.0477, -4.9504],\n",
      "          [-5.0273, -6.3466, -5.1722,  ..., -8.0520, -5.4775, -6.6749]]],\n",
      "\n",
      "\n",
      "        [[[-5.9954, -5.5896, -7.3979,  ..., -7.6455, -5.1309, -5.0319],\n",
      "          [-6.1605, -6.6263, -4.2148,  ..., -5.3626, -6.2811, -5.1542],\n",
      "          [-4.9927, -6.0318, -6.2540,  ..., -6.3049, -6.6051, -6.3120],\n",
      "          ...,\n",
      "          [-5.4179, -7.8102, -5.3022,  ..., -5.0710, -3.9306, -4.7417],\n",
      "          [-5.6596, -7.2310, -4.4766,  ..., -6.0458, -7.9515, -6.6989],\n",
      "          [-4.6798, -4.3820, -5.8977,  ..., -5.2983, -4.9297, -6.6016]],\n",
      "\n",
      "         [[-6.2732, -5.8140, -6.0310,  ..., -8.0405, -6.7379, -5.6683],\n",
      "          [-5.9702, -5.8262, -6.2532,  ..., -4.9452, -5.6233, -6.6372],\n",
      "          [-7.2137, -7.7002, -8.3657,  ..., -6.6151, -4.5264, -2.8719],\n",
      "          ...,\n",
      "          [-5.0234, -7.6131, -6.5393,  ..., -6.6515, -4.9013, -7.3097],\n",
      "          [-7.1354, -6.3761, -4.5077,  ..., -6.9270, -5.9459, -6.1242],\n",
      "          [-6.5981, -6.0509, -5.4124,  ..., -7.5163, -4.4560, -5.4389]],\n",
      "\n",
      "         [[-6.5128, -6.6988, -6.8775,  ..., -5.6490, -5.6299, -7.6940],\n",
      "          [-5.6617, -5.8714, -7.5771,  ..., -5.4759, -7.0551, -5.8064],\n",
      "          [-5.7598, -6.3288, -8.5073,  ..., -7.2635, -6.2466, -6.2253],\n",
      "          ...,\n",
      "          [-5.7778, -5.9876, -5.2400,  ..., -5.4546, -7.0034, -5.5207],\n",
      "          [-6.1398, -6.6523, -5.4179,  ..., -5.2197, -6.5285, -5.8843],\n",
      "          [-5.8378, -6.4825, -6.1550,  ..., -4.8837, -5.3511, -6.7735]]],\n",
      "\n",
      "\n",
      "        [[[-5.6439, -5.8212, -6.9475,  ..., -6.6724, -6.3573, -4.4898],\n",
      "          [-6.7110, -7.3528, -7.3888,  ..., -5.6539, -7.3134, -5.9065],\n",
      "          [-6.9174, -6.8539, -4.6598,  ..., -6.0009, -6.1528, -7.0883],\n",
      "          ...,\n",
      "          [-5.8529, -6.1203, -4.9225,  ..., -5.6432, -6.7531, -7.4350],\n",
      "          [-4.6000, -5.0014, -6.7323,  ..., -4.8712, -7.0332, -6.0740],\n",
      "          [-4.3712, -5.9586, -4.8683,  ..., -5.4677, -5.5597, -6.6288]],\n",
      "\n",
      "         [[-6.5043, -4.6042, -4.8428,  ..., -5.2032, -8.0269, -5.3088],\n",
      "          [-6.2792, -6.7355, -7.8235,  ..., -6.5619, -7.1024, -6.6907],\n",
      "          [-4.2110, -5.9805, -4.9656,  ..., -7.2668, -5.6935, -5.9949],\n",
      "          ...,\n",
      "          [-7.6174, -6.8069, -6.1409,  ..., -6.4094, -4.9036, -4.9168],\n",
      "          [-5.3212, -5.5474, -6.6192,  ..., -4.4937, -7.4542, -4.3076],\n",
      "          [-4.2110, -5.9805, -4.9656,  ..., -7.2668, -5.6935, -5.9949]],\n",
      "\n",
      "         [[-7.3500, -5.2194, -6.6400,  ..., -4.0562, -7.2604, -4.6096],\n",
      "          [-6.3125, -5.3409, -5.7216,  ..., -5.1406, -5.0766, -6.1419],\n",
      "          [-6.6557, -5.8892, -5.7765,  ..., -7.7807, -6.0334, -6.2484],\n",
      "          ...,\n",
      "          [-6.0386, -6.2901, -7.3359,  ..., -6.7075, -6.6042, -6.7669],\n",
      "          [-6.5835, -6.8242, -6.3935,  ..., -4.9297, -6.1167, -6.7769],\n",
      "          [-7.6926, -5.0970, -7.2634,  ..., -6.9023, -7.5560, -6.1037]]]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([16, 64, 512])):  tensor([[[-18.9442, -16.4758, -14.4405,  ..., -18.5695, -17.9787, -20.0571],\n",
      "         [-17.5570, -15.9536, -16.5203,  ..., -16.9974, -19.0082, -19.0821],\n",
      "         [-16.7306, -13.9448, -19.3313,  ..., -18.5812, -19.1592, -16.0857],\n",
      "         ...,\n",
      "         [-16.3030, -18.4427, -19.0792,  ..., -19.2323, -17.2974, -18.9263],\n",
      "         [-18.5200, -15.7898, -18.1298,  ..., -17.5871, -16.8739, -15.3201],\n",
      "         [-15.0714, -18.0441, -17.4583,  ..., -18.3741, -19.1867, -20.4178]],\n",
      "\n",
      "        [[-16.0591, -17.2255, -16.9584,  ..., -16.6488, -18.6590, -18.4002],\n",
      "         [-17.6068, -19.3107, -18.4385,  ..., -19.1518, -15.8297, -19.7699],\n",
      "         [-15.7118, -13.9436, -15.2182,  ..., -18.0565, -16.4052, -20.1884],\n",
      "         ...,\n",
      "         [-17.7182, -19.1611, -16.2227,  ..., -17.0214, -19.7116, -14.4488],\n",
      "         [-18.0796, -17.8883, -13.9588,  ..., -17.4797, -17.4302, -18.9089],\n",
      "         [-20.6371, -18.4675, -18.8088,  ..., -20.5585, -20.3122, -20.1147]],\n",
      "\n",
      "        [[-18.5637, -22.4936, -18.2600,  ..., -18.8575, -20.3251, -18.9734],\n",
      "         [-17.4747, -19.2094, -18.3150,  ..., -19.8689, -19.7343, -20.4635],\n",
      "         [-16.5301, -19.8126, -13.8691,  ..., -14.8399, -20.5797, -19.9855],\n",
      "         ...,\n",
      "         [-17.8206, -17.5663, -15.8926,  ..., -17.4703, -16.2168, -18.6867],\n",
      "         [-17.7102, -15.4698, -19.4885,  ..., -17.5726, -18.9896, -17.2808],\n",
      "         [-19.9569, -17.5219, -20.3328,  ..., -16.7963, -19.0364, -17.2946]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-21.3483, -14.2753, -17.1757,  ..., -16.3932, -21.2661, -18.5778],\n",
      "         [-14.2111, -16.5254, -17.6083,  ..., -18.8035, -19.4479, -18.2944],\n",
      "         [-21.9180, -18.9298, -19.6101,  ..., -19.6042, -17.8177, -17.0610],\n",
      "         ...,\n",
      "         [-19.8838, -17.4417, -20.7000,  ..., -16.4852, -18.6506, -21.1317],\n",
      "         [-18.6247, -17.8768, -17.1822,  ..., -17.6037, -16.4723, -17.9834],\n",
      "         [-18.0333, -16.9288, -17.9519,  ..., -18.5755, -15.8278, -18.7645]],\n",
      "\n",
      "        [[-18.7815, -18.1024, -20.3064,  ..., -21.3351, -17.4987, -18.3942],\n",
      "         [-17.7924, -18.3239, -18.0451,  ..., -15.7836, -18.9595, -17.5978],\n",
      "         [-17.9662, -20.0608, -23.1270,  ..., -20.1834, -17.3781, -15.4092],\n",
      "         ...,\n",
      "         [-16.2191, -21.4108, -17.0815,  ..., -17.1771, -15.8353, -17.5721],\n",
      "         [-18.9348, -20.2593, -14.4023,  ..., -18.1926, -20.4259, -18.7074],\n",
      "         [-17.1156, -16.9155, -17.4652,  ..., -17.6983, -14.7368, -18.8139]],\n",
      "\n",
      "        [[-19.4982, -15.6448, -18.4304,  ..., -15.9318, -21.6446, -14.4082],\n",
      "         [-19.3027, -19.4291, -20.9339,  ..., -17.3564, -19.4923, -18.7391],\n",
      "         [-17.7841, -18.7236, -15.4019,  ..., -21.0484, -17.8797, -19.3316],\n",
      "         ...,\n",
      "         [-19.5089, -19.2173, -18.3993,  ..., -18.7601, -18.2608, -19.1187],\n",
      "         [-16.5046, -17.3731, -19.7449,  ..., -14.2946, -20.6041, -17.1585],\n",
      "         [-16.2748, -17.0360, -17.0972,  ..., -19.6367, -18.8092, -18.7274]]],\n",
      "       grad_fn=<SumBackward1>)\n",
      "TorchSumLayer:\n",
      "                       Input shape: torch.Size([32, 1, 64, 512])\n",
      "                       Input: tensor([[[[-18.9442, -16.4758, -14.4405,  ..., -18.5695, -17.9787, -20.0571],\n",
      "          [-17.5570, -15.9536, -16.5203,  ..., -16.9974, -19.0082, -19.0821],\n",
      "          [-16.7306, -13.9448, -19.3313,  ..., -18.5812, -19.1592, -16.0857],\n",
      "          ...,\n",
      "          [-16.3030, -18.4427, -19.0792,  ..., -19.2323, -17.2974, -18.9263],\n",
      "          [-18.5200, -15.7898, -18.1298,  ..., -17.5871, -16.8739, -15.3201],\n",
      "          [-15.0714, -18.0441, -17.4583,  ..., -18.3741, -19.1867, -20.4178]]],\n",
      "\n",
      "\n",
      "        [[[-18.9442, -16.4758, -14.4405,  ..., -18.5695, -17.9787, -20.0571],\n",
      "          [-17.5570, -15.9536, -16.5203,  ..., -16.9974, -19.0082, -19.0821],\n",
      "          [-16.7306, -13.9448, -19.3313,  ..., -18.5812, -19.1592, -16.0857],\n",
      "          ...,\n",
      "          [-16.3030, -18.4427, -19.0792,  ..., -19.2323, -17.2974, -18.9263],\n",
      "          [-18.5200, -15.7898, -18.1298,  ..., -17.5871, -16.8739, -15.3201],\n",
      "          [-15.0714, -18.0441, -17.4583,  ..., -18.3741, -19.1867, -20.4178]]],\n",
      "\n",
      "\n",
      "        [[[-16.0591, -17.2255, -16.9584,  ..., -16.6488, -18.6590, -18.4002],\n",
      "          [-17.6068, -19.3107, -18.4385,  ..., -19.1518, -15.8297, -19.7699],\n",
      "          [-15.7118, -13.9436, -15.2182,  ..., -18.0565, -16.4052, -20.1884],\n",
      "          ...,\n",
      "          [-17.7182, -19.1611, -16.2227,  ..., -17.0214, -19.7116, -14.4488],\n",
      "          [-18.0796, -17.8883, -13.9588,  ..., -17.4797, -17.4302, -18.9089],\n",
      "          [-20.6371, -18.4675, -18.8088,  ..., -20.5585, -20.3122, -20.1147]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-18.7815, -18.1024, -20.3064,  ..., -21.3351, -17.4987, -18.3942],\n",
      "          [-17.7924, -18.3239, -18.0451,  ..., -15.7836, -18.9595, -17.5978],\n",
      "          [-17.9662, -20.0608, -23.1270,  ..., -20.1834, -17.3781, -15.4092],\n",
      "          ...,\n",
      "          [-16.2191, -21.4108, -17.0815,  ..., -17.1771, -15.8353, -17.5721],\n",
      "          [-18.9348, -20.2593, -14.4023,  ..., -18.1926, -20.4259, -18.7074],\n",
      "          [-17.1156, -16.9155, -17.4652,  ..., -17.6983, -14.7368, -18.8139]]],\n",
      "\n",
      "\n",
      "        [[[-19.4982, -15.6448, -18.4304,  ..., -15.9318, -21.6446, -14.4082],\n",
      "          [-19.3027, -19.4291, -20.9339,  ..., -17.3564, -19.4923, -18.7391],\n",
      "          [-17.7841, -18.7236, -15.4019,  ..., -21.0484, -17.8797, -19.3316],\n",
      "          ...,\n",
      "          [-19.5089, -19.2173, -18.3993,  ..., -18.7601, -18.2608, -19.1187],\n",
      "          [-16.5046, -17.3731, -19.7449,  ..., -14.2946, -20.6041, -17.1585],\n",
      "          [-16.2748, -17.0360, -17.0972,  ..., -19.6367, -18.8092, -18.7274]]],\n",
      "\n",
      "\n",
      "        [[[-19.4982, -15.6448, -18.4304,  ..., -15.9318, -21.6446, -14.4082],\n",
      "          [-19.3027, -19.4291, -20.9339,  ..., -17.3564, -19.4923, -18.7391],\n",
      "          [-17.7841, -18.7236, -15.4019,  ..., -21.0484, -17.8797, -19.3316],\n",
      "          ...,\n",
      "          [-19.5089, -19.2173, -18.3993,  ..., -18.7601, -18.2608, -19.1187],\n",
      "          [-16.5046, -17.3731, -19.7449,  ..., -14.2946, -20.6041, -17.1585],\n",
      "          [-16.2748, -17.0360, -17.0972,  ..., -19.6367, -18.8092, -18.7274]]]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([32, 64, 512])):  tensor([[[-16.8887, -16.9886, -16.8436,  ..., -16.2831, -16.7837, -16.8963],\n",
      "         [-16.9270, -17.0047, -16.9943,  ..., -16.7523, -17.1929, -16.4103],\n",
      "         [-16.9509, -16.9597, -16.7044,  ..., -16.9666, -16.8786, -16.9693],\n",
      "         ...,\n",
      "         [-16.3846, -16.2573, -16.5904,  ..., -16.3136, -16.4489, -16.1131],\n",
      "         [-16.0908, -16.6197, -16.5928,  ..., -16.4010, -16.5296, -16.4986],\n",
      "         [-16.5775, -16.5691, -16.8298,  ..., -16.4870, -16.6392, -16.5962]],\n",
      "\n",
      "        [[-16.8685, -16.8811, -16.8729,  ..., -16.8766, -16.7665, -16.8225],\n",
      "         [-16.9331, -16.6942, -16.8306,  ..., -16.8880, -16.9294, -16.9809],\n",
      "         [-16.8535, -17.1126, -16.7815,  ..., -16.9016, -16.7640, -16.9508],\n",
      "         ...,\n",
      "         [-16.6328, -15.5187, -16.1941,  ..., -15.9616, -16.5660, -16.0147],\n",
      "         [-16.5286, -16.5411, -16.7398,  ..., -16.4839, -16.3821, -16.4355],\n",
      "         [-16.4714, -16.6986, -16.5775,  ..., -16.7749, -16.6503, -16.6151]],\n",
      "\n",
      "        [[-16.3249, -15.7576, -15.7651,  ..., -15.4728, -16.3519, -16.3011],\n",
      "         [-16.3893, -16.7262, -16.8340,  ..., -16.6102, -16.7030, -16.5418],\n",
      "         [-16.8635, -16.9801, -16.9389,  ..., -16.4724, -16.8362, -16.7096],\n",
      "         ...,\n",
      "         [-16.8283, -16.7356, -16.7149,  ..., -17.0460, -16.8580, -16.7658],\n",
      "         [-16.7484, -16.5519, -16.4793,  ..., -16.8418, -16.3363, -16.6221],\n",
      "         [-16.5334, -16.7411, -16.5258,  ..., -16.4124, -16.4802, -16.4439]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-16.8355, -16.7111, -16.6372,  ..., -16.8036, -16.1840, -16.6292],\n",
      "         [-17.1130, -16.8331, -16.9296,  ..., -17.0060, -16.9391, -17.0561],\n",
      "         [-17.0806, -17.2365, -17.1555,  ..., -16.8484, -16.9647, -16.9723],\n",
      "         ...,\n",
      "         [-16.6441, -16.0825, -16.4249,  ..., -16.7307, -16.5578, -16.0917],\n",
      "         [-16.7728, -16.4879, -16.8513,  ..., -16.6270, -16.6174, -16.8979],\n",
      "         [-16.4512, -16.6302, -16.4602,  ..., -16.3890, -16.6278, -16.6150]],\n",
      "\n",
      "        [[-16.6414, -16.6600, -16.2677,  ..., -16.6962, -16.6090, -16.6552],\n",
      "         [-16.8729, -16.4757, -16.9053,  ..., -16.9206, -17.1114, -16.9871],\n",
      "         [-16.7369, -16.2738, -16.5785,  ..., -16.6790, -16.5115, -16.4469],\n",
      "         ...,\n",
      "         [-16.9343, -16.5093, -16.7986,  ..., -16.8983, -17.1235, -17.1290],\n",
      "         [-16.7848, -17.0128, -16.8809,  ..., -16.3257, -16.7641, -16.7285],\n",
      "         [-16.6166, -16.5731, -16.5655,  ..., -16.6347, -16.5037, -16.1953]],\n",
      "\n",
      "        [[-16.7143, -16.7511, -16.7643,  ..., -16.5628, -16.6606, -16.5147],\n",
      "         [-16.3067, -17.0056, -16.7174,  ..., -16.9995, -16.9657, -16.8099],\n",
      "         [-16.5593, -16.9234, -16.3021,  ..., -16.6575, -16.4570, -16.4099],\n",
      "         ...,\n",
      "         [-16.8397, -16.5744, -17.0291,  ..., -17.0675, -16.9242, -16.8210],\n",
      "         [-16.3987, -16.5431, -16.6770,  ..., -16.3977, -16.7740, -16.6649],\n",
      "         [-16.5014, -16.7472, -16.5266,  ..., -16.4693, -16.5045, -16.2769]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "TorchCPTLayer:\n",
      "                       Input shape: torch.Size([16, 2, 64, 512])\n",
      "                       Input: tensor([[[[-16.8887, -16.9886, -16.8436,  ..., -16.2831, -16.7837, -16.8963],\n",
      "          [-16.9270, -17.0047, -16.9943,  ..., -16.7523, -17.1929, -16.4103],\n",
      "          [-16.9509, -16.9597, -16.7044,  ..., -16.9666, -16.8786, -16.9693],\n",
      "          ...,\n",
      "          [-16.3846, -16.2573, -16.5904,  ..., -16.3136, -16.4489, -16.1131],\n",
      "          [-16.0908, -16.6197, -16.5928,  ..., -16.4010, -16.5296, -16.4986],\n",
      "          [-16.5775, -16.5691, -16.8298,  ..., -16.4870, -16.6392, -16.5962]],\n",
      "\n",
      "         [[-16.3249, -15.7576, -15.7651,  ..., -15.4728, -16.3519, -16.3011],\n",
      "          [-16.3893, -16.7262, -16.8340,  ..., -16.6102, -16.7030, -16.5418],\n",
      "          [-16.8635, -16.9801, -16.9389,  ..., -16.4724, -16.8362, -16.7096],\n",
      "          ...,\n",
      "          [-16.8283, -16.7356, -16.7149,  ..., -17.0460, -16.8580, -16.7658],\n",
      "          [-16.7484, -16.5519, -16.4793,  ..., -16.8418, -16.3363, -16.6221],\n",
      "          [-16.5334, -16.7411, -16.5258,  ..., -16.4124, -16.4802, -16.4439]]],\n",
      "\n",
      "\n",
      "        [[[-16.8291, -17.0357, -16.7291,  ..., -16.6806, -16.7576, -16.9804],\n",
      "          [-16.9322, -16.9611, -16.8491,  ..., -17.1082, -16.9100, -16.9818],\n",
      "          [-16.6856, -17.0336, -16.6974,  ..., -16.7822, -16.7880, -17.0631],\n",
      "          ...,\n",
      "          [-16.4728, -16.8774, -16.6779,  ..., -16.9509, -16.7699, -16.7997],\n",
      "          [-16.4579, -16.4983, -16.6343,  ..., -16.7425, -16.2869, -16.5615],\n",
      "          [-16.7240, -16.6530, -16.6931,  ..., -16.6013, -16.6093, -16.7033]],\n",
      "\n",
      "         [[-16.2860, -16.6668, -16.6555,  ..., -16.4785, -16.7010, -16.6836],\n",
      "          [-16.7910, -16.6710, -16.9350,  ..., -16.7552, -16.8855, -16.8749],\n",
      "          [-17.0359, -17.1014, -16.9779,  ..., -16.9897, -16.9420, -17.0031],\n",
      "          ...,\n",
      "          [-16.4886, -16.2377, -16.2035,  ..., -16.2114, -16.7921, -16.0885],\n",
      "          [-16.4670, -15.8523, -16.4842,  ..., -16.5907, -16.2858, -16.5493],\n",
      "          [-16.5072, -16.5352, -16.5763,  ..., -16.5756, -16.3394, -16.7244]]],\n",
      "\n",
      "\n",
      "        [[[-16.8685, -16.8811, -16.8729,  ..., -16.8766, -16.7665, -16.8225],\n",
      "          [-16.9331, -16.6942, -16.8306,  ..., -16.8880, -16.9294, -16.9809],\n",
      "          [-16.8535, -17.1126, -16.7815,  ..., -16.9016, -16.7640, -16.9508],\n",
      "          ...,\n",
      "          [-16.6328, -15.5187, -16.1941,  ..., -15.9616, -16.5660, -16.0147],\n",
      "          [-16.5286, -16.5411, -16.7398,  ..., -16.4839, -16.3821, -16.4355],\n",
      "          [-16.4714, -16.6986, -16.5775,  ..., -16.7749, -16.6503, -16.6151]],\n",
      "\n",
      "         [[-16.6448, -16.9069, -16.8477,  ..., -16.8702, -16.9077, -16.9759],\n",
      "          [-16.2901, -16.1674, -16.4903,  ..., -16.2134, -16.5453, -16.5254],\n",
      "          [-16.8105, -16.8063, -17.0674,  ..., -16.8651, -17.0026, -16.8458],\n",
      "          ...,\n",
      "          [-16.4547, -16.4586, -16.4738,  ..., -16.0785, -16.6599, -16.4984],\n",
      "          [-16.5936, -16.2687, -16.7674,  ..., -16.5654, -16.1471, -16.4101],\n",
      "          [-16.8996, -16.6632, -16.7046,  ..., -16.9243, -16.6764, -16.9003]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-16.5699, -16.8590, -16.5471,  ..., -16.8874, -16.6340, -16.8982],\n",
      "          [-16.5963, -16.5354, -16.5998,  ..., -16.6135, -16.7332, -16.6525],\n",
      "          [-16.6419, -16.6906, -16.7609,  ..., -16.8720, -16.8201, -16.7192],\n",
      "          ...,\n",
      "          [-16.5327, -16.7474, -16.6691,  ..., -16.6318, -16.8361, -16.8925],\n",
      "          [-16.7245, -16.8799, -16.8706,  ..., -16.9643, -16.7644, -16.5444],\n",
      "          [-16.0953, -16.5181, -16.4588,  ..., -16.6878, -16.6396, -16.5049]],\n",
      "\n",
      "         [[-16.8278, -16.7924, -16.5799,  ..., -16.7384, -16.7924, -16.5959],\n",
      "          [-16.6663, -16.9692, -17.0309,  ..., -17.0368, -17.0222, -17.0441],\n",
      "          [-17.1495, -16.9993, -16.9483,  ..., -16.9496, -17.0817, -16.8508],\n",
      "          ...,\n",
      "          [-16.2565, -16.3798, -16.4136,  ..., -16.2287, -16.5325, -16.2559],\n",
      "          [-16.7450, -16.7433, -16.6015,  ..., -16.4390, -16.5457, -16.5936],\n",
      "          [-16.4760, -16.3815, -16.6456,  ..., -16.6411, -16.4376, -16.7410]]],\n",
      "\n",
      "\n",
      "        [[[-16.8355, -16.7111, -16.6372,  ..., -16.8036, -16.1840, -16.6292],\n",
      "          [-17.1130, -16.8331, -16.9296,  ..., -17.0060, -16.9391, -17.0561],\n",
      "          [-17.0806, -17.2365, -17.1555,  ..., -16.8484, -16.9647, -16.9723],\n",
      "          ...,\n",
      "          [-16.6441, -16.0825, -16.4249,  ..., -16.7307, -16.5578, -16.0917],\n",
      "          [-16.7728, -16.4879, -16.8513,  ..., -16.6270, -16.6174, -16.8979],\n",
      "          [-16.4512, -16.6302, -16.4602,  ..., -16.3890, -16.6278, -16.6150]],\n",
      "\n",
      "         [[-16.6414, -16.6600, -16.2677,  ..., -16.6962, -16.6090, -16.6552],\n",
      "          [-16.8729, -16.4757, -16.9053,  ..., -16.9206, -17.1114, -16.9871],\n",
      "          [-16.7369, -16.2738, -16.5785,  ..., -16.6790, -16.5115, -16.4469],\n",
      "          ...,\n",
      "          [-16.9343, -16.5093, -16.7986,  ..., -16.8983, -17.1235, -17.1290],\n",
      "          [-16.7848, -17.0128, -16.8809,  ..., -16.3257, -16.7641, -16.7285],\n",
      "          [-16.6166, -16.5731, -16.5655,  ..., -16.6347, -16.5037, -16.1953]]],\n",
      "\n",
      "\n",
      "        [[[-16.7945, -16.7231, -16.7397,  ..., -16.7394, -16.7384, -16.7441],\n",
      "          [-16.7895, -16.6164, -16.6581,  ..., -16.5346, -16.4589, -16.8694],\n",
      "          [-16.4957, -16.6330, -16.6959,  ..., -16.7789, -16.7639, -16.6645],\n",
      "          ...,\n",
      "          [-16.7757, -16.6503, -16.6883,  ..., -16.5367, -16.6180, -16.6397],\n",
      "          [-16.0315, -16.7510, -16.6859,  ..., -16.6886, -16.8381, -16.5594],\n",
      "          [-16.7323, -16.6813, -16.6316,  ..., -16.7734, -16.4150, -16.8991]],\n",
      "\n",
      "         [[-16.7143, -16.7511, -16.7643,  ..., -16.5628, -16.6606, -16.5147],\n",
      "          [-16.3067, -17.0056, -16.7174,  ..., -16.9995, -16.9657, -16.8099],\n",
      "          [-16.5593, -16.9234, -16.3021,  ..., -16.6575, -16.4570, -16.4099],\n",
      "          ...,\n",
      "          [-16.8397, -16.5744, -17.0291,  ..., -17.0675, -16.9242, -16.8210],\n",
      "          [-16.3987, -16.5431, -16.6770,  ..., -16.3977, -16.7740, -16.6649],\n",
      "          [-16.5014, -16.7472, -16.5266,  ..., -16.4693, -16.5045, -16.2769]]]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([16, 64, 512])):  tensor([[[-32.7722, -32.8020, -32.7953,  ..., -32.8033, -32.8096, -32.8106],\n",
      "         [-33.5160, -33.5385, -33.5457,  ..., -33.5418, -33.5025, -33.5671],\n",
      "         [-33.6199, -33.6019, -33.5732,  ..., -33.5890, -33.5985, -33.6076],\n",
      "         ...,\n",
      "         [-32.9449, -32.9776, -32.9574,  ..., -32.9563, -32.9758, -32.9739],\n",
      "         [-33.0884, -33.0655, -33.1034,  ..., -33.0969, -33.0617, -33.0381],\n",
      "         [-33.0344, -33.0367, -33.0343,  ..., -33.0415, -33.0114, -33.0023]],\n",
      "\n",
      "        [[-33.4770, -33.5089, -33.4950,  ..., -33.4997, -33.4901, -33.4821],\n",
      "         [-33.7129, -33.7145, -33.6952,  ..., -33.6967, -33.6944, -33.7135],\n",
      "         [-33.7855, -33.7839, -33.8016,  ..., -33.7936, -33.7868, -33.7975],\n",
      "         ...,\n",
      "         [-32.9773, -32.9567, -32.9480,  ..., -32.9744, -32.9642, -32.9588],\n",
      "         [-32.9060, -32.8760, -32.9239,  ..., -32.9094, -32.9183, -32.9130],\n",
      "         [-32.9875, -33.0059, -33.0265,  ..., -32.9688, -33.0395, -32.9823]],\n",
      "\n",
      "        [[-33.5394, -33.5778, -33.5611,  ..., -33.5623, -33.5863, -33.5533],\n",
      "         [-33.1118, -33.1257, -33.1252,  ..., -33.1397, -33.0979, -33.1123],\n",
      "         [-33.6921, -33.7099, -33.6999,  ..., -33.7237, -33.7286, -33.7064],\n",
      "         ...,\n",
      "         [-32.7419, -32.7283, -32.7392,  ..., -32.7170, -32.7027, -32.7235],\n",
      "         [-32.9847, -32.9874, -32.9836,  ..., -32.9804, -32.9907, -33.0010],\n",
      "         [-33.3588, -33.3703, -33.3561,  ..., -33.3473, -33.3624, -33.3587]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-33.5110, -33.5211, -33.5116,  ..., -33.5093, -33.4933, -33.5328],\n",
      "         [-33.6019, -33.5973, -33.5864,  ..., -33.5810, -33.5930, -33.5719],\n",
      "         [-33.6933, -33.6836, -33.6936,  ..., -33.6946, -33.6847, -33.7058],\n",
      "         ...,\n",
      "         [-33.0427, -33.0545, -33.0675,  ..., -33.0179, -33.0479, -33.0225],\n",
      "         [-33.5040, -33.4898, -33.4975,  ..., -33.4881, -33.4992, -33.4983],\n",
      "         [-33.0382, -33.0549, -33.0447,  ..., -33.0721, -33.0375, -33.0684]],\n",
      "\n",
      "        [[-33.3432, -33.3069, -33.2843,  ..., -33.3154, -33.3172, -33.3003],\n",
      "         [-33.7904, -33.8043, -33.7833,  ..., -33.7744, -33.7930, -33.7942],\n",
      "         [-33.5754, -33.5754, -33.5639,  ..., -33.5673, -33.5899, -33.5827],\n",
      "         ...,\n",
      "         [-33.3507, -33.3859, -33.3459,  ..., -33.3515, -33.3782, -33.3891],\n",
      "         [-33.3345, -33.3490, -33.3231,  ..., -33.3244, -33.3177, -33.3191],\n",
      "         [-33.0924, -33.1024, -33.1028,  ..., -33.1042, -33.1043, -33.0867]],\n",
      "\n",
      "        [[-33.3304, -33.3148, -33.3018,  ..., -33.3095, -33.2570, -33.3150],\n",
      "         [-33.4706, -33.4541, -33.4507,  ..., -33.4584, -33.4774, -33.4479],\n",
      "         [-33.1847, -33.2050, -33.1983,  ..., -33.2091, -33.2022, -33.1831],\n",
      "         ...,\n",
      "         [-33.6474, -33.6110, -33.6441,  ..., -33.6531, -33.6255, -33.6458],\n",
      "         [-33.2612, -33.2473, -33.2405,  ..., -33.2343, -33.2286, -33.2643],\n",
      "         [-33.2565, -33.2753, -33.2598,  ..., -33.2706, -33.2649, -33.2770]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "TorchHadamardLayer:\n",
      "                       Input shape: torch.Size([8, 2, 64, 512])\n",
      "                       Input: tensor([[[[-32.7722, -32.8020, -32.7953,  ..., -32.8033, -32.8096, -32.8106],\n",
      "          [-33.5160, -33.5385, -33.5457,  ..., -33.5418, -33.5025, -33.5671],\n",
      "          [-33.6199, -33.6019, -33.5732,  ..., -33.5890, -33.5985, -33.6076],\n",
      "          ...,\n",
      "          [-32.9449, -32.9776, -32.9574,  ..., -32.9563, -32.9758, -32.9739],\n",
      "          [-33.0884, -33.0655, -33.1034,  ..., -33.0969, -33.0617, -33.0381],\n",
      "          [-33.0344, -33.0367, -33.0343,  ..., -33.0415, -33.0114, -33.0023]],\n",
      "\n",
      "         [[-33.4585, -33.4515, -33.4591,  ..., -33.4786, -33.4394, -33.4515],\n",
      "          [-33.0196, -33.0534, -33.0246,  ..., -33.0046, -33.0088, -33.0226],\n",
      "          [-33.5027, -33.5305, -33.5103,  ..., -33.4961, -33.5046, -33.5187],\n",
      "          ...,\n",
      "          [-33.2169, -33.2038, -33.2299,  ..., -33.1753, -33.2223, -33.1825],\n",
      "          [-33.2063, -33.1906, -33.1940,  ..., -33.1750, -33.2079, -33.2080],\n",
      "          [-33.5845, -33.6010, -33.6045,  ..., -33.5932, -33.5945, -33.6000]]],\n",
      "\n",
      "\n",
      "        [[[-33.5394, -33.5778, -33.5611,  ..., -33.5623, -33.5863, -33.5533],\n",
      "          [-33.1118, -33.1257, -33.1252,  ..., -33.1397, -33.0979, -33.1123],\n",
      "          [-33.6921, -33.7099, -33.6999,  ..., -33.7237, -33.7286, -33.7064],\n",
      "          ...,\n",
      "          [-32.7419, -32.7283, -32.7392,  ..., -32.7170, -32.7027, -32.7235],\n",
      "          [-32.9847, -32.9874, -32.9836,  ..., -32.9804, -32.9907, -33.0010],\n",
      "          [-33.3588, -33.3703, -33.3561,  ..., -33.3473, -33.3624, -33.3587]],\n",
      "\n",
      "         [[-32.6672, -32.6662, -32.6203,  ..., -32.6690, -32.6749, -32.7238],\n",
      "          [-33.4064, -33.4211, -33.4125,  ..., -33.4130, -33.3934, -33.3985],\n",
      "          [-33.3690, -33.3621, -33.3852,  ..., -33.3673, -33.3586, -33.3597],\n",
      "          ...,\n",
      "          [-33.4900, -33.4963, -33.4877,  ..., -33.4502, -33.4851, -33.4738],\n",
      "          [-33.2473, -33.2969, -33.2769,  ..., -33.2588, -33.2929, -33.2700],\n",
      "          [-33.2617, -33.2567, -33.2648,  ..., -33.2745, -33.2673, -33.2477]]],\n",
      "\n",
      "\n",
      "        [[[-33.4770, -33.5089, -33.4950,  ..., -33.4997, -33.4901, -33.4821],\n",
      "          [-33.7129, -33.7145, -33.6952,  ..., -33.6967, -33.6944, -33.7135],\n",
      "          [-33.7855, -33.7839, -33.8016,  ..., -33.7936, -33.7868, -33.7975],\n",
      "          ...,\n",
      "          [-32.9773, -32.9567, -32.9480,  ..., -32.9744, -32.9642, -32.9588],\n",
      "          [-32.9060, -32.8760, -32.9239,  ..., -32.9094, -32.9183, -32.9130],\n",
      "          [-32.9875, -33.0059, -33.0265,  ..., -32.9688, -33.0395, -32.9823]],\n",
      "\n",
      "         [[-33.4955, -33.4915, -33.4548,  ..., -33.4763, -33.4961, -33.5152],\n",
      "          [-33.0977, -33.1218, -33.0931,  ..., -33.1646, -33.1337, -33.1380],\n",
      "          [-33.5314, -33.5315, -33.5385,  ..., -33.5300, -33.5341, -33.5251],\n",
      "          ...,\n",
      "          [-33.4174, -33.4220, -33.3902,  ..., -33.3965, -33.3960, -33.3959],\n",
      "          [-33.4314, -33.4394, -33.4352,  ..., -33.4468, -33.4352, -33.4324],\n",
      "          [-33.6333, -33.6392, -33.6122,  ..., -33.6209, -33.6294, -33.6310]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-32.9404, -32.9322, -32.9075,  ..., -32.9110, -32.9184, -32.8855],\n",
      "          [-33.2585, -33.2317, -33.2504,  ..., -33.2362, -33.2169, -33.2239],\n",
      "          [-33.6388, -33.6316, -33.6481,  ..., -33.6493, -33.6417, -33.6315],\n",
      "          ...,\n",
      "          [-33.2137, -33.1898, -33.1859,  ..., -33.2194, -33.1929, -33.1794],\n",
      "          [-33.6466, -33.6882, -33.6659,  ..., -33.6574, -33.6675, -33.6652],\n",
      "          [-33.2914, -33.2792, -33.2755,  ..., -33.2652, -33.2631, -33.3000]],\n",
      "\n",
      "         [[-33.1365, -33.1197, -33.1306,  ..., -33.1085, -33.1414, -33.1380],\n",
      "          [-33.2554, -33.2532, -33.2354,  ..., -33.2436, -33.2387, -33.2507],\n",
      "          [-33.1023, -33.1028, -33.0842,  ..., -33.0863, -33.0872, -33.1012],\n",
      "          ...,\n",
      "          [-33.0356, -33.0306, -33.0410,  ..., -33.0282, -33.0260, -32.9966],\n",
      "          [-33.3073, -33.3365, -33.3437,  ..., -33.3515, -33.3356, -33.3567],\n",
      "          [-33.2643, -33.2555, -33.2393,  ..., -33.2572, -33.2461, -33.2582]]],\n",
      "\n",
      "\n",
      "        [[[-33.4962, -33.5061, -33.5187,  ..., -33.5059, -33.5197, -33.5092],\n",
      "          [-33.2141, -33.2363, -33.2351,  ..., -33.2211, -33.2270, -33.1930],\n",
      "          [-33.3086, -33.3254, -33.3343,  ..., -33.2931, -33.3043, -33.2897],\n",
      "          ...,\n",
      "          [-33.3039, -33.3172, -33.3393,  ..., -33.3419, -33.3271, -33.3255],\n",
      "          [-33.3962, -33.4435, -33.3551,  ..., -33.3729, -33.4161, -33.4285],\n",
      "          [-33.2247, -33.2527, -33.2528,  ..., -33.2441, -33.2268, -33.2442]],\n",
      "\n",
      "         [[-33.3432, -33.3069, -33.2843,  ..., -33.3154, -33.3172, -33.3003],\n",
      "          [-33.7904, -33.8043, -33.7833,  ..., -33.7744, -33.7930, -33.7942],\n",
      "          [-33.5754, -33.5754, -33.5639,  ..., -33.5673, -33.5899, -33.5827],\n",
      "          ...,\n",
      "          [-33.3507, -33.3859, -33.3459,  ..., -33.3515, -33.3782, -33.3891],\n",
      "          [-33.3345, -33.3490, -33.3231,  ..., -33.3244, -33.3177, -33.3191],\n",
      "          [-33.0924, -33.1024, -33.1028,  ..., -33.1042, -33.1043, -33.0867]]],\n",
      "\n",
      "\n",
      "        [[[-33.5110, -33.5211, -33.5116,  ..., -33.5093, -33.4933, -33.5328],\n",
      "          [-33.6019, -33.5973, -33.5864,  ..., -33.5810, -33.5930, -33.5719],\n",
      "          [-33.6933, -33.6836, -33.6936,  ..., -33.6946, -33.6847, -33.7058],\n",
      "          ...,\n",
      "          [-33.0427, -33.0545, -33.0675,  ..., -33.0179, -33.0479, -33.0225],\n",
      "          [-33.5040, -33.4898, -33.4975,  ..., -33.4881, -33.4992, -33.4983],\n",
      "          [-33.0382, -33.0549, -33.0447,  ..., -33.0721, -33.0375, -33.0684]],\n",
      "\n",
      "         [[-33.3304, -33.3148, -33.3018,  ..., -33.3095, -33.2570, -33.3150],\n",
      "          [-33.4706, -33.4541, -33.4507,  ..., -33.4584, -33.4774, -33.4479],\n",
      "          [-33.1847, -33.2050, -33.1983,  ..., -33.2091, -33.2022, -33.1831],\n",
      "          ...,\n",
      "          [-33.6474, -33.6110, -33.6441,  ..., -33.6531, -33.6255, -33.6458],\n",
      "          [-33.2612, -33.2473, -33.2405,  ..., -33.2343, -33.2286, -33.2643],\n",
      "          [-33.2565, -33.2753, -33.2598,  ..., -33.2706, -33.2649, -33.2770]]]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([8, 64, 512])):  tensor([[[-66.2307, -66.2534, -66.2543,  ..., -66.2818, -66.2490, -66.2622],\n",
      "         [-66.5356, -66.5919, -66.5702,  ..., -66.5465, -66.5112, -66.5897],\n",
      "         [-67.1227, -67.1324, -67.0835,  ..., -67.0851, -67.1031, -67.1262],\n",
      "         ...,\n",
      "         [-66.1618, -66.1815, -66.1873,  ..., -66.1316, -66.1980, -66.1564],\n",
      "         [-66.2946, -66.2561, -66.2974,  ..., -66.2720, -66.2697, -66.2461],\n",
      "         [-66.6190, -66.6377, -66.6388,  ..., -66.6347, -66.6059, -66.6022]],\n",
      "\n",
      "        [[-66.2066, -66.2441, -66.1814,  ..., -66.2313, -66.2612, -66.2771],\n",
      "         [-66.5182, -66.5468, -66.5376,  ..., -66.5528, -66.4913, -66.5107],\n",
      "         [-67.0611, -67.0720, -67.0851,  ..., -67.0910, -67.0872, -67.0661],\n",
      "         ...,\n",
      "         [-66.2319, -66.2246, -66.2270,  ..., -66.1672, -66.1878, -66.1973],\n",
      "         [-66.2319, -66.2843, -66.2605,  ..., -66.2392, -66.2836, -66.2710],\n",
      "         [-66.6205, -66.6270, -66.6210,  ..., -66.6217, -66.6298, -66.6064]],\n",
      "\n",
      "        [[-66.9725, -67.0005, -66.9497,  ..., -66.9760, -66.9863, -66.9973],\n",
      "         [-66.8106, -66.8363, -66.7883,  ..., -66.8614, -66.8281, -66.8515],\n",
      "         [-67.3168, -67.3154, -67.3401,  ..., -67.3236, -67.3210, -67.3226],\n",
      "         ...,\n",
      "         [-66.3947, -66.3787, -66.3382,  ..., -66.3709, -66.3602, -66.3547],\n",
      "         [-66.3373, -66.3153, -66.3591,  ..., -66.3561, -66.3534, -66.3454],\n",
      "         [-66.6208, -66.6450, -66.6387,  ..., -66.5897, -66.6689, -66.6133]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-66.0768, -66.0519, -66.0381,  ..., -66.0195, -66.0597, -66.0235],\n",
      "         [-66.5139, -66.4849, -66.4858,  ..., -66.4798, -66.4556, -66.4746],\n",
      "         [-66.7410, -66.7344, -66.7323,  ..., -66.7356, -66.7288, -66.7327],\n",
      "         ...,\n",
      "         [-66.2493, -66.2203, -66.2270,  ..., -66.2476, -66.2190, -66.1761],\n",
      "         [-66.9539, -67.0247, -67.0096,  ..., -67.0089, -67.0032, -67.0219],\n",
      "         [-66.5557, -66.5347, -66.5148,  ..., -66.5223, -66.5092, -66.5582]],\n",
      "\n",
      "        [[-66.8393, -66.8131, -66.8030,  ..., -66.8213, -66.8370, -66.8096],\n",
      "         [-67.0045, -67.0406, -67.0184,  ..., -66.9954, -67.0201, -66.9872],\n",
      "         [-66.8840, -66.9008, -66.8982,  ..., -66.8604, -66.8943, -66.8724],\n",
      "         ...,\n",
      "         [-66.6546, -66.7032, -66.6851,  ..., -66.6934, -66.7053, -66.7146],\n",
      "         [-66.7307, -66.7925, -66.6782,  ..., -66.6972, -66.7339, -66.7477],\n",
      "         [-66.3171, -66.3551, -66.3556,  ..., -66.3483, -66.3311, -66.3309]],\n",
      "\n",
      "        [[-66.8414, -66.8359, -66.8134,  ..., -66.8189, -66.7503, -66.8478],\n",
      "         [-67.0724, -67.0515, -67.0371,  ..., -67.0393, -67.0704, -67.0199],\n",
      "         [-66.8780, -66.8885, -66.8919,  ..., -66.9037, -66.8869, -66.8889],\n",
      "         ...,\n",
      "         [-66.6901, -66.6655, -66.7116,  ..., -66.6710, -66.6734, -66.6683],\n",
      "         [-66.7652, -66.7372, -66.7380,  ..., -66.7224, -66.7278, -66.7626],\n",
      "         [-66.2947, -66.3302, -66.3044,  ..., -66.3427, -66.3024, -66.3454]]],\n",
      "       grad_fn=<SumBackward1>)\n",
      "TorchSumLayer:\n",
      "                       Input shape: torch.Size([4, 2, 64, 512])\n",
      "                       Input: tensor([[[[-66.2307, -66.2534, -66.2543,  ..., -66.2818, -66.2490, -66.2622],\n",
      "          [-66.5356, -66.5919, -66.5702,  ..., -66.5465, -66.5112, -66.5897],\n",
      "          [-67.1227, -67.1324, -67.0835,  ..., -67.0851, -67.1031, -67.1262],\n",
      "          ...,\n",
      "          [-66.1618, -66.1815, -66.1873,  ..., -66.1316, -66.1980, -66.1564],\n",
      "          [-66.2946, -66.2561, -66.2974,  ..., -66.2720, -66.2697, -66.2461],\n",
      "          [-66.6190, -66.6377, -66.6388,  ..., -66.6347, -66.6059, -66.6022]],\n",
      "\n",
      "         [[-66.2066, -66.2441, -66.1814,  ..., -66.2313, -66.2612, -66.2771],\n",
      "          [-66.5182, -66.5468, -66.5376,  ..., -66.5528, -66.4913, -66.5107],\n",
      "          [-67.0611, -67.0720, -67.0851,  ..., -67.0910, -67.0872, -67.0661],\n",
      "          ...,\n",
      "          [-66.2319, -66.2246, -66.2270,  ..., -66.1672, -66.1878, -66.1973],\n",
      "          [-66.2319, -66.2843, -66.2605,  ..., -66.2392, -66.2836, -66.2710],\n",
      "          [-66.6205, -66.6270, -66.6210,  ..., -66.6217, -66.6298, -66.6064]]],\n",
      "\n",
      "\n",
      "        [[[-66.9725, -67.0005, -66.9497,  ..., -66.9760, -66.9863, -66.9973],\n",
      "          [-66.8106, -66.8363, -66.7883,  ..., -66.8614, -66.8281, -66.8515],\n",
      "          [-67.3168, -67.3154, -67.3401,  ..., -67.3236, -67.3210, -67.3226],\n",
      "          ...,\n",
      "          [-66.3947, -66.3787, -66.3382,  ..., -66.3709, -66.3602, -66.3547],\n",
      "          [-66.3373, -66.3153, -66.3591,  ..., -66.3561, -66.3534, -66.3454],\n",
      "          [-66.6208, -66.6450, -66.6387,  ..., -66.5897, -66.6689, -66.6133]],\n",
      "\n",
      "         [[-67.0067, -67.0013, -67.0160,  ..., -66.9964, -66.9934, -66.9969],\n",
      "          [-66.8743, -66.8753, -66.8628,  ..., -66.8314, -66.8812, -66.8526],\n",
      "          [-67.3627, -67.3447, -67.3619,  ..., -67.3532, -67.3216, -67.3388],\n",
      "          ...,\n",
      "          [-66.4635, -66.4039, -66.4149,  ..., -66.4040, -66.4045, -66.3819],\n",
      "          [-66.3289, -66.3177, -66.2847,  ..., -66.2737, -66.3142, -66.3286],\n",
      "          [-66.6102, -66.6126, -66.6483,  ..., -66.6432, -66.6080, -66.6000]]],\n",
      "\n",
      "\n",
      "        [[[-66.0647, -66.0289, -66.0692,  ..., -66.0481, -66.0636, -66.0595],\n",
      "          [-66.4860, -66.4731, -66.4306,  ..., -66.4903, -66.4976, -66.4831],\n",
      "          [-66.7632, -66.7784, -66.6980,  ..., -66.7470, -66.7763, -66.7547],\n",
      "          ...,\n",
      "          [-66.3087, -66.2930, -66.2833,  ..., -66.2934, -66.2946, -66.2972],\n",
      "          [-67.0661, -67.0442, -67.0066,  ..., -67.0807, -67.0217, -67.0299],\n",
      "          [-66.5452, -66.5012, -66.5632,  ..., -66.5231, -66.5622, -66.5415]],\n",
      "\n",
      "         [[-66.0768, -66.0519, -66.0381,  ..., -66.0195, -66.0597, -66.0235],\n",
      "          [-66.5139, -66.4849, -66.4858,  ..., -66.4798, -66.4556, -66.4746],\n",
      "          [-66.7410, -66.7344, -66.7323,  ..., -66.7356, -66.7288, -66.7327],\n",
      "          ...,\n",
      "          [-66.2493, -66.2203, -66.2270,  ..., -66.2476, -66.2190, -66.1761],\n",
      "          [-66.9539, -67.0247, -67.0096,  ..., -67.0089, -67.0032, -67.0219],\n",
      "          [-66.5557, -66.5347, -66.5148,  ..., -66.5223, -66.5092, -66.5582]]],\n",
      "\n",
      "\n",
      "        [[[-66.8393, -66.8131, -66.8030,  ..., -66.8213, -66.8370, -66.8096],\n",
      "          [-67.0045, -67.0406, -67.0184,  ..., -66.9954, -67.0201, -66.9872],\n",
      "          [-66.8840, -66.9008, -66.8982,  ..., -66.8604, -66.8943, -66.8724],\n",
      "          ...,\n",
      "          [-66.6546, -66.7032, -66.6851,  ..., -66.6934, -66.7053, -66.7146],\n",
      "          [-66.7307, -66.7925, -66.6782,  ..., -66.6972, -66.7339, -66.7477],\n",
      "          [-66.3171, -66.3551, -66.3556,  ..., -66.3483, -66.3311, -66.3309]],\n",
      "\n",
      "         [[-66.8414, -66.8359, -66.8134,  ..., -66.8189, -66.7503, -66.8478],\n",
      "          [-67.0724, -67.0515, -67.0371,  ..., -67.0393, -67.0704, -67.0199],\n",
      "          [-66.8780, -66.8885, -66.8919,  ..., -66.9037, -66.8869, -66.8889],\n",
      "          ...,\n",
      "          [-66.6901, -66.6655, -66.7116,  ..., -66.6710, -66.6734, -66.6683],\n",
      "          [-66.7652, -66.7372, -66.7380,  ..., -66.7224, -66.7278, -66.7626],\n",
      "          [-66.2947, -66.3302, -66.3044,  ..., -66.3427, -66.3024, -66.3454]]]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([4, 64, 512])):  tensor([[[-66.2154, -66.2493, -66.2186,  ..., -66.2361, -66.2500, -66.2664],\n",
      "         [-66.5245, -66.5715, -66.5544,  ..., -66.5522, -66.5095, -66.5664],\n",
      "         [-67.0832, -67.1050, -67.0843,  ..., -67.0904, -67.1017, -67.1086],\n",
      "         ...,\n",
      "         [-66.2056, -66.2005, -66.2062,  ..., -66.1637, -66.1971, -66.1679],\n",
      "         [-66.2545, -66.2686, -66.2795,  ..., -66.2423, -66.2709, -66.2532],\n",
      "         [-66.6199, -66.6329, -66.6302,  ..., -66.6230, -66.6080, -66.6034]],\n",
      "\n",
      "        [[-66.9823, -67.0009, -66.9821,  ..., -66.9796, -66.9880, -66.9970],\n",
      "         [-66.8288, -66.8585, -66.8246,  ..., -66.8560, -66.8411, -66.8524],\n",
      "         [-67.3300, -67.3322, -67.3509,  ..., -67.3288, -67.3211, -67.3352],\n",
      "         ...,\n",
      "         [-66.4143, -66.3931, -66.3756,  ..., -66.3767, -66.3710, -66.3759],\n",
      "         [-66.3349, -66.3167, -66.3214,  ..., -66.3410, -66.3435, -66.3322],\n",
      "         [-66.6177, -66.6263, -66.6434,  ..., -66.5990, -66.6534, -66.6029]],\n",
      "\n",
      "        [[-66.0752, -66.0480, -66.0521,  ..., -66.0332, -66.0602, -66.0354],\n",
      "         [-66.5102, -66.4830, -66.4603,  ..., -66.4848, -66.4608, -66.4774],\n",
      "         [-66.7439, -66.7416, -66.7165,  ..., -66.7411, -66.7346, -66.7400],\n",
      "         ...,\n",
      "         [-66.2569, -66.2321, -66.2522,  ..., -66.2694, -66.2281, -66.2150],\n",
      "         [-66.9680, -67.0279, -67.0082,  ..., -67.0429, -67.0055, -67.0245],\n",
      "         [-66.5543, -66.5290, -66.5365,  ..., -66.5227, -66.5156, -66.5525]],\n",
      "\n",
      "        [[-66.8397, -66.8251, -66.8066,  ..., -66.8196, -66.7826, -66.8419],\n",
      "         [-67.0153, -67.0463, -67.0248,  ..., -67.0253, -67.0508, -67.0149],\n",
      "         [-66.8830, -66.8943, -66.8960,  ..., -66.8899, -66.8897, -66.8865],\n",
      "         ...,\n",
      "         [-66.6603, -66.6831, -66.6942,  ..., -66.6780, -66.6855, -66.6751],\n",
      "         [-66.7363, -66.7628, -66.6984,  ..., -66.7144, -66.7301, -66.7603],\n",
      "         [-66.3134, -66.3418, -66.3377,  ..., -66.3445, -66.3133, -66.3432]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "TorchSumLayer:\n",
      "                       Input shape: torch.Size([8, 1, 64, 512])\n",
      "                       Input: tensor([[[[-66.2154, -66.2493, -66.2186,  ..., -66.2361, -66.2500, -66.2664],\n",
      "          [-66.5245, -66.5715, -66.5544,  ..., -66.5522, -66.5095, -66.5664],\n",
      "          [-67.0832, -67.1050, -67.0843,  ..., -67.0904, -67.1017, -67.1086],\n",
      "          ...,\n",
      "          [-66.2056, -66.2005, -66.2062,  ..., -66.1637, -66.1971, -66.1679],\n",
      "          [-66.2545, -66.2686, -66.2795,  ..., -66.2423, -66.2709, -66.2532],\n",
      "          [-66.6199, -66.6329, -66.6302,  ..., -66.6230, -66.6080, -66.6034]]],\n",
      "\n",
      "\n",
      "        [[[-66.2154, -66.2493, -66.2186,  ..., -66.2361, -66.2500, -66.2664],\n",
      "          [-66.5245, -66.5715, -66.5544,  ..., -66.5522, -66.5095, -66.5664],\n",
      "          [-67.0832, -67.1050, -67.0843,  ..., -67.0904, -67.1017, -67.1086],\n",
      "          ...,\n",
      "          [-66.2056, -66.2005, -66.2062,  ..., -66.1637, -66.1971, -66.1679],\n",
      "          [-66.2545, -66.2686, -66.2795,  ..., -66.2423, -66.2709, -66.2532],\n",
      "          [-66.6199, -66.6329, -66.6302,  ..., -66.6230, -66.6080, -66.6034]]],\n",
      "\n",
      "\n",
      "        [[[-66.9823, -67.0009, -66.9821,  ..., -66.9796, -66.9880, -66.9970],\n",
      "          [-66.8288, -66.8585, -66.8246,  ..., -66.8560, -66.8411, -66.8524],\n",
      "          [-67.3300, -67.3322, -67.3509,  ..., -67.3288, -67.3211, -67.3352],\n",
      "          ...,\n",
      "          [-66.4143, -66.3931, -66.3756,  ..., -66.3767, -66.3710, -66.3759],\n",
      "          [-66.3349, -66.3167, -66.3214,  ..., -66.3410, -66.3435, -66.3322],\n",
      "          [-66.6177, -66.6263, -66.6434,  ..., -66.5990, -66.6534, -66.6029]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-66.0752, -66.0480, -66.0521,  ..., -66.0332, -66.0602, -66.0354],\n",
      "          [-66.5102, -66.4830, -66.4603,  ..., -66.4848, -66.4608, -66.4774],\n",
      "          [-66.7439, -66.7416, -66.7165,  ..., -66.7411, -66.7346, -66.7400],\n",
      "          ...,\n",
      "          [-66.2569, -66.2321, -66.2522,  ..., -66.2694, -66.2281, -66.2150],\n",
      "          [-66.9680, -67.0279, -67.0082,  ..., -67.0429, -67.0055, -67.0245],\n",
      "          [-66.5543, -66.5290, -66.5365,  ..., -66.5227, -66.5156, -66.5525]]],\n",
      "\n",
      "\n",
      "        [[[-66.8397, -66.8251, -66.8066,  ..., -66.8196, -66.7826, -66.8419],\n",
      "          [-67.0153, -67.0463, -67.0248,  ..., -67.0253, -67.0508, -67.0149],\n",
      "          [-66.8830, -66.8943, -66.8960,  ..., -66.8899, -66.8897, -66.8865],\n",
      "          ...,\n",
      "          [-66.6603, -66.6831, -66.6942,  ..., -66.6780, -66.6855, -66.6751],\n",
      "          [-66.7363, -66.7628, -66.6984,  ..., -66.7144, -66.7301, -66.7603],\n",
      "          [-66.3134, -66.3418, -66.3377,  ..., -66.3445, -66.3133, -66.3432]]],\n",
      "\n",
      "\n",
      "        [[[-66.8397, -66.8251, -66.8066,  ..., -66.8196, -66.7826, -66.8419],\n",
      "          [-67.0153, -67.0463, -67.0248,  ..., -67.0253, -67.0508, -67.0149],\n",
      "          [-66.8830, -66.8943, -66.8960,  ..., -66.8899, -66.8897, -66.8865],\n",
      "          ...,\n",
      "          [-66.6603, -66.6831, -66.6942,  ..., -66.6780, -66.6855, -66.6751],\n",
      "          [-66.7363, -66.7628, -66.6984,  ..., -66.7144, -66.7301, -66.7603],\n",
      "          [-66.3134, -66.3418, -66.3377,  ..., -66.3445, -66.3133, -66.3432]]]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([8, 64, 512])):  tensor([[[-66.2449, -66.2441, -66.2418,  ..., -66.2430, -66.2433, -66.2446],\n",
      "         [-66.5348, -66.5327, -66.5342,  ..., -66.5346, -66.5346, -66.5356],\n",
      "         [-67.0927, -67.0910, -67.0914,  ..., -67.0911, -67.0920, -67.0910],\n",
      "         ...,\n",
      "         [-66.1791, -66.1802, -66.1799,  ..., -66.1781, -66.1771, -66.1766],\n",
      "         [-66.2654, -66.2684, -66.2666,  ..., -66.2678, -66.2678, -66.2669],\n",
      "         [-66.6200, -66.6234, -66.6184,  ..., -66.6210, -66.6209, -66.6232]],\n",
      "\n",
      "        [[-66.2440, -66.2434, -66.2431,  ..., -66.2443, -66.2431, -66.2460],\n",
      "         [-66.5323, -66.5321, -66.5347,  ..., -66.5345, -66.5343, -66.5327],\n",
      "         [-67.0919, -67.0923, -67.0910,  ..., -67.0927, -67.0915, -67.0922],\n",
      "         ...,\n",
      "         [-66.1781, -66.1798, -66.1796,  ..., -66.1777, -66.1798, -66.1771],\n",
      "         [-66.2678, -66.2669, -66.2669,  ..., -66.2652, -66.2662, -66.2670],\n",
      "         [-66.6220, -66.6202, -66.6233,  ..., -66.6201, -66.6217, -66.6197]],\n",
      "\n",
      "        [[-66.9880, -66.9885, -66.9872,  ..., -66.9872, -66.9873, -66.9878],\n",
      "         [-66.8476, -66.8477, -66.8472,  ..., -66.8460, -66.8477, -66.8458],\n",
      "         [-67.3313, -67.3306, -67.3312,  ..., -67.3306, -67.3310, -67.3319],\n",
      "         ...,\n",
      "         [-66.3818, -66.3820, -66.3808,  ..., -66.3806, -66.3845, -66.3804],\n",
      "         [-66.3266, -66.3294, -66.3308,  ..., -66.3283, -66.3304, -66.3288],\n",
      "         [-66.6338, -66.6331, -66.6335,  ..., -66.6309, -66.6315, -66.6342]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-66.0572, -66.0549, -66.0563,  ..., -66.0557, -66.0575, -66.0544],\n",
      "         [-66.4769, -66.4763, -66.4774,  ..., -66.4758, -66.4764, -66.4764],\n",
      "         [-66.7445, -66.7426, -66.7431,  ..., -66.7425, -66.7437, -66.7429],\n",
      "         ...,\n",
      "         [-66.2583, -66.2597, -66.2563,  ..., -66.2539, -66.2582, -66.2572],\n",
      "         [-67.0260, -67.0259, -67.0254,  ..., -67.0241, -67.0254, -67.0246],\n",
      "         [-66.5317, -66.5299, -66.5297,  ..., -66.5318, -66.5312, -66.5301]],\n",
      "\n",
      "        [[-66.8258, -66.8249, -66.8246,  ..., -66.8243, -66.8236, -66.8266],\n",
      "         [-67.0335, -67.0347, -67.0350,  ..., -67.0343, -67.0341, -67.0359],\n",
      "         [-66.8821, -66.8840, -66.8841,  ..., -66.8824, -66.8844, -66.8830],\n",
      "         ...,\n",
      "         [-66.6914, -66.6904, -66.6915,  ..., -66.6912, -66.6913, -66.6913],\n",
      "         [-66.7376, -66.7363, -66.7369,  ..., -66.7334, -66.7365, -66.7365],\n",
      "         [-66.3177, -66.3180, -66.3201,  ..., -66.3208, -66.3202, -66.3189]],\n",
      "\n",
      "        [[-66.8244, -66.8254, -66.8246,  ..., -66.8242, -66.8248, -66.8253],\n",
      "         [-67.0339, -67.0358, -67.0350,  ..., -67.0361, -67.0343, -67.0359],\n",
      "         [-66.8824, -66.8837, -66.8835,  ..., -66.8831, -66.8833, -66.8818],\n",
      "         ...,\n",
      "         [-66.6909, -66.6911, -66.6917,  ..., -66.6881, -66.6902, -66.6920],\n",
      "         [-66.7323, -66.7338, -66.7343,  ..., -66.7334, -66.7375, -66.7359],\n",
      "         [-66.3188, -66.3203, -66.3183,  ..., -66.3198, -66.3202, -66.3200]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "TorchCPTLayer:\n",
      "                       Input shape: torch.Size([4, 2, 64, 512])\n",
      "                       Input: tensor([[[[-66.2449, -66.2441, -66.2418,  ..., -66.2430, -66.2433, -66.2446],\n",
      "          [-66.5348, -66.5327, -66.5342,  ..., -66.5346, -66.5346, -66.5356],\n",
      "          [-67.0927, -67.0910, -67.0914,  ..., -67.0911, -67.0920, -67.0910],\n",
      "          ...,\n",
      "          [-66.1791, -66.1802, -66.1799,  ..., -66.1781, -66.1771, -66.1766],\n",
      "          [-66.2654, -66.2684, -66.2666,  ..., -66.2678, -66.2678, -66.2669],\n",
      "          [-66.6200, -66.6234, -66.6184,  ..., -66.6210, -66.6209, -66.6232]],\n",
      "\n",
      "         [[-66.9880, -66.9885, -66.9872,  ..., -66.9872, -66.9873, -66.9878],\n",
      "          [-66.8476, -66.8477, -66.8472,  ..., -66.8460, -66.8477, -66.8458],\n",
      "          [-67.3313, -67.3306, -67.3312,  ..., -67.3306, -67.3310, -67.3319],\n",
      "          ...,\n",
      "          [-66.3818, -66.3820, -66.3808,  ..., -66.3806, -66.3845, -66.3804],\n",
      "          [-66.3266, -66.3294, -66.3308,  ..., -66.3283, -66.3304, -66.3288],\n",
      "          [-66.6338, -66.6331, -66.6335,  ..., -66.6309, -66.6315, -66.6342]]],\n",
      "\n",
      "\n",
      "        [[[-66.2440, -66.2434, -66.2431,  ..., -66.2443, -66.2431, -66.2460],\n",
      "          [-66.5323, -66.5321, -66.5347,  ..., -66.5345, -66.5343, -66.5327],\n",
      "          [-67.0919, -67.0923, -67.0910,  ..., -67.0927, -67.0915, -67.0922],\n",
      "          ...,\n",
      "          [-66.1781, -66.1798, -66.1796,  ..., -66.1777, -66.1798, -66.1771],\n",
      "          [-66.2678, -66.2669, -66.2669,  ..., -66.2652, -66.2662, -66.2670],\n",
      "          [-66.6220, -66.6202, -66.6233,  ..., -66.6201, -66.6217, -66.6197]],\n",
      "\n",
      "         [[-66.0575, -66.0548, -66.0568,  ..., -66.0556, -66.0557, -66.0568],\n",
      "          [-66.4763, -66.4748, -66.4757,  ..., -66.4764, -66.4763, -66.4769],\n",
      "          [-66.7436, -66.7437, -66.7430,  ..., -66.7433, -66.7438, -66.7433],\n",
      "          ...,\n",
      "          [-66.2557, -66.2583, -66.2562,  ..., -66.2578, -66.2564, -66.2575],\n",
      "          [-67.0250, -67.0244, -67.0255,  ..., -67.0247, -67.0254, -67.0229],\n",
      "          [-66.5301, -66.5312, -66.5302,  ..., -66.5297, -66.5301, -66.5314]]],\n",
      "\n",
      "\n",
      "        [[[-66.0572, -66.0549, -66.0563,  ..., -66.0557, -66.0575, -66.0544],\n",
      "          [-66.4769, -66.4763, -66.4774,  ..., -66.4758, -66.4764, -66.4764],\n",
      "          [-66.7445, -66.7426, -66.7431,  ..., -66.7425, -66.7437, -66.7429],\n",
      "          ...,\n",
      "          [-66.2583, -66.2597, -66.2563,  ..., -66.2539, -66.2582, -66.2572],\n",
      "          [-67.0260, -67.0259, -67.0254,  ..., -67.0241, -67.0254, -67.0246],\n",
      "          [-66.5317, -66.5299, -66.5297,  ..., -66.5318, -66.5312, -66.5301]],\n",
      "\n",
      "         [[-66.8258, -66.8249, -66.8246,  ..., -66.8243, -66.8236, -66.8266],\n",
      "          [-67.0335, -67.0347, -67.0350,  ..., -67.0343, -67.0341, -67.0359],\n",
      "          [-66.8821, -66.8840, -66.8841,  ..., -66.8824, -66.8844, -66.8830],\n",
      "          ...,\n",
      "          [-66.6914, -66.6904, -66.6915,  ..., -66.6912, -66.6913, -66.6913],\n",
      "          [-66.7376, -66.7363, -66.7369,  ..., -66.7334, -66.7365, -66.7365],\n",
      "          [-66.3177, -66.3180, -66.3201,  ..., -66.3208, -66.3202, -66.3189]]],\n",
      "\n",
      "\n",
      "        [[[-66.9881, -66.9867, -66.9871,  ..., -66.9870, -66.9872, -66.9877],\n",
      "          [-66.8474, -66.8475, -66.8477,  ..., -66.8479, -66.8473, -66.8456],\n",
      "          [-67.3307, -67.3307, -67.3303,  ..., -67.3297, -67.3298, -67.3309],\n",
      "          ...,\n",
      "          [-66.3829, -66.3821, -66.3820,  ..., -66.3847, -66.3827, -66.3815],\n",
      "          [-66.3292, -66.3294, -66.3281,  ..., -66.3273, -66.3282, -66.3271],\n",
      "          [-66.6329, -66.6335, -66.6331,  ..., -66.6333, -66.6357, -66.6331]],\n",
      "\n",
      "         [[-66.8244, -66.8254, -66.8246,  ..., -66.8242, -66.8248, -66.8253],\n",
      "          [-67.0339, -67.0358, -67.0350,  ..., -67.0361, -67.0343, -67.0359],\n",
      "          [-66.8824, -66.8837, -66.8835,  ..., -66.8831, -66.8833, -66.8818],\n",
      "          ...,\n",
      "          [-66.6909, -66.6911, -66.6917,  ..., -66.6881, -66.6902, -66.6920],\n",
      "          [-66.7323, -66.7338, -66.7343,  ..., -66.7334, -66.7375, -66.7359],\n",
      "          [-66.3188, -66.3203, -66.3183,  ..., -66.3198, -66.3202, -66.3200]]]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([4, 64, 512])):  tensor([[[-133.2314, -133.2313, -133.2312,  ..., -133.2314, -133.2313,\n",
      "          -133.2314],\n",
      "         [-133.3819, -133.3819, -133.3818,  ..., -133.3818, -133.3818,\n",
      "          -133.3817],\n",
      "         [-134.4225, -134.4225, -134.4224,  ..., -134.4224, -134.4225,\n",
      "          -134.4224],\n",
      "         ...,\n",
      "         [-132.5609, -132.5606, -132.5610,  ..., -132.5607, -132.5607,\n",
      "          -132.5609],\n",
      "         [-132.5954, -132.5953, -132.5955,  ..., -132.5954, -132.5955,\n",
      "          -132.5954],\n",
      "         [-133.2545, -133.2545, -133.2548,  ..., -133.2546, -133.2547,\n",
      "          -133.2547]],\n",
      "\n",
      "        [[-132.3001, -132.3001, -132.3000,  ..., -132.3003, -132.2999,\n",
      "          -132.3000],\n",
      "         [-133.0111, -133.0111, -133.0112,  ..., -133.0109, -133.0111,\n",
      "          -133.0109],\n",
      "         [-133.8350, -133.8351, -133.8350,  ..., -133.8350, -133.8350,\n",
      "          -133.8351],\n",
      "         ...,\n",
      "         [-132.4347, -132.4348, -132.4348,  ..., -132.4347, -132.4348,\n",
      "          -132.4348],\n",
      "         [-133.2909, -133.2911, -133.2910,  ..., -133.2909, -133.2911,\n",
      "          -133.2909],\n",
      "         [-133.1519, -133.1519, -133.1518,  ..., -133.1519, -133.1517,\n",
      "          -133.1517]],\n",
      "\n",
      "        [[-132.8809, -132.8811, -132.8809,  ..., -132.8808, -132.8810,\n",
      "          -132.8810],\n",
      "         [-133.5121, -133.5121, -133.5119,  ..., -133.5119, -133.5120,\n",
      "          -133.5120],\n",
      "         [-133.6265, -133.6265, -133.6265,  ..., -133.6265, -133.6265,\n",
      "          -133.6264],\n",
      "         ...,\n",
      "         [-132.9476, -132.9477, -132.9477,  ..., -132.9476, -132.9478,\n",
      "          -132.9477],\n",
      "         [-133.7594, -133.7593, -133.7593,  ..., -133.7593, -133.7594,\n",
      "          -133.7593],\n",
      "         [-132.8504, -132.8504, -132.8505,  ..., -132.8503, -132.8502,\n",
      "          -132.8504]],\n",
      "\n",
      "        [[-133.8119, -133.8120, -133.8120,  ..., -133.8119, -133.8119,\n",
      "          -133.8119],\n",
      "         [-133.8825, -133.8827, -133.8827,  ..., -133.8828, -133.8827,\n",
      "          -133.8826],\n",
      "         [-134.2136, -134.2137, -134.2138,  ..., -134.2136, -134.2137,\n",
      "          -134.2137],\n",
      "         ...,\n",
      "         [-133.0733, -133.0734, -133.0733,  ..., -133.0734, -133.0733,\n",
      "          -133.0734],\n",
      "         [-133.0639, -133.0637, -133.0638,  ..., -133.0639, -133.0638,\n",
      "          -133.0638],\n",
      "         [-132.9535, -132.9534, -132.9533,  ..., -132.9534, -132.9532,\n",
      "          -132.9534]]], grad_fn=<AddBackward0>)\n",
      "TorchCPTLayer:\n",
      "                       Input shape: torch.Size([2, 2, 64, 512])\n",
      "                       Input: tensor([[[[-133.2314, -133.2313, -133.2312,  ..., -133.2314, -133.2313,\n",
      "           -133.2314],\n",
      "          [-133.3819, -133.3819, -133.3818,  ..., -133.3818, -133.3818,\n",
      "           -133.3817],\n",
      "          [-134.4225, -134.4225, -134.4224,  ..., -134.4224, -134.4225,\n",
      "           -134.4224],\n",
      "          ...,\n",
      "          [-132.5609, -132.5606, -132.5610,  ..., -132.5607, -132.5607,\n",
      "           -132.5609],\n",
      "          [-132.5954, -132.5953, -132.5955,  ..., -132.5954, -132.5955,\n",
      "           -132.5954],\n",
      "          [-133.2545, -133.2545, -133.2548,  ..., -133.2546, -133.2547,\n",
      "           -133.2547]],\n",
      "\n",
      "         [[-132.8809, -132.8811, -132.8809,  ..., -132.8808, -132.8810,\n",
      "           -132.8810],\n",
      "          [-133.5121, -133.5121, -133.5119,  ..., -133.5119, -133.5120,\n",
      "           -133.5120],\n",
      "          [-133.6265, -133.6265, -133.6265,  ..., -133.6265, -133.6265,\n",
      "           -133.6264],\n",
      "          ...,\n",
      "          [-132.9476, -132.9477, -132.9477,  ..., -132.9476, -132.9478,\n",
      "           -132.9477],\n",
      "          [-133.7594, -133.7593, -133.7593,  ..., -133.7593, -133.7594,\n",
      "           -133.7593],\n",
      "          [-132.8504, -132.8504, -132.8505,  ..., -132.8503, -132.8502,\n",
      "           -132.8504]]],\n",
      "\n",
      "\n",
      "        [[[-132.3001, -132.3001, -132.3000,  ..., -132.3003, -132.2999,\n",
      "           -132.3000],\n",
      "          [-133.0111, -133.0111, -133.0112,  ..., -133.0109, -133.0111,\n",
      "           -133.0109],\n",
      "          [-133.8350, -133.8351, -133.8350,  ..., -133.8350, -133.8350,\n",
      "           -133.8351],\n",
      "          ...,\n",
      "          [-132.4347, -132.4348, -132.4348,  ..., -132.4347, -132.4348,\n",
      "           -132.4348],\n",
      "          [-133.2909, -133.2911, -133.2910,  ..., -133.2909, -133.2911,\n",
      "           -133.2909],\n",
      "          [-133.1519, -133.1519, -133.1518,  ..., -133.1519, -133.1517,\n",
      "           -133.1517]],\n",
      "\n",
      "         [[-133.8119, -133.8120, -133.8120,  ..., -133.8119, -133.8119,\n",
      "           -133.8119],\n",
      "          [-133.8825, -133.8827, -133.8827,  ..., -133.8828, -133.8827,\n",
      "           -133.8826],\n",
      "          [-134.2136, -134.2137, -134.2138,  ..., -134.2136, -134.2137,\n",
      "           -134.2137],\n",
      "          ...,\n",
      "          [-133.0733, -133.0734, -133.0733,  ..., -133.0734, -133.0733,\n",
      "           -133.0734],\n",
      "          [-133.0639, -133.0637, -133.0638,  ..., -133.0639, -133.0638,\n",
      "           -133.0638],\n",
      "          [-132.9535, -132.9534, -132.9533,  ..., -132.9534, -132.9532,\n",
      "           -132.9534]]]], grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([2, 64, 1])):  tensor([[[-266.1122],\n",
      "         [-266.8938],\n",
      "         [-268.0490],\n",
      "         [-266.9195],\n",
      "         [-266.2654],\n",
      "         [-265.8719],\n",
      "         [-267.2574],\n",
      "         [-266.3139],\n",
      "         [-266.8520],\n",
      "         [-266.6794],\n",
      "         [-266.4248],\n",
      "         [-265.0307],\n",
      "         [-265.9156],\n",
      "         [-266.1329],\n",
      "         [-267.5032],\n",
      "         [-266.6303],\n",
      "         [-265.8799],\n",
      "         [-264.8815],\n",
      "         [-265.8971],\n",
      "         [-265.7052],\n",
      "         [-267.1541],\n",
      "         [-266.6457],\n",
      "         [-266.7937],\n",
      "         [-266.5622],\n",
      "         [-267.0421],\n",
      "         [-266.8618],\n",
      "         [-266.4951],\n",
      "         [-265.1066],\n",
      "         [-266.6608],\n",
      "         [-266.4837],\n",
      "         [-266.1593],\n",
      "         [-266.9082],\n",
      "         [-266.3330],\n",
      "         [-266.4734],\n",
      "         [-266.7374],\n",
      "         [-266.6852],\n",
      "         [-265.6392],\n",
      "         [-265.4817],\n",
      "         [-267.2367],\n",
      "         [-264.2392],\n",
      "         [-264.4469],\n",
      "         [-266.3970],\n",
      "         [-264.9679],\n",
      "         [-266.8445],\n",
      "         [-266.8323],\n",
      "         [-266.3925],\n",
      "         [-266.3465],\n",
      "         [-266.4330],\n",
      "         [-266.5119],\n",
      "         [-265.5346],\n",
      "         [-267.4353],\n",
      "         [-265.5822],\n",
      "         [-266.6038],\n",
      "         [-266.5920],\n",
      "         [-266.1332],\n",
      "         [-265.9516],\n",
      "         [-267.7294],\n",
      "         [-268.5032],\n",
      "         [-265.3927],\n",
      "         [-266.3293],\n",
      "         [-265.2816],\n",
      "         [-265.5085],\n",
      "         [-266.3548],\n",
      "         [-266.1051]],\n",
      "\n",
      "        [[-266.1121],\n",
      "         [-266.8937],\n",
      "         [-268.0487],\n",
      "         [-266.9195],\n",
      "         [-266.2654],\n",
      "         [-265.8721],\n",
      "         [-267.2574],\n",
      "         [-266.3141],\n",
      "         [-266.8518],\n",
      "         [-266.6797],\n",
      "         [-266.4246],\n",
      "         [-265.0306],\n",
      "         [-265.9155],\n",
      "         [-266.1326],\n",
      "         [-267.5032],\n",
      "         [-266.6302],\n",
      "         [-265.8799],\n",
      "         [-264.8817],\n",
      "         [-265.8972],\n",
      "         [-265.7052],\n",
      "         [-267.1539],\n",
      "         [-266.6458],\n",
      "         [-266.7935],\n",
      "         [-266.5620],\n",
      "         [-267.0420],\n",
      "         [-266.8615],\n",
      "         [-266.4950],\n",
      "         [-265.1066],\n",
      "         [-266.6608],\n",
      "         [-266.4836],\n",
      "         [-266.1594],\n",
      "         [-266.9081],\n",
      "         [-266.3329],\n",
      "         [-266.4733],\n",
      "         [-266.7373],\n",
      "         [-266.6852],\n",
      "         [-265.6389],\n",
      "         [-265.4820],\n",
      "         [-267.2368],\n",
      "         [-264.2388],\n",
      "         [-264.4471],\n",
      "         [-266.3971],\n",
      "         [-264.9677],\n",
      "         [-266.8443],\n",
      "         [-266.8323],\n",
      "         [-266.3926],\n",
      "         [-266.3463],\n",
      "         [-266.4329],\n",
      "         [-266.5117],\n",
      "         [-265.5346],\n",
      "         [-267.4352],\n",
      "         [-265.5821],\n",
      "         [-266.6040],\n",
      "         [-266.5921],\n",
      "         [-266.1331],\n",
      "         [-265.9516],\n",
      "         [-267.7291],\n",
      "         [-268.5033],\n",
      "         [-265.3928],\n",
      "         [-266.3293],\n",
      "         [-265.2816],\n",
      "         [-265.5081],\n",
      "         [-266.3548],\n",
      "         [-266.1052]]], grad_fn=<AddBackward0>)\n",
      "TorchSumLayer:\n",
      "                       Input shape: torch.Size([1, 2, 64, 1])\n",
      "                       Input: tensor([[[[-266.1122],\n",
      "          [-266.8938],\n",
      "          [-268.0490],\n",
      "          [-266.9195],\n",
      "          [-266.2654],\n",
      "          [-265.8719],\n",
      "          [-267.2574],\n",
      "          [-266.3139],\n",
      "          [-266.8520],\n",
      "          [-266.6794],\n",
      "          [-266.4248],\n",
      "          [-265.0307],\n",
      "          [-265.9156],\n",
      "          [-266.1329],\n",
      "          [-267.5032],\n",
      "          [-266.6303],\n",
      "          [-265.8799],\n",
      "          [-264.8815],\n",
      "          [-265.8971],\n",
      "          [-265.7052],\n",
      "          [-267.1541],\n",
      "          [-266.6457],\n",
      "          [-266.7937],\n",
      "          [-266.5622],\n",
      "          [-267.0421],\n",
      "          [-266.8618],\n",
      "          [-266.4951],\n",
      "          [-265.1066],\n",
      "          [-266.6608],\n",
      "          [-266.4837],\n",
      "          [-266.1593],\n",
      "          [-266.9082],\n",
      "          [-266.3330],\n",
      "          [-266.4734],\n",
      "          [-266.7374],\n",
      "          [-266.6852],\n",
      "          [-265.6392],\n",
      "          [-265.4817],\n",
      "          [-267.2367],\n",
      "          [-264.2392],\n",
      "          [-264.4469],\n",
      "          [-266.3970],\n",
      "          [-264.9679],\n",
      "          [-266.8445],\n",
      "          [-266.8323],\n",
      "          [-266.3925],\n",
      "          [-266.3465],\n",
      "          [-266.4330],\n",
      "          [-266.5119],\n",
      "          [-265.5346],\n",
      "          [-267.4353],\n",
      "          [-265.5822],\n",
      "          [-266.6038],\n",
      "          [-266.5920],\n",
      "          [-266.1332],\n",
      "          [-265.9516],\n",
      "          [-267.7294],\n",
      "          [-268.5032],\n",
      "          [-265.3927],\n",
      "          [-266.3293],\n",
      "          [-265.2816],\n",
      "          [-265.5085],\n",
      "          [-266.3548],\n",
      "          [-266.1051]],\n",
      "\n",
      "         [[-266.1121],\n",
      "          [-266.8937],\n",
      "          [-268.0487],\n",
      "          [-266.9195],\n",
      "          [-266.2654],\n",
      "          [-265.8721],\n",
      "          [-267.2574],\n",
      "          [-266.3141],\n",
      "          [-266.8518],\n",
      "          [-266.6797],\n",
      "          [-266.4246],\n",
      "          [-265.0306],\n",
      "          [-265.9155],\n",
      "          [-266.1326],\n",
      "          [-267.5032],\n",
      "          [-266.6302],\n",
      "          [-265.8799],\n",
      "          [-264.8817],\n",
      "          [-265.8972],\n",
      "          [-265.7052],\n",
      "          [-267.1539],\n",
      "          [-266.6458],\n",
      "          [-266.7935],\n",
      "          [-266.5620],\n",
      "          [-267.0420],\n",
      "          [-266.8615],\n",
      "          [-266.4950],\n",
      "          [-265.1066],\n",
      "          [-266.6608],\n",
      "          [-266.4836],\n",
      "          [-266.1594],\n",
      "          [-266.9081],\n",
      "          [-266.3329],\n",
      "          [-266.4733],\n",
      "          [-266.7373],\n",
      "          [-266.6852],\n",
      "          [-265.6389],\n",
      "          [-265.4820],\n",
      "          [-267.2368],\n",
      "          [-264.2388],\n",
      "          [-264.4471],\n",
      "          [-266.3971],\n",
      "          [-264.9677],\n",
      "          [-266.8443],\n",
      "          [-266.8323],\n",
      "          [-266.3926],\n",
      "          [-266.3463],\n",
      "          [-266.4329],\n",
      "          [-266.5117],\n",
      "          [-265.5346],\n",
      "          [-267.4352],\n",
      "          [-265.5821],\n",
      "          [-266.6040],\n",
      "          [-266.5921],\n",
      "          [-266.1331],\n",
      "          [-265.9516],\n",
      "          [-267.7291],\n",
      "          [-268.5033],\n",
      "          [-265.3928],\n",
      "          [-266.3293],\n",
      "          [-265.2816],\n",
      "          [-265.5081],\n",
      "          [-266.3548],\n",
      "          [-266.1052]]]], grad_fn=<UnsqueezeBackward0>)\n",
      "Output (torch.Size([1, 64, 1])):  tensor([[[-266.1122],\n",
      "         [-266.8937],\n",
      "         [-268.0489],\n",
      "         [-266.9195],\n",
      "         [-266.2654],\n",
      "         [-265.8720],\n",
      "         [-267.2574],\n",
      "         [-266.3140],\n",
      "         [-266.8519],\n",
      "         [-266.6795],\n",
      "         [-266.4247],\n",
      "         [-265.0306],\n",
      "         [-265.9156],\n",
      "         [-266.1328],\n",
      "         [-267.5032],\n",
      "         [-266.6303],\n",
      "         [-265.8799],\n",
      "         [-264.8816],\n",
      "         [-265.8972],\n",
      "         [-265.7052],\n",
      "         [-267.1540],\n",
      "         [-266.6458],\n",
      "         [-266.7936],\n",
      "         [-266.5621],\n",
      "         [-267.0421],\n",
      "         [-266.8616],\n",
      "         [-266.4951],\n",
      "         [-265.1066],\n",
      "         [-266.6608],\n",
      "         [-266.4837],\n",
      "         [-266.1593],\n",
      "         [-266.9082],\n",
      "         [-266.3330],\n",
      "         [-266.4734],\n",
      "         [-266.7374],\n",
      "         [-266.6852],\n",
      "         [-265.6390],\n",
      "         [-265.4818],\n",
      "         [-267.2368],\n",
      "         [-264.2390],\n",
      "         [-264.4470],\n",
      "         [-266.3970],\n",
      "         [-264.9679],\n",
      "         [-266.8444],\n",
      "         [-266.8323],\n",
      "         [-266.3925],\n",
      "         [-266.3464],\n",
      "         [-266.4330],\n",
      "         [-266.5118],\n",
      "         [-265.5346],\n",
      "         [-267.4352],\n",
      "         [-265.5821],\n",
      "         [-266.6039],\n",
      "         [-266.5920],\n",
      "         [-266.1331],\n",
      "         [-265.9516],\n",
      "         [-267.7292],\n",
      "         [-268.5033],\n",
      "         [-265.3927],\n",
      "         [-266.3293],\n",
      "         [-265.2816],\n",
      "         [-265.5083],\n",
      "         [-266.3548],\n",
      "         [-266.1051]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-17045.1230, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(\"Circuit Input: \", patched.reshape(-1,4).shape, patched.reshape(-1,4, 1).permute(1,0,2))\n",
    "res = cpatch(patched.reshape(-1, 3*kernel_size*kernel_size))\n",
    "res.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "701563ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[235,  44, 101,  ...,  28, 137, 141]])\n",
      "TorchCategoricalLayer:\n",
      "                       Input shape: torch.Size([3072, 1, 1])\n",
      "                       Input: tensor([[[235]],\n",
      "\n",
      "        [[ 16]],\n",
      "\n",
      "        [[101]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[250]],\n",
      "\n",
      "        [[141]],\n",
      "\n",
      "        [[110]]])\n",
      "Output (torch.Size([3072, 1, 512])):  tensor([[[-5.9017, -5.2065, -4.6380,  ..., -7.0506, -6.0913, -5.5275]],\n",
      "\n",
      "        [[-5.3310, -6.3777, -3.8229,  ..., -6.1503, -6.5037, -6.8531]],\n",
      "\n",
      "        [[-7.7115, -4.8916, -5.9795,  ..., -5.3686, -5.3837, -7.6764]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.3712, -5.9586, -4.8683,  ..., -5.4677, -5.5597, -6.6288]],\n",
      "\n",
      "        [[-4.2110, -5.9805, -4.9656,  ..., -7.2668, -5.6935, -5.9949]],\n",
      "\n",
      "        [[-7.6926, -5.0970, -7.2634,  ..., -6.9023, -7.5560, -6.1037]]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "TorchHadamardLayer:\n",
      "                       Input shape: torch.Size([1024, 3, 1, 512])\n",
      "                       Input: tensor([[[[-5.9017, -5.2065, -4.6380,  ..., -7.0506, -6.0913, -5.5275]],\n",
      "\n",
      "         [[-5.3310, -6.3777, -3.8229,  ..., -6.1503, -6.5037, -6.8531]],\n",
      "\n",
      "         [[-7.7115, -4.8916, -5.9795,  ..., -5.3686, -5.3837, -7.6764]]],\n",
      "\n",
      "\n",
      "        [[[-5.4697, -5.9085, -6.1005,  ..., -5.0270, -5.3412, -6.8285]],\n",
      "\n",
      "         [[-5.4169, -6.1519, -6.3200,  ..., -5.1877, -6.0122, -6.5483]],\n",
      "\n",
      "         [[-5.1725, -5.1651, -4.5379,  ..., -6.4341, -7.3056, -5.0234]]],\n",
      "\n",
      "\n",
      "        [[[-5.5657, -6.6976, -6.4540,  ..., -6.1760, -7.2122, -7.3014]],\n",
      "\n",
      "         [[-4.9120, -6.7523, -6.2174,  ..., -6.1434, -6.4120, -5.4745]],\n",
      "\n",
      "         [[-8.0860, -9.0437, -5.5886,  ..., -6.5381, -6.7009, -6.1975]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.9563, -5.2952, -5.2949,  ..., -5.7753, -6.0459, -5.7736]],\n",
      "\n",
      "         [[-6.0497, -5.2870, -7.4849,  ..., -4.7482, -4.3045, -6.3160]],\n",
      "\n",
      "         [[-5.0273, -6.3466, -5.1722,  ..., -8.0520, -5.4775, -6.6749]]],\n",
      "\n",
      "\n",
      "        [[[-4.6798, -4.3820, -5.8977,  ..., -5.2983, -4.9297, -6.6016]],\n",
      "\n",
      "         [[-6.5981, -6.0509, -5.4124,  ..., -7.5163, -4.4560, -5.4389]],\n",
      "\n",
      "         [[-5.8378, -6.4825, -6.1550,  ..., -4.8837, -5.3511, -6.7735]]],\n",
      "\n",
      "\n",
      "        [[[-4.3712, -5.9586, -4.8683,  ..., -5.4677, -5.5597, -6.6288]],\n",
      "\n",
      "         [[-4.2110, -5.9805, -4.9656,  ..., -7.2668, -5.6935, -5.9949]],\n",
      "\n",
      "         [[-7.6926, -5.0970, -7.2634,  ..., -6.9023, -7.5560, -6.1037]]]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([1024, 1, 512])):  tensor([[[-18.9442, -16.4758, -14.4405,  ..., -18.5695, -17.9787, -20.0571]],\n",
      "\n",
      "        [[-16.0591, -17.2255, -16.9584,  ..., -16.6488, -18.6590, -18.4002]],\n",
      "\n",
      "        [[-18.5637, -22.4936, -18.2600,  ..., -18.8575, -20.3251, -18.9734]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-18.0333, -16.9288, -17.9519,  ..., -18.5755, -15.8278, -18.7645]],\n",
      "\n",
      "        [[-17.1156, -16.9155, -17.4652,  ..., -17.6983, -14.7368, -18.8139]],\n",
      "\n",
      "        [[-16.2748, -17.0360, -17.0972,  ..., -19.6367, -18.8092, -18.7274]]],\n",
      "       grad_fn=<SumBackward1>)\n",
      "TorchSumLayer:\n",
      "                       Input shape: torch.Size([2048, 1, 1, 512])\n",
      "                       Input: tensor([[[[-18.9442, -16.4758, -14.4405,  ..., -18.5695, -17.9787, -20.0571]]],\n",
      "\n",
      "\n",
      "        [[[-18.9442, -16.4758, -14.4405,  ..., -18.5695, -17.9787, -20.0571]]],\n",
      "\n",
      "\n",
      "        [[[-16.0591, -17.2255, -16.9584,  ..., -16.6488, -18.6590, -18.4002]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-17.1156, -16.9155, -17.4652,  ..., -17.6983, -14.7368, -18.8139]]],\n",
      "\n",
      "\n",
      "        [[[-16.2748, -17.0360, -17.0972,  ..., -19.6367, -18.8092, -18.7274]]],\n",
      "\n",
      "\n",
      "        [[[-16.2748, -17.0360, -17.0972,  ..., -19.6367, -18.8092, -18.7274]]]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([2048, 1, 512])):  tensor([[[-16.8887, -16.9886, -16.8436,  ..., -16.2831, -16.7837, -16.8963]],\n",
      "\n",
      "        [[-16.8685, -16.8811, -16.8729,  ..., -16.8766, -16.7665, -16.8225]],\n",
      "\n",
      "        [[-16.3249, -15.7576, -15.7651,  ..., -15.4728, -16.3519, -16.3011]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-16.4512, -16.6302, -16.4602,  ..., -16.3890, -16.6278, -16.6150]],\n",
      "\n",
      "        [[-16.6166, -16.5731, -16.5655,  ..., -16.6347, -16.5037, -16.1953]],\n",
      "\n",
      "        [[-16.5014, -16.7472, -16.5266,  ..., -16.4693, -16.5045, -16.2769]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "TorchCPTLayer:\n",
      "                       Input shape: torch.Size([1024, 2, 1, 512])\n",
      "                       Input: tensor([[[[-16.8887, -16.9886, -16.8436,  ..., -16.2831, -16.7837, -16.8963]],\n",
      "\n",
      "         [[-16.3249, -15.7576, -15.7651,  ..., -15.4728, -16.3519, -16.3011]]],\n",
      "\n",
      "\n",
      "        [[[-16.8291, -17.0357, -16.7291,  ..., -16.6806, -16.7576, -16.9804]],\n",
      "\n",
      "         [[-16.2860, -16.6668, -16.6555,  ..., -16.4785, -16.7010, -16.6836]]],\n",
      "\n",
      "\n",
      "        [[[-16.8685, -16.8811, -16.8729,  ..., -16.8766, -16.7665, -16.8225]],\n",
      "\n",
      "         [[-16.6448, -16.9069, -16.8477,  ..., -16.8702, -16.9077, -16.9759]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-16.0953, -16.5181, -16.4588,  ..., -16.6878, -16.6396, -16.5049]],\n",
      "\n",
      "         [[-16.4760, -16.3815, -16.6456,  ..., -16.6411, -16.4376, -16.7410]]],\n",
      "\n",
      "\n",
      "        [[[-16.4512, -16.6302, -16.4602,  ..., -16.3890, -16.6278, -16.6150]],\n",
      "\n",
      "         [[-16.6166, -16.5731, -16.5655,  ..., -16.6347, -16.5037, -16.1953]]],\n",
      "\n",
      "\n",
      "        [[[-16.7323, -16.6813, -16.6316,  ..., -16.7734, -16.4150, -16.8991]],\n",
      "\n",
      "         [[-16.5014, -16.7472, -16.5266,  ..., -16.4693, -16.5045, -16.2769]]]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([1024, 1, 512])):  tensor([[[-32.7722, -32.8020, -32.7953,  ..., -32.8033, -32.8096, -32.8106]],\n",
      "\n",
      "        [[-33.4770, -33.5089, -33.4950,  ..., -33.4997, -33.4901, -33.4821]],\n",
      "\n",
      "        [[-33.5394, -33.5778, -33.5611,  ..., -33.5623, -33.5863, -33.5533]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-33.0382, -33.0549, -33.0447,  ..., -33.0721, -33.0375, -33.0684]],\n",
      "\n",
      "        [[-33.0924, -33.1024, -33.1028,  ..., -33.1042, -33.1043, -33.0867]],\n",
      "\n",
      "        [[-33.2565, -33.2753, -33.2598,  ..., -33.2706, -33.2649, -33.2770]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "TorchHadamardLayer:\n",
      "                       Input shape: torch.Size([512, 2, 1, 512])\n",
      "                       Input: tensor([[[[-32.7722, -32.8020, -32.7953,  ..., -32.8033, -32.8096, -32.8106]],\n",
      "\n",
      "         [[-33.4585, -33.4515, -33.4591,  ..., -33.4786, -33.4394, -33.4515]]],\n",
      "\n",
      "\n",
      "        [[[-33.5394, -33.5778, -33.5611,  ..., -33.5623, -33.5863, -33.5533]],\n",
      "\n",
      "         [[-32.6672, -32.6662, -32.6203,  ..., -32.6690, -32.6749, -32.7238]]],\n",
      "\n",
      "\n",
      "        [[[-33.4770, -33.5089, -33.4950,  ..., -33.4997, -33.4901, -33.4821]],\n",
      "\n",
      "         [[-33.4955, -33.4915, -33.4548,  ..., -33.4763, -33.4961, -33.5152]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-33.2914, -33.2792, -33.2755,  ..., -33.2652, -33.2631, -33.3000]],\n",
      "\n",
      "         [[-33.2643, -33.2555, -33.2393,  ..., -33.2572, -33.2461, -33.2582]]],\n",
      "\n",
      "\n",
      "        [[[-33.2247, -33.2527, -33.2528,  ..., -33.2441, -33.2268, -33.2442]],\n",
      "\n",
      "         [[-33.0924, -33.1024, -33.1028,  ..., -33.1042, -33.1043, -33.0867]]],\n",
      "\n",
      "\n",
      "        [[[-33.0382, -33.0549, -33.0447,  ..., -33.0721, -33.0375, -33.0684]],\n",
      "\n",
      "         [[-33.2565, -33.2753, -33.2598,  ..., -33.2706, -33.2649, -33.2770]]]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([512, 1, 512])):  tensor([[[-66.2307, -66.2534, -66.2543,  ..., -66.2818, -66.2490, -66.2622]],\n",
      "\n",
      "        [[-66.2066, -66.2441, -66.1814,  ..., -66.2313, -66.2612, -66.2771]],\n",
      "\n",
      "        [[-66.9725, -67.0005, -66.9497,  ..., -66.9760, -66.9863, -66.9973]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-66.5557, -66.5347, -66.5148,  ..., -66.5223, -66.5092, -66.5582]],\n",
      "\n",
      "        [[-66.3171, -66.3551, -66.3556,  ..., -66.3483, -66.3311, -66.3309]],\n",
      "\n",
      "        [[-66.2947, -66.3302, -66.3044,  ..., -66.3427, -66.3024, -66.3454]]],\n",
      "       grad_fn=<SumBackward1>)\n",
      "TorchSumLayer:\n",
      "                       Input shape: torch.Size([256, 2, 1, 512])\n",
      "                       Input: tensor([[[[-66.2307, -66.2534, -66.2543,  ..., -66.2818, -66.2490, -66.2622]],\n",
      "\n",
      "         [[-66.2066, -66.2441, -66.1814,  ..., -66.2313, -66.2612, -66.2771]]],\n",
      "\n",
      "\n",
      "        [[[-66.9725, -67.0005, -66.9497,  ..., -66.9760, -66.9863, -66.9973]],\n",
      "\n",
      "         [[-67.0067, -67.0013, -67.0160,  ..., -66.9964, -66.9934, -66.9969]]],\n",
      "\n",
      "\n",
      "        [[[-66.0647, -66.0289, -66.0692,  ..., -66.0481, -66.0636, -66.0595]],\n",
      "\n",
      "         [[-66.0768, -66.0519, -66.0381,  ..., -66.0195, -66.0597, -66.0235]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-66.6208, -66.6450, -66.6387,  ..., -66.5897, -66.6689, -66.6133]],\n",
      "\n",
      "         [[-66.6102, -66.6126, -66.6483,  ..., -66.6432, -66.6080, -66.6000]]],\n",
      "\n",
      "\n",
      "        [[[-66.5452, -66.5012, -66.5632,  ..., -66.5231, -66.5622, -66.5415]],\n",
      "\n",
      "         [[-66.5557, -66.5347, -66.5148,  ..., -66.5223, -66.5092, -66.5582]]],\n",
      "\n",
      "\n",
      "        [[[-66.3171, -66.3551, -66.3556,  ..., -66.3483, -66.3311, -66.3309]],\n",
      "\n",
      "         [[-66.2947, -66.3302, -66.3044,  ..., -66.3427, -66.3024, -66.3454]]]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([256, 1, 512])):  tensor([[[-66.2154, -66.2493, -66.2186,  ..., -66.2361, -66.2500, -66.2664]],\n",
      "\n",
      "        [[-66.9823, -67.0009, -66.9821,  ..., -66.9796, -66.9880, -66.9970]],\n",
      "\n",
      "        [[-66.0752, -66.0480, -66.0521,  ..., -66.0332, -66.0602, -66.0354]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-66.6177, -66.6263, -66.6434,  ..., -66.5990, -66.6534, -66.6029]],\n",
      "\n",
      "        [[-66.5543, -66.5290, -66.5365,  ..., -66.5227, -66.5156, -66.5525]],\n",
      "\n",
      "        [[-66.3134, -66.3418, -66.3377,  ..., -66.3445, -66.3133, -66.3432]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "TorchSumLayer:\n",
      "                       Input shape: torch.Size([512, 1, 1, 512])\n",
      "                       Input: tensor([[[[-66.2154, -66.2493, -66.2186,  ..., -66.2361, -66.2500, -66.2664]]],\n",
      "\n",
      "\n",
      "        [[[-66.2154, -66.2493, -66.2186,  ..., -66.2361, -66.2500, -66.2664]]],\n",
      "\n",
      "\n",
      "        [[[-66.9823, -67.0009, -66.9821,  ..., -66.9796, -66.9880, -66.9970]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-66.5543, -66.5290, -66.5365,  ..., -66.5227, -66.5156, -66.5525]]],\n",
      "\n",
      "\n",
      "        [[[-66.3134, -66.3418, -66.3377,  ..., -66.3445, -66.3133, -66.3432]]],\n",
      "\n",
      "\n",
      "        [[[-66.3134, -66.3418, -66.3377,  ..., -66.3445, -66.3133, -66.3432]]]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([512, 1, 512])):  tensor([[[-66.2449, -66.2441, -66.2418,  ..., -66.2430, -66.2433, -66.2446]],\n",
      "\n",
      "        [[-66.2440, -66.2434, -66.2431,  ..., -66.2443, -66.2431, -66.2460]],\n",
      "\n",
      "        [[-66.9880, -66.9885, -66.9872,  ..., -66.9872, -66.9873, -66.9878]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-66.5317, -66.5299, -66.5297,  ..., -66.5318, -66.5312, -66.5301]],\n",
      "\n",
      "        [[-66.3177, -66.3180, -66.3201,  ..., -66.3208, -66.3202, -66.3189]],\n",
      "\n",
      "        [[-66.3188, -66.3203, -66.3183,  ..., -66.3198, -66.3202, -66.3200]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "TorchCPTLayer:\n",
      "                       Input shape: torch.Size([256, 2, 1, 512])\n",
      "                       Input: tensor([[[[-66.2449, -66.2441, -66.2418,  ..., -66.2430, -66.2433, -66.2446]],\n",
      "\n",
      "         [[-66.9880, -66.9885, -66.9872,  ..., -66.9872, -66.9873, -66.9878]]],\n",
      "\n",
      "\n",
      "        [[[-66.2440, -66.2434, -66.2431,  ..., -66.2443, -66.2431, -66.2460]],\n",
      "\n",
      "         [[-66.0575, -66.0548, -66.0568,  ..., -66.0556, -66.0557, -66.0568]]],\n",
      "\n",
      "\n",
      "        [[[-66.0572, -66.0549, -66.0563,  ..., -66.0557, -66.0575, -66.0544]],\n",
      "\n",
      "         [[-66.8258, -66.8249, -66.8246,  ..., -66.8243, -66.8236, -66.8266]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-66.6220, -66.6202, -66.6233,  ..., -66.6201, -66.6217, -66.6197]],\n",
      "\n",
      "         [[-66.5301, -66.5312, -66.5302,  ..., -66.5297, -66.5301, -66.5314]]],\n",
      "\n",
      "\n",
      "        [[[-66.5317, -66.5299, -66.5297,  ..., -66.5318, -66.5312, -66.5301]],\n",
      "\n",
      "         [[-66.3177, -66.3180, -66.3201,  ..., -66.3208, -66.3202, -66.3189]]],\n",
      "\n",
      "\n",
      "        [[[-66.6329, -66.6335, -66.6331,  ..., -66.6333, -66.6357, -66.6331]],\n",
      "\n",
      "         [[-66.3188, -66.3203, -66.3183,  ..., -66.3198, -66.3202, -66.3200]]]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([256, 1, 512])):  tensor([[[-133.2314, -133.2313, -133.2312,  ..., -133.2314, -133.2313,\n",
      "          -133.2314]],\n",
      "\n",
      "        [[-132.3001, -132.3001, -132.3000,  ..., -132.3003, -132.2999,\n",
      "          -132.3000]],\n",
      "\n",
      "        [[-132.8809, -132.8811, -132.8809,  ..., -132.8808, -132.8810,\n",
      "          -132.8810]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-133.1519, -133.1519, -133.1518,  ..., -133.1519, -133.1517,\n",
      "          -133.1517]],\n",
      "\n",
      "        [[-132.8504, -132.8504, -132.8505,  ..., -132.8503, -132.8502,\n",
      "          -132.8504]],\n",
      "\n",
      "        [[-132.9535, -132.9534, -132.9533,  ..., -132.9534, -132.9532,\n",
      "          -132.9534]]], grad_fn=<AddBackward0>)\n",
      "TorchCPTLayer:\n",
      "                       Input shape: torch.Size([128, 2, 1, 512])\n",
      "                       Input: tensor([[[[-133.2314, -133.2313, -133.2312,  ..., -133.2314, -133.2313,\n",
      "           -133.2314]],\n",
      "\n",
      "         [[-132.8809, -132.8811, -132.8809,  ..., -132.8808, -132.8810,\n",
      "           -132.8810]]],\n",
      "\n",
      "\n",
      "        [[[-132.3001, -132.3001, -132.3000,  ..., -132.3003, -132.2999,\n",
      "           -132.3000]],\n",
      "\n",
      "         [[-133.8119, -133.8120, -133.8120,  ..., -133.8119, -133.8119,\n",
      "           -133.8119]]],\n",
      "\n",
      "\n",
      "        [[[-133.3819, -133.3819, -133.3818,  ..., -133.3818, -133.3818,\n",
      "           -133.3817]],\n",
      "\n",
      "         [[-133.5121, -133.5121, -133.5119,  ..., -133.5119, -133.5120,\n",
      "           -133.5120]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-133.2909, -133.2911, -133.2910,  ..., -133.2909, -133.2911,\n",
      "           -133.2909]],\n",
      "\n",
      "         [[-133.0639, -133.0637, -133.0638,  ..., -133.0639, -133.0638,\n",
      "           -133.0638]]],\n",
      "\n",
      "\n",
      "        [[[-133.2545, -133.2545, -133.2548,  ..., -133.2546, -133.2547,\n",
      "           -133.2547]],\n",
      "\n",
      "         [[-132.8504, -132.8504, -132.8505,  ..., -132.8503, -132.8502,\n",
      "           -132.8504]]],\n",
      "\n",
      "\n",
      "        [[[-133.1519, -133.1519, -133.1518,  ..., -133.1519, -133.1517,\n",
      "           -133.1517]],\n",
      "\n",
      "         [[-132.9535, -132.9534, -132.9533,  ..., -132.9534, -132.9532,\n",
      "           -132.9534]]]], grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([128, 1, 512])):  tensor([[[-266.1122, -266.1122, -266.1122,  ..., -266.1122, -266.1122,\n",
      "          -266.1122]],\n",
      "\n",
      "        [[-266.1121, -266.1121, -266.1121,  ..., -266.1121, -266.1121,\n",
      "          -266.1121]],\n",
      "\n",
      "        [[-266.8938, -266.8938, -266.8938,  ..., -266.8938, -266.8938,\n",
      "          -266.8938]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-266.3548, -266.3548, -266.3548,  ..., -266.3548, -266.3548,\n",
      "          -266.3548]],\n",
      "\n",
      "        [[-266.1051, -266.1051, -266.1051,  ..., -266.1051, -266.1051,\n",
      "          -266.1051]],\n",
      "\n",
      "        [[-266.1052, -266.1052, -266.1052,  ..., -266.1052, -266.1052,\n",
      "          -266.1052]]], grad_fn=<AddBackward0>)\n",
      "TorchSumLayer:\n",
      "                       Input shape: torch.Size([64, 2, 1, 512])\n",
      "                       Input: tensor([[[[-266.1122, -266.1122, -266.1122,  ..., -266.1122, -266.1122,\n",
      "           -266.1122]],\n",
      "\n",
      "         [[-266.1121, -266.1121, -266.1121,  ..., -266.1121, -266.1121,\n",
      "           -266.1121]]],\n",
      "\n",
      "\n",
      "        [[[-266.8938, -266.8938, -266.8938,  ..., -266.8938, -266.8938,\n",
      "           -266.8938]],\n",
      "\n",
      "         [[-266.8937, -266.8937, -266.8937,  ..., -266.8937, -266.8937,\n",
      "           -266.8937]]],\n",
      "\n",
      "\n",
      "        [[[-268.0490, -268.0490, -268.0490,  ..., -268.0490, -268.0490,\n",
      "           -268.0490]],\n",
      "\n",
      "         [[-268.0487, -268.0487, -268.0487,  ..., -268.0487, -268.0487,\n",
      "           -268.0487]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-265.5085, -265.5085, -265.5085,  ..., -265.5085, -265.5085,\n",
      "           -265.5085]],\n",
      "\n",
      "         [[-265.5081, -265.5081, -265.5081,  ..., -265.5081, -265.5081,\n",
      "           -265.5081]]],\n",
      "\n",
      "\n",
      "        [[[-266.3548, -266.3548, -266.3548,  ..., -266.3548, -266.3548,\n",
      "           -266.3548]],\n",
      "\n",
      "         [[-266.3548, -266.3548, -266.3548,  ..., -266.3548, -266.3548,\n",
      "           -266.3548]]],\n",
      "\n",
      "\n",
      "        [[[-266.1051, -266.1051, -266.1051,  ..., -266.1051, -266.1051,\n",
      "           -266.1051]],\n",
      "\n",
      "         [[-266.1052, -266.1052, -266.1052,  ..., -266.1052, -266.1052,\n",
      "           -266.1052]]]], grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([64, 1, 512])):  tensor([[[-266.1122, -266.1122, -266.1122,  ..., -266.1122, -266.1122,\n",
      "          -266.1122]],\n",
      "\n",
      "        [[-266.8937, -266.8937, -266.8937,  ..., -266.8937, -266.8937,\n",
      "          -266.8937]],\n",
      "\n",
      "        [[-268.0489, -268.0489, -268.0489,  ..., -268.0489, -268.0489,\n",
      "          -268.0489]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-265.5083, -265.5083, -265.5083,  ..., -265.5083, -265.5083,\n",
      "          -265.5083]],\n",
      "\n",
      "        [[-266.3548, -266.3548, -266.3548,  ..., -266.3548, -266.3548,\n",
      "          -266.3548]],\n",
      "\n",
      "        [[-266.1051, -266.1051, -266.1051,  ..., -266.1051, -266.1051,\n",
      "          -266.1051]]], grad_fn=<AddBackward0>)\n",
      "TorchSumLayer:\n",
      "                       Input shape: torch.Size([128, 1, 1, 512])\n",
      "                       Input: tensor([[[[-266.1122, -266.1122, -266.1122,  ..., -266.1122, -266.1122,\n",
      "           -266.1122]]],\n",
      "\n",
      "\n",
      "        [[[-266.1122, -266.1122, -266.1122,  ..., -266.1122, -266.1122,\n",
      "           -266.1122]]],\n",
      "\n",
      "\n",
      "        [[[-266.8937, -266.8937, -266.8937,  ..., -266.8937, -266.8937,\n",
      "           -266.8937]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-266.3548, -266.3548, -266.3548,  ..., -266.3548, -266.3548,\n",
      "           -266.3548]]],\n",
      "\n",
      "\n",
      "        [[[-266.1051, -266.1051, -266.1051,  ..., -266.1051, -266.1051,\n",
      "           -266.1051]]],\n",
      "\n",
      "\n",
      "        [[[-266.1051, -266.1051, -266.1051,  ..., -266.1051, -266.1051,\n",
      "           -266.1051]]]], grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([128, 1, 512])):  tensor([[[-266.1122, -266.1122, -266.1122,  ..., -266.1122, -266.1122,\n",
      "          -266.1122]],\n",
      "\n",
      "        [[-266.1122, -266.1122, -266.1122,  ..., -266.1122, -266.1122,\n",
      "          -266.1122]],\n",
      "\n",
      "        [[-266.8937, -266.8937, -266.8937,  ..., -266.8937, -266.8937,\n",
      "          -266.8937]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-266.3548, -266.3548, -266.3548,  ..., -266.3548, -266.3548,\n",
      "          -266.3548]],\n",
      "\n",
      "        [[-266.1051, -266.1051, -266.1051,  ..., -266.1051, -266.1051,\n",
      "          -266.1051]],\n",
      "\n",
      "        [[-266.1051, -266.1051, -266.1051,  ..., -266.1051, -266.1051,\n",
      "          -266.1051]]], grad_fn=<AddBackward0>)\n",
      "TorchCPTLayer:\n",
      "                       Input shape: torch.Size([64, 2, 1, 512])\n",
      "                       Input: tensor([[[[-266.1122, -266.1122, -266.1122,  ..., -266.1122, -266.1122,\n",
      "           -266.1122]],\n",
      "\n",
      "         [[-266.8937, -266.8937, -266.8937,  ..., -266.8937, -266.8937,\n",
      "           -266.8937]]],\n",
      "\n",
      "\n",
      "        [[[-268.0489, -268.0489, -268.0489,  ..., -268.0489, -268.0489,\n",
      "           -268.0489]],\n",
      "\n",
      "         [[-266.9195, -266.9195, -266.9195,  ..., -266.9195, -266.9195,\n",
      "           -266.9195]]],\n",
      "\n",
      "\n",
      "        [[[-266.2654, -266.2654, -266.2654,  ..., -266.2654, -266.2654,\n",
      "           -266.2654]],\n",
      "\n",
      "         [[-265.8720, -265.8720, -265.8720,  ..., -265.8720, -265.8720,\n",
      "           -265.8720]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-266.1331, -266.1331, -266.1331,  ..., -266.1331, -266.1331,\n",
      "           -266.1331]],\n",
      "\n",
      "         [[-266.3548, -266.3548, -266.3548,  ..., -266.3548, -266.3548,\n",
      "           -266.3548]]],\n",
      "\n",
      "\n",
      "        [[[-266.3548, -266.3548, -266.3548,  ..., -266.3548, -266.3548,\n",
      "           -266.3548]],\n",
      "\n",
      "         [[-266.1051, -266.1051, -266.1051,  ..., -266.1051, -266.1051,\n",
      "           -266.1051]]],\n",
      "\n",
      "\n",
      "        [[[-265.9516, -265.9516, -265.9516,  ..., -265.9516, -265.9516,\n",
      "           -265.9516]],\n",
      "\n",
      "         [[-266.1051, -266.1051, -266.1051,  ..., -266.1051, -266.1051,\n",
      "           -266.1051]]]], grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([64, 1, 512])):  tensor([[[-533.0059, -533.0059, -533.0059,  ..., -533.0059, -533.0059,\n",
      "          -533.0059]],\n",
      "\n",
      "        [[-534.9684, -534.9684, -534.9684,  ..., -534.9684, -534.9684,\n",
      "          -534.9684]],\n",
      "\n",
      "        [[-532.1375, -532.1375, -532.1375,  ..., -532.1375, -532.1375,\n",
      "          -532.1375]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-532.4879, -532.4879, -532.4879,  ..., -532.4879, -532.4879,\n",
      "          -532.4879]],\n",
      "\n",
      "        [[-532.4599, -532.4599, -532.4599,  ..., -532.4599, -532.4599,\n",
      "          -532.4599]],\n",
      "\n",
      "        [[-532.0568, -532.0568, -532.0568,  ..., -532.0568, -532.0568,\n",
      "          -532.0568]]], grad_fn=<AddBackward0>)\n",
      "TorchHadamardLayer:\n",
      "                       Input shape: torch.Size([32, 2, 1, 512])\n",
      "                       Input: tensor([[[[-533.0059, -533.0059, -533.0059,  ..., -533.0059, -533.0059,\n",
      "           -533.0059]],\n",
      "\n",
      "         [[-533.5314, -533.5314, -533.5314,  ..., -533.5314, -533.5314,\n",
      "           -533.5314]]],\n",
      "\n",
      "\n",
      "        [[[-532.9641, -532.9641, -532.9641,  ..., -532.9641, -532.9641,\n",
      "           -532.9641]],\n",
      "\n",
      "         [[-533.5732, -533.5732, -533.5732,  ..., -533.5732, -533.5732,\n",
      "           -533.5732]]],\n",
      "\n",
      "\n",
      "        [[[-534.9684, -534.9684, -534.9684,  ..., -534.9684, -534.9684,\n",
      "           -534.9684]],\n",
      "\n",
      "         [[-531.4554, -531.4554, -531.4554,  ..., -531.4554, -531.4554,\n",
      "           -531.4554]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-531.8855, -531.8855, -531.8855,  ..., -531.8855, -531.8855,\n",
      "           -531.8855]],\n",
      "\n",
      "         [[-532.1003, -532.1003, -532.1003,  ..., -532.1003, -532.1003,\n",
      "           -532.1003]]],\n",
      "\n",
      "\n",
      "        [[[-532.0847, -532.0847, -532.0847,  ..., -532.0847, -532.0847,\n",
      "           -532.0847]],\n",
      "\n",
      "         [[-532.4599, -532.4599, -532.4599,  ..., -532.4599, -532.4599,\n",
      "           -532.4599]]],\n",
      "\n",
      "\n",
      "        [[[-532.4879, -532.4879, -532.4879,  ..., -532.4879, -532.4879,\n",
      "           -532.4879]],\n",
      "\n",
      "         [[-532.0568, -532.0568, -532.0568,  ..., -532.0568, -532.0568,\n",
      "           -532.0568]]]], grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([32, 1, 512])):  tensor([[[-1066.5374, -1066.5374, -1066.5374,  ..., -1066.5374,\n",
      "          -1066.5374, -1066.5374]],\n",
      "\n",
      "        [[-1066.5374, -1066.5374, -1066.5374,  ..., -1066.5374,\n",
      "          -1066.5374, -1066.5374]],\n",
      "\n",
      "        [[-1066.4238, -1066.4238, -1066.4238,  ..., -1066.4238,\n",
      "          -1066.4238, -1066.4238]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1063.9858, -1063.9858, -1063.9858,  ..., -1063.9858,\n",
      "          -1063.9858, -1063.9858]],\n",
      "\n",
      "        [[-1064.5447, -1064.5447, -1064.5447,  ..., -1064.5447,\n",
      "          -1064.5447, -1064.5447]],\n",
      "\n",
      "        [[-1064.5447, -1064.5447, -1064.5447,  ..., -1064.5447,\n",
      "          -1064.5447, -1064.5447]]], grad_fn=<SumBackward1>)\n",
      "TorchSumLayer:\n",
      "                       Input shape: torch.Size([16, 2, 1, 512])\n",
      "                       Input: tensor([[[[-1066.5374, -1066.5374, -1066.5374,  ..., -1066.5374,\n",
      "           -1066.5374, -1066.5374]],\n",
      "\n",
      "         [[-1066.5374, -1066.5374, -1066.5374,  ..., -1066.5374,\n",
      "           -1066.5374, -1066.5374]]],\n",
      "\n",
      "\n",
      "        [[[-1066.4238, -1066.4238, -1066.4238,  ..., -1066.4238,\n",
      "           -1066.4238, -1066.4238]],\n",
      "\n",
      "         [[-1066.4238, -1066.4238, -1066.4238,  ..., -1066.4238,\n",
      "           -1066.4238, -1066.4238]]],\n",
      "\n",
      "\n",
      "        [[[-1064.1858, -1064.1858, -1064.1858,  ..., -1064.1858,\n",
      "           -1064.1858, -1064.1858]],\n",
      "\n",
      "         [[-1064.1858, -1064.1858, -1064.1858,  ..., -1064.1858,\n",
      "           -1064.1858, -1064.1858]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1064.7394, -1064.7394, -1064.7394,  ..., -1064.7394,\n",
      "           -1064.7394, -1064.7394]],\n",
      "\n",
      "         [[-1064.7394, -1064.7394, -1064.7394,  ..., -1064.7394,\n",
      "           -1064.7394, -1064.7394]]],\n",
      "\n",
      "\n",
      "        [[[-1063.9858, -1063.9858, -1063.9858,  ..., -1063.9858,\n",
      "           -1063.9858, -1063.9858]],\n",
      "\n",
      "         [[-1063.9858, -1063.9858, -1063.9858,  ..., -1063.9858,\n",
      "           -1063.9858, -1063.9858]]],\n",
      "\n",
      "\n",
      "        [[[-1064.5447, -1064.5447, -1064.5447,  ..., -1064.5447,\n",
      "           -1064.5447, -1064.5447]],\n",
      "\n",
      "         [[-1064.5447, -1064.5447, -1064.5447,  ..., -1064.5447,\n",
      "           -1064.5447, -1064.5447]]]], grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([16, 1, 512])):  tensor([[[-1066.5374, -1066.5374, -1066.5374,  ..., -1066.5374,\n",
      "          -1066.5374, -1066.5374]],\n",
      "\n",
      "        [[-1066.4238, -1066.4238, -1066.4238,  ..., -1066.4238,\n",
      "          -1066.4238, -1066.4238]],\n",
      "\n",
      "        [[-1064.1858, -1064.1858, -1064.1858,  ..., -1064.1858,\n",
      "          -1064.1858, -1064.1858]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1064.7394, -1064.7394, -1064.7394,  ..., -1064.7394,\n",
      "          -1064.7394, -1064.7394]],\n",
      "\n",
      "        [[-1063.9858, -1063.9858, -1063.9858,  ..., -1063.9858,\n",
      "          -1063.9858, -1063.9858]],\n",
      "\n",
      "        [[-1064.5447, -1064.5447, -1064.5447,  ..., -1064.5447,\n",
      "          -1064.5447, -1064.5447]]], grad_fn=<AddBackward0>)\n",
      "TorchSumLayer:\n",
      "                       Input shape: torch.Size([32, 1, 1, 512])\n",
      "                       Input: tensor([[[[-1066.5374, -1066.5374, -1066.5374,  ..., -1066.5374,\n",
      "           -1066.5374, -1066.5374]]],\n",
      "\n",
      "\n",
      "        [[[-1066.5374, -1066.5374, -1066.5374,  ..., -1066.5374,\n",
      "           -1066.5374, -1066.5374]]],\n",
      "\n",
      "\n",
      "        [[[-1066.4238, -1066.4238, -1066.4238,  ..., -1066.4238,\n",
      "           -1066.4238, -1066.4238]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1063.9858, -1063.9858, -1063.9858,  ..., -1063.9858,\n",
      "           -1063.9858, -1063.9858]]],\n",
      "\n",
      "\n",
      "        [[[-1064.5447, -1064.5447, -1064.5447,  ..., -1064.5447,\n",
      "           -1064.5447, -1064.5447]]],\n",
      "\n",
      "\n",
      "        [[[-1064.5447, -1064.5447, -1064.5447,  ..., -1064.5447,\n",
      "           -1064.5447, -1064.5447]]]], grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([32, 1, 512])):  tensor([[[-1066.5374, -1066.5374, -1066.5374,  ..., -1066.5374,\n",
      "          -1066.5374, -1066.5374]],\n",
      "\n",
      "        [[-1066.5374, -1066.5374, -1066.5374,  ..., -1066.5374,\n",
      "          -1066.5374, -1066.5374]],\n",
      "\n",
      "        [[-1066.4238, -1066.4238, -1066.4238,  ..., -1066.4238,\n",
      "          -1066.4238, -1066.4238]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1063.9858, -1063.9858, -1063.9858,  ..., -1063.9858,\n",
      "          -1063.9858, -1063.9858]],\n",
      "\n",
      "        [[-1064.5447, -1064.5447, -1064.5447,  ..., -1064.5447,\n",
      "          -1064.5447, -1064.5447]],\n",
      "\n",
      "        [[-1064.5447, -1064.5447, -1064.5447,  ..., -1064.5447,\n",
      "          -1064.5447, -1064.5447]]], grad_fn=<AddBackward0>)\n",
      "TorchCPTLayer:\n",
      "                       Input shape: torch.Size([16, 2, 1, 512])\n",
      "                       Input: tensor([[[[-1066.5374, -1066.5374, -1066.5374,  ..., -1066.5374,\n",
      "           -1066.5374, -1066.5374]],\n",
      "\n",
      "         [[-1066.4238, -1066.4238, -1066.4238,  ..., -1066.4238,\n",
      "           -1066.4238, -1066.4238]]],\n",
      "\n",
      "\n",
      "        [[[-1064.1858, -1064.1858, -1064.1858,  ..., -1064.1858,\n",
      "           -1064.1858, -1064.1858]],\n",
      "\n",
      "         [[-1067.7048, -1067.7048, -1067.7048,  ..., -1067.7048,\n",
      "           -1067.7048, -1067.7048]]],\n",
      "\n",
      "\n",
      "        [[[-1066.5374, -1066.5374, -1066.5374,  ..., -1066.5374,\n",
      "           -1066.5374, -1066.5374]],\n",
      "\n",
      "         [[-1064.6652, -1064.6652, -1064.6652,  ..., -1064.6652,\n",
      "           -1064.6652, -1064.6652]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1064.3457, -1064.3457, -1064.3457,  ..., -1064.3457,\n",
      "           -1064.3457, -1064.3457]],\n",
      "\n",
      "         [[-1063.9858, -1063.9858, -1063.9858,  ..., -1063.9858,\n",
      "           -1063.9858, -1063.9858]]],\n",
      "\n",
      "\n",
      "        [[[-1063.9858, -1063.9858, -1063.9858,  ..., -1063.9858,\n",
      "           -1063.9858, -1063.9858]],\n",
      "\n",
      "         [[-1064.5447, -1064.5447, -1064.5447,  ..., -1064.5447,\n",
      "           -1064.5447, -1064.5447]]],\n",
      "\n",
      "\n",
      "        [[[-1064.2551, -1064.2551, -1064.2551,  ..., -1064.2551,\n",
      "           -1064.2551, -1064.2551]],\n",
      "\n",
      "         [[-1064.5447, -1064.5447, -1064.5447,  ..., -1064.5447,\n",
      "           -1064.5447, -1064.5447]]]], grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([16, 1, 512])):  tensor([[[-2132.9612, -2132.9612, -2132.9612,  ..., -2132.9612,\n",
      "          -2132.9612, -2132.9612]],\n",
      "\n",
      "        [[-2131.8906, -2131.8906, -2131.8906,  ..., -2131.8906,\n",
      "          -2131.8906, -2131.8906]],\n",
      "\n",
      "        [[-2131.2026, -2131.2026, -2131.2026,  ..., -2131.2026,\n",
      "          -2131.2026, -2131.2026]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2128.3315, -2128.3315, -2128.3315,  ..., -2128.3315,\n",
      "          -2128.3315, -2128.3315]],\n",
      "\n",
      "        [[-2128.5305, -2128.5305, -2128.5305,  ..., -2128.5305,\n",
      "          -2128.5305, -2128.5305]],\n",
      "\n",
      "        [[-2128.7998, -2128.7998, -2128.7998,  ..., -2128.7998,\n",
      "          -2128.7998, -2128.7998]]], grad_fn=<AddBackward0>)\n",
      "TorchHadamardLayer:\n",
      "                       Input shape: torch.Size([8, 2, 1, 512])\n",
      "                       Input: tensor([[[[-2132.9612, -2132.9612, -2132.9612,  ..., -2132.9612,\n",
      "           -2132.9612, -2132.9612]],\n",
      "\n",
      "         [[-2127.8691, -2127.8691, -2127.8691,  ..., -2127.8691,\n",
      "           -2127.8691, -2127.8691]]],\n",
      "\n",
      "\n",
      "        [[[-2131.2026, -2131.2026, -2131.2026,  ..., -2131.2026,\n",
      "           -2131.2026, -2131.2026]],\n",
      "\n",
      "         [[-2129.6279, -2129.6279, -2129.6279,  ..., -2129.6279,\n",
      "           -2129.6279, -2129.6279]]],\n",
      "\n",
      "\n",
      "        [[[-2131.8906, -2131.8906, -2131.8906,  ..., -2131.8906,\n",
      "           -2131.8906, -2131.8906]],\n",
      "\n",
      "         [[-2133.3677, -2133.3677, -2133.3677,  ..., -2133.3677,\n",
      "           -2133.3677, -2133.3677]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2131.9292, -2131.9292, -2131.9292,  ..., -2131.9292,\n",
      "           -2131.9292, -2131.9292]],\n",
      "\n",
      "         [[-2129.9741, -2129.9741, -2129.9741,  ..., -2129.9741,\n",
      "           -2129.9741, -2129.9741]]],\n",
      "\n",
      "\n",
      "        [[[-2128.6008, -2128.6008, -2128.6008,  ..., -2128.6008,\n",
      "           -2128.6008, -2128.6008]],\n",
      "\n",
      "         [[-2128.5305, -2128.5305, -2128.5305,  ..., -2128.5305,\n",
      "           -2128.5305, -2128.5305]]],\n",
      "\n",
      "\n",
      "        [[[-2128.3315, -2128.3315, -2128.3315,  ..., -2128.3315,\n",
      "           -2128.3315, -2128.3315]],\n",
      "\n",
      "         [[-2128.7998, -2128.7998, -2128.7998,  ..., -2128.7998,\n",
      "           -2128.7998, -2128.7998]]]], grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([8, 1, 512])):  tensor([[[-4260.8301, -4260.8301, -4260.8301,  ..., -4260.8301,\n",
      "          -4260.8301, -4260.8301]],\n",
      "\n",
      "        [[-4260.8306, -4260.8306, -4260.8306,  ..., -4260.8306,\n",
      "          -4260.8306, -4260.8306]],\n",
      "\n",
      "        [[-4265.2583, -4265.2583, -4265.2583,  ..., -4265.2583,\n",
      "          -4265.2583, -4265.2583]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4261.9033, -4261.9033, -4261.9033,  ..., -4261.9033,\n",
      "          -4261.9033, -4261.9033]],\n",
      "\n",
      "        [[-4257.1313, -4257.1313, -4257.1313,  ..., -4257.1313,\n",
      "          -4257.1313, -4257.1313]],\n",
      "\n",
      "        [[-4257.1313, -4257.1313, -4257.1313,  ..., -4257.1313,\n",
      "          -4257.1313, -4257.1313]]], grad_fn=<SumBackward1>)\n",
      "TorchSumLayer:\n",
      "                       Input shape: torch.Size([4, 2, 1, 512])\n",
      "                       Input: tensor([[[[-4260.8301, -4260.8301, -4260.8301,  ..., -4260.8301,\n",
      "           -4260.8301, -4260.8301]],\n",
      "\n",
      "         [[-4260.8306, -4260.8306, -4260.8306,  ..., -4260.8306,\n",
      "           -4260.8306, -4260.8306]]],\n",
      "\n",
      "\n",
      "        [[[-4265.2583, -4265.2583, -4265.2583,  ..., -4265.2583,\n",
      "           -4265.2583, -4265.2583]],\n",
      "\n",
      "         [[-4265.2583, -4265.2583, -4265.2583,  ..., -4265.2583,\n",
      "           -4265.2583, -4265.2583]]],\n",
      "\n",
      "\n",
      "        [[[-4261.9033, -4261.9033, -4261.9033,  ..., -4261.9033,\n",
      "           -4261.9033, -4261.9033]],\n",
      "\n",
      "         [[-4261.9033, -4261.9033, -4261.9033,  ..., -4261.9033,\n",
      "           -4261.9033, -4261.9033]]],\n",
      "\n",
      "\n",
      "        [[[-4257.1313, -4257.1313, -4257.1313,  ..., -4257.1313,\n",
      "           -4257.1313, -4257.1313]],\n",
      "\n",
      "         [[-4257.1313, -4257.1313, -4257.1313,  ..., -4257.1313,\n",
      "           -4257.1313, -4257.1313]]]], grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([4, 1, 512])):  tensor([[[-4260.8306, -4260.8301, -4260.8301,  ..., -4260.8306,\n",
      "          -4260.8301, -4260.8301]],\n",
      "\n",
      "        [[-4265.2583, -4265.2583, -4265.2583,  ..., -4265.2583,\n",
      "          -4265.2583, -4265.2583]],\n",
      "\n",
      "        [[-4261.9033, -4261.9033, -4261.9033,  ..., -4261.9033,\n",
      "          -4261.9033, -4261.9033]],\n",
      "\n",
      "        [[-4257.1313, -4257.1313, -4257.1313,  ..., -4257.1313,\n",
      "          -4257.1313, -4257.1313]]], grad_fn=<AddBackward0>)\n",
      "TorchSumLayer:\n",
      "                       Input shape: torch.Size([8, 1, 1, 512])\n",
      "                       Input: tensor([[[[-4260.8306, -4260.8301, -4260.8301,  ..., -4260.8306,\n",
      "           -4260.8301, -4260.8301]]],\n",
      "\n",
      "\n",
      "        [[[-4260.8306, -4260.8301, -4260.8301,  ..., -4260.8306,\n",
      "           -4260.8301, -4260.8301]]],\n",
      "\n",
      "\n",
      "        [[[-4265.2583, -4265.2583, -4265.2583,  ..., -4265.2583,\n",
      "           -4265.2583, -4265.2583]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4261.9033, -4261.9033, -4261.9033,  ..., -4261.9033,\n",
      "           -4261.9033, -4261.9033]]],\n",
      "\n",
      "\n",
      "        [[[-4257.1313, -4257.1313, -4257.1313,  ..., -4257.1313,\n",
      "           -4257.1313, -4257.1313]]],\n",
      "\n",
      "\n",
      "        [[[-4257.1313, -4257.1313, -4257.1313,  ..., -4257.1313,\n",
      "           -4257.1313, -4257.1313]]]], grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([8, 1, 512])):  tensor([[[-4260.8301, -4260.8301, -4260.8301,  ..., -4260.8301,\n",
      "          -4260.8301, -4260.8301]],\n",
      "\n",
      "        [[-4260.8301, -4260.8301, -4260.8301,  ..., -4260.8301,\n",
      "          -4260.8306, -4260.8301]],\n",
      "\n",
      "        [[-4265.2583, -4265.2583, -4265.2583,  ..., -4265.2583,\n",
      "          -4265.2583, -4265.2583]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4261.9033, -4261.9033, -4261.9033,  ..., -4261.9033,\n",
      "          -4261.9033, -4261.9033]],\n",
      "\n",
      "        [[-4257.1313, -4257.1313, -4257.1313,  ..., -4257.1313,\n",
      "          -4257.1313, -4257.1313]],\n",
      "\n",
      "        [[-4257.1313, -4257.1313, -4257.1313,  ..., -4257.1313,\n",
      "          -4257.1313, -4257.1313]]], grad_fn=<AddBackward0>)\n",
      "TorchCPTLayer:\n",
      "                       Input shape: torch.Size([4, 2, 1, 512])\n",
      "                       Input: tensor([[[[-4260.8301, -4260.8301, -4260.8301,  ..., -4260.8301,\n",
      "           -4260.8301, -4260.8301]],\n",
      "\n",
      "         [[-4265.2583, -4265.2583, -4265.2583,  ..., -4265.2583,\n",
      "           -4265.2583, -4265.2583]]],\n",
      "\n",
      "\n",
      "        [[[-4260.8301, -4260.8301, -4260.8301,  ..., -4260.8301,\n",
      "           -4260.8306, -4260.8301]],\n",
      "\n",
      "         [[-4261.9033, -4261.9033, -4261.9033,  ..., -4261.9033,\n",
      "           -4261.9033, -4261.9033]]],\n",
      "\n",
      "\n",
      "        [[[-4261.9033, -4261.9033, -4261.9033,  ..., -4261.9033,\n",
      "           -4261.9033, -4261.9033]],\n",
      "\n",
      "         [[-4257.1313, -4257.1313, -4257.1313,  ..., -4257.1313,\n",
      "           -4257.1313, -4257.1313]]],\n",
      "\n",
      "\n",
      "        [[[-4265.2583, -4265.2583, -4265.2583,  ..., -4265.2583,\n",
      "           -4265.2583, -4265.2583]],\n",
      "\n",
      "         [[-4257.1313, -4257.1313, -4257.1313,  ..., -4257.1313,\n",
      "           -4257.1313, -4257.1313]]]], grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([4, 1, 512])):  tensor([[[-8526.0879, -8526.0879, -8526.0879,  ..., -8526.0879,\n",
      "          -8526.0879, -8526.0879]],\n",
      "\n",
      "        [[-8522.7334, -8522.7334, -8522.7334,  ..., -8522.7334,\n",
      "          -8522.7334, -8522.7334]],\n",
      "\n",
      "        [[-8519.0352, -8519.0352, -8519.0352,  ..., -8519.0352,\n",
      "          -8519.0352, -8519.0352]],\n",
      "\n",
      "        [[-8522.3896, -8522.3896, -8522.3896,  ..., -8522.3896,\n",
      "          -8522.3896, -8522.3896]]], grad_fn=<AddBackward0>)\n",
      "TorchCPTLayer:\n",
      "                       Input shape: torch.Size([2, 2, 1, 512])\n",
      "                       Input: tensor([[[[-8526.0879, -8526.0879, -8526.0879,  ..., -8526.0879,\n",
      "           -8526.0879, -8526.0879]],\n",
      "\n",
      "         [[-8519.0352, -8519.0352, -8519.0352,  ..., -8519.0352,\n",
      "           -8519.0352, -8519.0352]]],\n",
      "\n",
      "\n",
      "        [[[-8522.7334, -8522.7334, -8522.7334,  ..., -8522.7334,\n",
      "           -8522.7334, -8522.7334]],\n",
      "\n",
      "         [[-8522.3896, -8522.3896, -8522.3896,  ..., -8522.3896,\n",
      "           -8522.3896, -8522.3896]]]], grad_fn=<IndexBackward0>)\n",
      "Output (torch.Size([2, 1, 1])):  tensor([[[-17045.1230]],\n",
      "\n",
      "        [[-17045.1230]]], grad_fn=<AddBackward0>)\n",
      "TorchSumLayer:\n",
      "                       Input shape: torch.Size([1, 2, 1, 1])\n",
      "                       Input: tensor([[[[-17045.1230]],\n",
      "\n",
      "         [[-17045.1230]]]], grad_fn=<UnsqueezeBackward0>)\n",
      "Output (torch.Size([1, 1, 1])):  tensor([[[-17045.1230]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-17045.1230]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(example_data.reshape(1,-1))\n",
    "\n",
    "cbase(example_data.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9580536e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchSharedParameter(\n",
       "  output-shape: (3072, 512, 256)\n",
       "  (internal_param): ModuleList(\n",
       "    (0): TorchTensorParameter(output-shape: (48, 512, 256))\n",
       "    (1): TorchSoftmaxParameter(\n",
       "      input-shapes: [(48, 512, 256)]\n",
       "      output-shape: (48, 512, 256)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbase.layers[0].probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55408542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.2929e-02, 1.2673e-02, 1.3991e-03,  ..., 4.2933e-03,\n",
       "          5.4251e-03, 1.1941e-03],\n",
       "         [1.6076e-03, 1.9501e-04, 1.3110e-03,  ..., 3.0377e-03,\n",
       "          1.2048e-03, 1.7922e-03],\n",
       "         [2.3351e-03, 1.1709e-03, 2.8509e-03,  ..., 4.5627e-03,\n",
       "          3.3654e-03, 1.8465e-03],\n",
       "         ...,\n",
       "         [3.8859e-03, 3.2517e-04, 6.2499e-03,  ..., 7.5306e-04,\n",
       "          1.3511e-03, 2.3571e-03],\n",
       "         [6.6722e-03, 4.4425e-03, 6.9162e-03,  ..., 2.1398e-03,\n",
       "          1.6363e-03, 2.9410e-03],\n",
       "         [2.3152e-03, 7.2537e-04, 2.9835e-03,  ..., 1.7328e-03,\n",
       "          1.0447e-03, 1.4942e-03]],\n",
       "\n",
       "        [[1.2807e-03, 2.0195e-02, 1.2609e-03,  ..., 1.2189e-03,\n",
       "          1.3611e-03, 5.2363e-04],\n",
       "         [1.0251e-02, 2.2320e-03, 6.3639e-03,  ..., 8.4052e-04,\n",
       "          2.1866e-03, 1.2582e-03],\n",
       "         [7.5096e-03, 2.1310e-03, 1.2494e-03,  ..., 1.2873e-03,\n",
       "          9.7402e-03, 5.6151e-03],\n",
       "         ...,\n",
       "         [4.3466e-04, 3.4471e-03, 2.9194e-04,  ..., 2.3836e-03,\n",
       "          5.2810e-04, 4.6492e-03],\n",
       "         [1.4732e-03, 4.7463e-04, 1.3636e-02,  ..., 5.0658e-04,\n",
       "          1.3624e-03, 1.9269e-03],\n",
       "         [9.5118e-04, 6.1216e-03, 1.6440e-03,  ..., 6.7781e-04,\n",
       "          5.1532e-03, 3.0966e-04]],\n",
       "\n",
       "        [[5.9309e-03, 9.9889e-03, 7.0671e-03,  ..., 2.6720e-04,\n",
       "          1.4626e-02, 6.9795e-04],\n",
       "         [1.4690e-03, 5.1312e-02, 7.7640e-03,  ..., 9.6497e-04,\n",
       "          1.5326e-03, 1.5278e-03],\n",
       "         [7.4303e-03, 1.3754e-03, 2.9629e-04,  ..., 1.7376e-03,\n",
       "          3.4315e-04, 1.6318e-03],\n",
       "         ...,\n",
       "         [1.6234e-03, 7.9494e-04, 2.3910e-03,  ..., 6.5955e-03,\n",
       "          1.1325e-02, 7.8148e-04],\n",
       "         [4.3739e-03, 1.7034e-03, 5.2030e-03,  ..., 1.6177e-03,\n",
       "          4.9807e-03, 8.3566e-03],\n",
       "         [1.1381e-03, 1.5825e-03, 3.3568e-03,  ..., 1.9053e-02,\n",
       "          2.6916e-03, 2.2199e-03]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.1834e-03, 1.0804e-03, 6.9547e-03,  ..., 7.5066e-04,\n",
       "          2.8416e-03, 4.7108e-03],\n",
       "         [7.8978e-04, 9.0746e-03, 1.6436e-03,  ..., 4.1029e-03,\n",
       "          5.7768e-03, 5.6784e-03],\n",
       "         [3.5506e-03, 1.3756e-03, 2.5156e-02,  ..., 1.2855e-03,\n",
       "          6.4019e-03, 8.2755e-03],\n",
       "         ...,\n",
       "         [1.4778e-02, 2.9110e-03, 2.0452e-02,  ..., 2.6448e-03,\n",
       "          1.9619e-03, 3.6661e-03],\n",
       "         [6.6651e-04, 6.4100e-04, 4.8872e-04,  ..., 6.0096e-03,\n",
       "          1.7261e-03, 2.4877e-03],\n",
       "         [1.9461e-03, 1.0824e-02, 8.7529e-04,  ..., 1.0222e-03,\n",
       "          2.2395e-03, 1.0053e-02]],\n",
       "\n",
       "        [[1.0159e-03, 6.2319e-03, 2.2629e-03,  ..., 1.7951e-03,\n",
       "          7.5702e-04, 5.2161e-03],\n",
       "         [1.5449e-03, 1.2311e-02, 5.3718e-04,  ..., 3.0231e-03,\n",
       "          1.5314e-03, 1.9029e-03],\n",
       "         [5.1014e-03, 1.0924e-03, 1.4512e-02,  ..., 3.3927e-02,\n",
       "          5.1772e-03, 6.6372e-03],\n",
       "         ...,\n",
       "         [1.7778e-03, 5.7014e-03, 1.4491e-03,  ..., 3.0638e-04,\n",
       "          5.7278e-03, 5.7545e-04],\n",
       "         [5.4491e-03, 6.3985e-03, 5.8996e-03,  ..., 6.4843e-03,\n",
       "          8.3675e-05, 7.8245e-04],\n",
       "         [5.0416e-03, 5.5998e-04, 1.1673e-03,  ..., 1.9357e-03,\n",
       "          6.7441e-03, 2.8442e-03]],\n",
       "\n",
       "        [[3.3748e-04, 6.9812e-03, 3.0470e-04,  ..., 2.7511e-03,\n",
       "          1.7121e-03, 2.4357e-03],\n",
       "         [2.1652e-03, 1.7404e-03, 1.3108e-03,  ..., 7.4060e-03,\n",
       "          7.7573e-03, 3.8629e-04],\n",
       "         [1.2617e-03, 1.4121e-03, 3.1059e-04,  ..., 8.2836e-04,\n",
       "          9.3627e-03, 2.6152e-03],\n",
       "         ...,\n",
       "         [3.0332e-03, 1.0643e-02, 3.2283e-03,  ..., 3.9620e-04,\n",
       "          1.0207e-03, 4.7555e-03],\n",
       "         [7.7205e-04, 2.4430e-03, 1.2793e-03,  ..., 4.2910e-03,\n",
       "          1.0462e-03, 6.2221e-03],\n",
       "         [3.2144e-03, 1.1072e-03, 2.7979e-04,  ..., 6.8114e-04,\n",
       "          2.1107e-03, 1.6171e-03]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbase.layers[0].probs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a73947cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchCategoricalLayer(\n",
       "  folds: 48  variables: 1  output-units: 512\n",
       "  input-shape: (48, 1, -1, 1)\n",
       "  output-shape: (48, -1, 512)\n",
       "  (probs): TorchParameter(\n",
       "    shape: (48, 512, 256)\n",
       "    (0): TorchTensorParameter(output-shape: (48, 512, 256))\n",
       "    (1): TorchSoftmaxParameter(\n",
       "      input-shapes: [(48, 512, 256)]\n",
       "      output-shape: (48, 512, 256)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpatch.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "148d6f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.2929e-02, 1.2673e-02, 1.3991e-03,  ..., 4.2933e-03,\n",
       "          5.4251e-03, 1.1941e-03],\n",
       "         [1.6076e-03, 1.9501e-04, 1.3110e-03,  ..., 3.0377e-03,\n",
       "          1.2048e-03, 1.7922e-03],\n",
       "         [2.3351e-03, 1.1709e-03, 2.8509e-03,  ..., 4.5627e-03,\n",
       "          3.3654e-03, 1.8465e-03],\n",
       "         ...,\n",
       "         [3.8859e-03, 3.2517e-04, 6.2499e-03,  ..., 7.5306e-04,\n",
       "          1.3511e-03, 2.3571e-03],\n",
       "         [6.6722e-03, 4.4425e-03, 6.9162e-03,  ..., 2.1398e-03,\n",
       "          1.6363e-03, 2.9410e-03],\n",
       "         [2.3152e-03, 7.2537e-04, 2.9835e-03,  ..., 1.7328e-03,\n",
       "          1.0447e-03, 1.4942e-03]],\n",
       "\n",
       "        [[1.2807e-03, 2.0195e-02, 1.2609e-03,  ..., 1.2189e-03,\n",
       "          1.3611e-03, 5.2363e-04],\n",
       "         [1.0251e-02, 2.2320e-03, 6.3639e-03,  ..., 8.4052e-04,\n",
       "          2.1866e-03, 1.2582e-03],\n",
       "         [7.5096e-03, 2.1310e-03, 1.2494e-03,  ..., 1.2873e-03,\n",
       "          9.7402e-03, 5.6151e-03],\n",
       "         ...,\n",
       "         [4.3466e-04, 3.4471e-03, 2.9194e-04,  ..., 2.3836e-03,\n",
       "          5.2810e-04, 4.6492e-03],\n",
       "         [1.4732e-03, 4.7463e-04, 1.3636e-02,  ..., 5.0658e-04,\n",
       "          1.3624e-03, 1.9269e-03],\n",
       "         [9.5118e-04, 6.1216e-03, 1.6440e-03,  ..., 6.7781e-04,\n",
       "          5.1532e-03, 3.0966e-04]],\n",
       "\n",
       "        [[5.9309e-03, 9.9889e-03, 7.0671e-03,  ..., 2.6720e-04,\n",
       "          1.4626e-02, 6.9795e-04],\n",
       "         [1.4690e-03, 5.1312e-02, 7.7640e-03,  ..., 9.6497e-04,\n",
       "          1.5326e-03, 1.5278e-03],\n",
       "         [7.4303e-03, 1.3754e-03, 2.9629e-04,  ..., 1.7376e-03,\n",
       "          3.4315e-04, 1.6318e-03],\n",
       "         ...,\n",
       "         [1.6234e-03, 7.9494e-04, 2.3910e-03,  ..., 6.5955e-03,\n",
       "          1.1325e-02, 7.8148e-04],\n",
       "         [4.3739e-03, 1.7034e-03, 5.2030e-03,  ..., 1.6177e-03,\n",
       "          4.9807e-03, 8.3566e-03],\n",
       "         [1.1381e-03, 1.5825e-03, 3.3568e-03,  ..., 1.9053e-02,\n",
       "          2.6916e-03, 2.2199e-03]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.1834e-03, 1.0804e-03, 6.9547e-03,  ..., 7.5066e-04,\n",
       "          2.8416e-03, 4.7108e-03],\n",
       "         [7.8978e-04, 9.0746e-03, 1.6436e-03,  ..., 4.1029e-03,\n",
       "          5.7768e-03, 5.6784e-03],\n",
       "         [3.5506e-03, 1.3756e-03, 2.5156e-02,  ..., 1.2855e-03,\n",
       "          6.4019e-03, 8.2755e-03],\n",
       "         ...,\n",
       "         [1.4778e-02, 2.9110e-03, 2.0452e-02,  ..., 2.6448e-03,\n",
       "          1.9619e-03, 3.6661e-03],\n",
       "         [6.6651e-04, 6.4100e-04, 4.8872e-04,  ..., 6.0096e-03,\n",
       "          1.7261e-03, 2.4877e-03],\n",
       "         [1.9461e-03, 1.0824e-02, 8.7529e-04,  ..., 1.0222e-03,\n",
       "          2.2395e-03, 1.0053e-02]],\n",
       "\n",
       "        [[1.0159e-03, 6.2319e-03, 2.2629e-03,  ..., 1.7951e-03,\n",
       "          7.5702e-04, 5.2161e-03],\n",
       "         [1.5449e-03, 1.2311e-02, 5.3718e-04,  ..., 3.0231e-03,\n",
       "          1.5314e-03, 1.9029e-03],\n",
       "         [5.1014e-03, 1.0924e-03, 1.4512e-02,  ..., 3.3927e-02,\n",
       "          5.1772e-03, 6.6372e-03],\n",
       "         ...,\n",
       "         [1.7778e-03, 5.7014e-03, 1.4491e-03,  ..., 3.0638e-04,\n",
       "          5.7278e-03, 5.7545e-04],\n",
       "         [5.4491e-03, 6.3985e-03, 5.8996e-03,  ..., 6.4843e-03,\n",
       "          8.3675e-05, 7.8245e-04],\n",
       "         [5.0416e-03, 5.5998e-04, 1.1673e-03,  ..., 1.9357e-03,\n",
       "          6.7441e-03, 2.8442e-03]],\n",
       "\n",
       "        [[3.3748e-04, 6.9812e-03, 3.0470e-04,  ..., 2.7511e-03,\n",
       "          1.7121e-03, 2.4357e-03],\n",
       "         [2.1652e-03, 1.7404e-03, 1.3108e-03,  ..., 7.4060e-03,\n",
       "          7.7573e-03, 3.8629e-04],\n",
       "         [1.2617e-03, 1.4121e-03, 3.1059e-04,  ..., 8.2836e-04,\n",
       "          9.3627e-03, 2.6152e-03],\n",
       "         ...,\n",
       "         [3.0332e-03, 1.0643e-02, 3.2283e-03,  ..., 3.9620e-04,\n",
       "          1.0207e-03, 4.7555e-03],\n",
       "         [7.7205e-04, 2.4430e-03, 1.2793e-03,  ..., 4.2910e-03,\n",
       "          1.0462e-03, 6.2221e-03],\n",
       "         [3.2144e-03, 1.1072e-03, 2.7979e-04,  ..., 6.8114e-04,\n",
       "          2.1107e-03, 1.6171e-03]]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpatch.layers[0].probs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9ff01a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,  64, 128],\n",
       "        [ 65, 129,   1],\n",
       "        [  2,  66, 130],\n",
       "        [  3,  67, 131],\n",
       "        [132,   4,  68],\n",
       "        [  5,  69, 133],\n",
       "        [134,  70,   6],\n",
       "        [  7,  71, 135],\n",
       "        [  8,  72, 136],\n",
       "        [ 73, 137,   9],\n",
       "        [ 10,  74, 138],\n",
       "        [ 11,  75, 139],\n",
       "        [140,  12,  76],\n",
       "        [ 13,  77, 141],\n",
       "        [142,  78,  14],\n",
       "        [ 15,  79, 143],\n",
       "        [ 16,  80, 144],\n",
       "        [ 81, 145,  17],\n",
       "        [ 18,  82, 146],\n",
       "        [ 19,  83, 147],\n",
       "        [148,  20,  84],\n",
       "        [ 21,  85, 149],\n",
       "        [150,  86,  22],\n",
       "        [ 23,  87, 151],\n",
       "        [ 24,  88, 152],\n",
       "        [ 89, 153,  25],\n",
       "        [ 26,  90, 154],\n",
       "        [ 27,  91, 155],\n",
       "        [156,  28,  92],\n",
       "        [ 29,  93, 157],\n",
       "        [158,  94,  30],\n",
       "        [ 31,  95, 159],\n",
       "        [ 32,  96, 160],\n",
       "        [ 33, 161,  97],\n",
       "        [162,  34,  98],\n",
       "        [ 35,  99, 163],\n",
       "        [164, 100,  36],\n",
       "        [ 37, 101, 165],\n",
       "        [ 38, 166, 102],\n",
       "        [103,  39, 167],\n",
       "        [ 40, 104, 168],\n",
       "        [ 41, 169, 105],\n",
       "        [170,  42, 106],\n",
       "        [ 43, 107, 171],\n",
       "        [172, 108,  44],\n",
       "        [ 45, 109, 173],\n",
       "        [ 46, 174, 110],\n",
       "        [111,  47, 175],\n",
       "        [ 48, 112, 176],\n",
       "        [ 49, 177, 113],\n",
       "        [178,  50, 114],\n",
       "        [ 51, 115, 179],\n",
       "        [180, 116,  52],\n",
       "        [ 53, 117, 181],\n",
       "        [ 54, 182, 118],\n",
       "        [119,  55, 183],\n",
       "        [ 56, 120, 184],\n",
       "        [ 57, 185, 121],\n",
       "        [186,  58, 122],\n",
       "        [ 59, 123, 187],\n",
       "        [188, 124,  60],\n",
       "        [ 61, 125, 189],\n",
       "        [ 62, 190, 126],\n",
       "        [127,  63, 191]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctest.layers[0].scope_idx.reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9383e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for variable_id in range(16):\n",
    "    probs_four = torch.zeros((1,1,256))\n",
    "    probs_four[0,0,variable_id]=1\n",
    "    cbase.layers[variable_id].probs.nodes[0]._ptensor.data=probs_four.data*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "739fb174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-94.7456]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbase_folded =compile(new_circ)\n",
    "cbase_folded(example_data.reshape(1,-1))\n",
    "# cbase_folded.layers[0].probs.nodes[0]._ptensor.data.shape\n",
    "# patched.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "ed5b9eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchCircuit(\n",
       "  (0): TorchCategoricalLayer(\n",
       "    folds: 16  variables: 1  output-units: 2\n",
       "    input-shape: (16, 1, -1, 1)\n",
       "    output-shape: (16, -1, 2)\n",
       "    (probs): TorchParameter(\n",
       "      shape: (16, 2, 256)\n",
       "      (0): TorchTensorParameter(output-shape: (16, 2, 256))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(16, 2, 256)]\n",
       "        output-shape: (16, 2, 256)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): TorchCPTLayer(\n",
       "    folds: 16  arity: 2  input-units: 2  output-units: 2\n",
       "    input-shape: (16, 2, -1, 2)\n",
       "    output-shape: (16, -1, 2)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (16, 2, 2)\n",
       "      (0): TorchTensorParameter(output-shape: (16, 2, 2))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(16, 2, 2)]\n",
       "        output-shape: (16, 2, 2)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): TorchCPTLayer(\n",
       "    folds: 8  arity: 2  input-units: 2  output-units: 2\n",
       "    input-shape: (8, 2, -1, 2)\n",
       "    output-shape: (8, -1, 2)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (8, 2, 2)\n",
       "      (0): TorchTensorParameter(output-shape: (8, 2, 2))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(8, 2, 2)]\n",
       "        output-shape: (8, 2, 2)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): TorchSumLayer(\n",
       "    folds: 4  arity: 2  input-units: 2  output-units: 2\n",
       "    input-shape: (4, 2, -1, 2)\n",
       "    output-shape: (4, -1, 2)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (4, 2, 4)\n",
       "      (0): TorchTensorParameter(output-shape: (4, 2, 2))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(4, 2, 2)]\n",
       "        output-shape: (4, 2, 2)\n",
       "      )\n",
       "      (2): TorchMixingWeightParameter(\n",
       "        input-shapes: [(4, 2, 2)]\n",
       "        output-shape: (4, 2, 4)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): TorchCPTLayer(\n",
       "    folds: 4  arity: 2  input-units: 2  output-units: 2\n",
       "    input-shape: (4, 2, -1, 2)\n",
       "    output-shape: (4, -1, 2)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (4, 2, 2)\n",
       "      (0): TorchTensorParameter(output-shape: (4, 2, 2))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(4, 2, 2)]\n",
       "        output-shape: (4, 2, 2)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): TorchCPTLayer(\n",
       "    folds: 2  arity: 2  input-units: 2  output-units: 1\n",
       "    input-shape: (2, 2, -1, 2)\n",
       "    output-shape: (2, -1, 1)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (2, 1, 2)\n",
       "      (0): TorchTensorParameter(output-shape: (2, 1, 2))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(2, 1, 2)]\n",
       "        output-shape: (2, 1, 2)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (6): TorchSumLayer(\n",
       "    folds: 1  arity: 2  input-units: 1  output-units: 1\n",
       "    input-shape: (1, 2, -1, 1)\n",
       "    output-shape: (1, -1, 1)\n",
       "    (weight): TorchParameter(\n",
       "      shape: (1, 1, 2)\n",
       "      (0): TorchTensorParameter(output-shape: (1, 1, 2))\n",
       "      (1): TorchSoftmaxParameter(\n",
       "        input-shapes: [(1, 1, 2)]\n",
       "        output-shape: (1, 1, 2)\n",
       "      )\n",
       "      (2): TorchMixingWeightParameter(\n",
       "        input-shapes: [(1, 1, 2)]\n",
       "        output-shape: (1, 1, 2)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbase_folded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaddcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-4.7684e-07, -2.0000e+01, -2.0000e+01,  ..., -2.0000e+01,\n",
       "          -2.0000e+01, -2.0000e+01],\n",
       "         [-2.0000e+01, -4.7684e-07, -2.0000e+01,  ..., -2.0000e+01,\n",
       "          -2.0000e+01, -2.0000e+01]],\n",
       "\n",
       "        [[-2.0000e+01, -4.7684e-07, -2.0000e+01,  ..., -2.0000e+01,\n",
       "          -2.0000e+01, -2.0000e+01],\n",
       "         [-2.0000e+01, -2.0000e+01, -4.7684e-07,  ..., -2.0000e+01,\n",
       "          -2.0000e+01, -2.0000e+01]],\n",
       "\n",
       "        [[-2.0000e+01, -2.0000e+01, -2.0000e+01,  ..., -2.0000e+01,\n",
       "          -2.0000e+01, -2.0000e+01],\n",
       "         [-2.0000e+01, -2.0000e+01, -2.0000e+01,  ..., -2.0000e+01,\n",
       "          -2.0000e+01, -2.0000e+01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.0000e+01, -2.0000e+01, -2.0000e+01,  ..., -2.0000e+01,\n",
       "          -2.0000e+01, -2.0000e+01],\n",
       "         [-2.0000e+01, -2.0000e+01, -2.0000e+01,  ..., -2.0000e+01,\n",
       "          -2.0000e+01, -2.0000e+01]],\n",
       "\n",
       "        [[-2.0000e+01, -2.0000e+01, -2.0000e+01,  ..., -2.0000e+01,\n",
       "          -2.0000e+01, -2.0000e+01],\n",
       "         [-2.0000e+01, -2.0000e+01, -2.0000e+01,  ..., -2.0000e+01,\n",
       "          -2.0000e+01, -2.0000e+01]],\n",
       "\n",
       "        [[-2.0000e+01, -2.0000e+01, -2.0000e+01,  ..., -2.0000e+01,\n",
       "          -2.0000e+01, -2.0000e+01],\n",
       "         [-2.0000e+01, -2.0000e+01, -2.0000e+01,  ..., -2.0000e+01,\n",
       "          -2.0000e+01, -2.0000e+01]]], grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folded_tensor=torch.zeros((16,2,256))\n",
    "for idx,variable_id in enumerate(patched.reshape(-1).long()):\n",
    "    # probs_four = torch.arange(1,257).reshape(1,1,256)\n",
    "    probs_four=torch.zeros((1,2,256))\n",
    "    probs_four[0,0,variable_id]=1\n",
    "    probs_four[0,1,variable_id+1]=1\n",
    "    folded_tensor[idx, :, :]=(probs_four.data*20)\n",
    "cbase_folded.layers[0].probs.nodes[0]._ptensor.data = folded_tensor.data[patched.reshape(-1).long(),:,:]\n",
    "cbase_folded.layers[0].probs().log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522aeaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  4.,  5.,  2.,  3.,  6.,  7.,  8.,  9., 12., 13., 10., 11.,\n",
       "         14., 15.]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "838f5bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-4.7684e-07, -2.0000e+01]],\n",
       "\n",
       "        [[-4.7684e-07, -2.0000e+01]],\n",
       "\n",
       "        [[-4.7684e-07, -2.0000e+01]],\n",
       "\n",
       "        [[-4.7684e-07, -2.0000e+01]],\n",
       "\n",
       "        [[-4.7684e-07, -2.0000e+01]],\n",
       "\n",
       "        [[-4.7684e-07, -2.0000e+01]],\n",
       "\n",
       "        [[-4.7684e-07, -2.0000e+01]],\n",
       "\n",
       "        [[-4.7684e-07, -2.0000e+01]],\n",
       "\n",
       "        [[-4.7684e-07, -2.0000e+01]],\n",
       "\n",
       "        [[-4.7684e-07, -2.0000e+01]],\n",
       "\n",
       "        [[-4.7684e-07, -2.0000e+01]],\n",
       "\n",
       "        [[-4.7684e-07, -2.0000e+01]],\n",
       "\n",
       "        [[-4.7684e-07, -2.0000e+01]],\n",
       "\n",
       "        [[-4.7684e-07, -2.0000e+01]],\n",
       "\n",
       "        [[-4.7684e-07, -2.0000e+01]],\n",
       "\n",
       "        [[-4.7684e-07, -2.0000e+01]]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbase_folded.layers[0].log_unnormalized_likelihood(example_data.reshape(16,-1, 1))\n",
    "\n",
    "cbase_folded.layers[0].log_unnormalized_likelihood(patched.reshape(1,-1).reshape(16,-1, 1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
