{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "24e4acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from cirkit.templates import data_modalities, utils\n",
    "\n",
    "KERNEL_SIZE = (4, 4)\n",
    "STRIDE = KERNEL_SIZE\n",
    "gpu_id = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae519efc",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6c7ed83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 196 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "PIXEL_RANGE = 255\n",
    "# Store an example image\n",
    "example_image = None\n",
    "\n",
    "\n",
    "def patchify(kernel_size, stride):\n",
    "    def _create_patch(image):\n",
    "        batched = image.view((1,) + image.shape)  # (B,C,H,W)\n",
    "        batched_patches = F.unfold(\n",
    "            batched, kernel_size=kernel_size, stride=stride\n",
    "        )  # (B, C x K x K, L)\n",
    "        patches = batched_patches.transpose(1, 2).view(\n",
    "            (batched_patches.shape[-1], 1, *kernel_size)\n",
    "        )  # (P,C, H, W)\n",
    "        return patches\n",
    "\n",
    "    return _create_patch\n",
    "\n",
    "\n",
    "def collate_patches(batch):\n",
    "    batched_patch = []\n",
    "    batched_label = []\n",
    "\n",
    "    num_patch = batch[0][0].shape[0]\n",
    "    for tensor, label in batch:\n",
    "        batched_label.extend([label for _ in range(num_patch)])\n",
    "\n",
    "        batched_patch.extend(tensor.unbind(0))\n",
    "    # (B,P,C,H,W) -> (BxP,C,H,W)\n",
    "    return torch.stack(batched_patch), batched_label\n",
    "\n",
    "\n",
    "# Load the MNIST data set and data loaders\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        # Set pixel values in the [0-255] range\n",
    "        patchify(KERNEL_SIZE, STRIDE),\n",
    "        transforms.Lambda(lambda x: (PIXEL_RANGE * x).long()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Function to plot the first 9 images from the dataloader\n",
    "def plot_sample_images(dataloader, gridsize=4):\n",
    "    global example_image\n",
    "    # Get the first batch of images and labels\n",
    "    images, label = next(iter(dataloader))\n",
    "    example_image = images[0][0]\n",
    "    images = images[: gridsize**2]\n",
    "\n",
    "    # Create a 3x3 subplot\n",
    "    fig, axes = plt.subplots(gridsize, gridsize, figsize=(8, 8))\n",
    "\n",
    "    # Plot each image\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Convert the image to a 2D array (since MNIST images are 28x28 pixels)\n",
    "        img = images[i, :, :, :].numpy().squeeze()\n",
    "\n",
    "        # Display the image\n",
    "        ax.imshow(img, cmap=\"gray\")\n",
    "        ax.axis(\"off\")  # Turn off axis\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    fig.suptitle(\"Example MNIST Images\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "data_train = datasets.MNIST(\"datasets\", train=True, download=True, transform=transform)\n",
    "data_test = datasets.MNIST(\"datasets\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Instantiate the training and testing data loaders\n",
    "train_dataloader = DataLoader(\n",
    "    data_train, shuffle=True, batch_size=256, collate_fn=collate_patches\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    data_test, shuffle=False, batch_size=256, collate_fn=collate_patches\n",
    ")\n",
    "# Call the function to plot images\n",
    "plot_sample_images(train_dataloader, gridsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a3661357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cirkit.symbolic.circuit.Circuit at 0x7f2f9024d570>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit = data_modalities.image_data(\n",
    "    (1, *KERNEL_SIZE),\n",
    "    region_graph=\"quad-graph\",\n",
    "    input_layer=\"categorical\",\n",
    "    num_input_units=64,\n",
    "    sum_product_layer=\"cp\",\n",
    "    num_sum_units=64,\n",
    "    sum_weight_param=utils.Parameterization(\n",
    "        activation=\"softmax\", initialization=\"normal\"\n",
    "    ),\n",
    ")\n",
    "circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e278fd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200: Average NLL: 51.610\n",
      "Step 400: Average NLL: 18.951\n",
      "Step 600: Average NLL: 16.763\n",
      "Step 800: Average NLL: 15.937\n",
      "Step 1000: Average NLL: 15.541\n",
      "Step 1200: Average NLL: 15.334\n",
      "Step 1400: Average NLL: 15.213\n",
      "Step 1600: Average NLL: 15.165\n",
      "Step 1800: Average NLL: 15.073\n",
      "Step 2000: Average NLL: 15.062\n",
      "Step 2200: Average NLL: 15.045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'# trainable parameters': 508546,\n",
       " 'train loss': [51.61037826538086,\n",
       "  18.9510440826416,\n",
       "  16.762956619262695,\n",
       "  15.9368314743042,\n",
       "  15.540987968444824,\n",
       "  15.334369659423828,\n",
       "  15.213346481323242,\n",
       "  15.165040969848633,\n",
       "  15.072599411010742,\n",
       "  15.061633110046387,\n",
       "  15.045388221740723]}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from cirkit.pipeline import compile\n",
    "\n",
    "\n",
    "def train_circuit(cc):\n",
    "    # Set some seeds\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    # torch.cuda.manual_seed(42)\n",
    "\n",
    "    # Set the torch device to use\n",
    "    device = torch.device(f\"cuda:{gpu_id}\")\n",
    "\n",
    "    # Compile the circuit\n",
    "    circuit = compile(cc)\n",
    "\n",
    "    # Move the circuit to chosen device\n",
    "    circuit = circuit.to(device)\n",
    "\n",
    "    num_epochs = 10\n",
    "    step_idx = 0\n",
    "    running_loss = 0.0\n",
    "    running_samples = 0\n",
    "    stats = dict()\n",
    "\n",
    "    stats[\"# trainable parameters\"] = sum(\n",
    "        p.numel() for p in circuit.parameters() if p.requires_grad\n",
    "    )\n",
    "    stats[\"train loss\"] = []\n",
    "\n",
    "    # Initialize a torch optimizer of your choice,\n",
    "    #  e.g., Adam, by passing the parameters of the circuit\n",
    "    optimizer = torch.optim.Adam(circuit.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        for i, (batch, _) in enumerate(train_dataloader):\n",
    "            # The circuit expects an input of shape (batch_dim, num_variables)\n",
    "            BS = batch.shape[0]\n",
    "            batch = batch.view(BS, -1).to(device)\n",
    "\n",
    "            # Compute the log-likelihoods of the batch, by evaluating the circuit\n",
    "            log_likelihoods = circuit(batch)\n",
    "\n",
    "            # We take the negated average log-likelihood as loss\n",
    "            loss = -torch.mean(log_likelihoods)\n",
    "            loss.backward()\n",
    "            # Update the parameters of the circuits, as any other model in PyTorch\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            running_loss += loss.detach() * len(batch)\n",
    "            running_samples += len(batch)\n",
    "            step_idx += 1\n",
    "            if step_idx % 200 == 0:\n",
    "                average_nll = running_loss / running_samples\n",
    "                print(f\"Step {step_idx}: Average NLL: {average_nll:.3f}\")\n",
    "                running_loss = 0.0\n",
    "                running_samples = 0\n",
    "\n",
    "                stats[\"train loss\"].append(average_nll.cpu().item())\n",
    "    return stats, circuit\n",
    "\n",
    "\n",
    "stats, t_circuit = train_circuit(circuit)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ee65a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test LL: 731.456\n",
      "Bits per dimension: 1.346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'# trainable parameters': 508546,\n",
       " 'train loss': [51.61037826538086,\n",
       "  18.9510440826416,\n",
       "  16.762956619262695,\n",
       "  15.9368314743042,\n",
       "  15.540987968444824,\n",
       "  15.334369659423828,\n",
       "  15.213346481323242,\n",
       "  15.165040969848633,\n",
       "  15.072599411010742,\n",
       "  15.061633110046387,\n",
       "  15.045388221740723],\n",
       " 'test loss': 731.456281640625,\n",
       " 'test bits per dimension': np.float64(1.3460055486607279),\n",
       " 'train loss (min)': 15.045388221740723}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_circuit(circuit):\n",
    "    circuit = circuit.to()\n",
    "    with torch.no_grad():\n",
    "        test_lls = 0.0\n",
    "\n",
    "        for batch, _ in test_dataloader:\n",
    "            # The circuit expects an input of shape (batch_dim, num_variables)\n",
    "            BS = batch.shape[0]\n",
    "            # (BxP,C,H,W) -> # (B,P,C,H,W)\n",
    "            batch = batch.view(BS, -1).to(f\"cuda:{gpu_id}\")\n",
    "            # Compute the log-likelihoods of the batch\n",
    "            log_likelihoods = circuit(batch)\n",
    "\n",
    "            # Accumulate the log-likelihoods\n",
    "            test_lls += log_likelihoods.sum().item()\n",
    "\n",
    "        # Compute average test log-likelihood and bits per dimension\n",
    "        average_nll = -test_lls / len(data_test)\n",
    "\n",
    "        bpd = average_nll / (28 * 28 * np.log(2.0))\n",
    "        print(f\"Average test LL: {average_nll:.3f}\")\n",
    "        print(f\"Bits per dimension: {bpd:.3f}\")\n",
    "\n",
    "        stats[\"test loss\"] = average_nll\n",
    "        stats[\"test bits per dimension\"] = bpd\n",
    "\n",
    "    # Free GPU memory\n",
    "    circuit = circuit.to(\"cpu\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    stats[\"train loss (min)\"] = min(stats[\"train loss\"])\n",
    "    return stats\n",
    "\n",
    "\n",
    "eval_circuit(t_circuit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
